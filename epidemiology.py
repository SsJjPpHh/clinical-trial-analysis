
"""
æµè¡Œç—…å­¦åˆ†ææ¨¡å— (epidemiology.py)
æä¾›ä¸“é—¨çš„æµè¡Œç—…å­¦åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬é˜Ÿåˆ—ç ”ç©¶ã€ç—…ä¾‹å¯¹ç…§ç ”ç©¶ã€æ¨ªæ–­é¢ç ”ç©¶ç­‰
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import scipy.stats as stats
from scipy.stats import chi2_contingency, fisher_exact, mannwhitneyu, ttest_ind
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

def epidemiology_analysis():
    """æµè¡Œç—…å­¦åˆ†æä¸»å‡½æ•°"""
    st.markdown("# ğŸ¦  æµè¡Œç—…å­¦åˆ†ææ¨¡å—")
    st.markdown("*ä¸“ä¸šçš„æµè¡Œç—…å­¦ç ”ç©¶åˆ†æå·¥å…·*")
    
    # ä¾§è¾¹æ  - åˆ†æç±»å‹é€‰æ‹©
    with st.sidebar:
        st.markdown("### ğŸ“‹ åˆ†æç±»å‹")
        analysis_type = st.selectbox(
            "é€‰æ‹©åˆ†æç±»å‹",
            [
                "ğŸ“Š æè¿°æ€§æµè¡Œç—…å­¦",
                "ğŸ”¬ é˜Ÿåˆ—ç ”ç©¶åˆ†æ", 
                "ğŸ¯ ç—…ä¾‹å¯¹ç…§ç ”ç©¶",
                "ğŸ“ˆ æ¨ªæ–­é¢ç ”ç©¶",
                "ğŸŒ ç–¾ç—…ç›‘æµ‹åˆ†æ",
                "ğŸ“‰ æµè¡Œè¶‹åŠ¿åˆ†æ",
                "ğŸ—ºï¸ ç©ºé—´æµè¡Œç—…å­¦",
                "âš¡ ç–«æƒ…æš´å‘è°ƒæŸ¥",
                "ğŸ§¬ åˆ†å­æµè¡Œç—…å­¦",
                "ğŸ“Š ç­›æŸ¥è¯•éªŒè¯„ä»·"
            ]
        )
    
    # æ•°æ®ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ğŸ“ ä¸Šä¼ æµè¡Œç—…å­¦æ•°æ®",
        type=['csv', 'xlsx', 'xls'],
        help="æ”¯æŒCSVå’ŒExcelæ ¼å¼çš„æµè¡Œç—…å­¦æ•°æ®"
    )
    
    if uploaded_file is not None:
        try:
            # è¯»å–æ•°æ®
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")
            
            # æ•°æ®é¢„è§ˆ
            with st.expander("ğŸ‘€ æ•°æ®é¢„è§ˆ", expanded=False):
                st.dataframe(df.head(10))
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ€»æ ·æœ¬é‡", len(df))
                with col2:
                    st.metric("å˜é‡æ•°", len(df.columns))
                with col3:
                    missing_rate = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
                    st.metric("ç¼ºå¤±ç‡", f"{missing_rate:.1f}%")
            
            # æ ¹æ®é€‰æ‹©çš„åˆ†æç±»å‹è°ƒç”¨ç›¸åº”å‡½æ•°
            if analysis_type == "ğŸ“Š æè¿°æ€§æµè¡Œç—…å­¦":
                descriptive_epidemiology(df)
            elif analysis_type == "ğŸ”¬ é˜Ÿåˆ—ç ”ç©¶åˆ†æ":
                cohort_study_analysis(df)
            elif analysis_type == "ğŸ¯ ç—…ä¾‹å¯¹ç…§ç ”ç©¶":
                case_control_analysis(df)
            elif analysis_type == "ğŸ“ˆ æ¨ªæ–­é¢ç ”ç©¶":
                cross_sectional_analysis(df)
            elif analysis_type == "ğŸŒ ç–¾ç—…ç›‘æµ‹åˆ†æ":
                disease_surveillance(df)
            elif analysis_type == "ğŸ“‰ æµè¡Œè¶‹åŠ¿åˆ†æ":
                trend_analysis(df)
            elif analysis_type == "ğŸ—ºï¸ ç©ºé—´æµè¡Œç—…å­¦":
                spatial_epidemiology(df)
            elif analysis_type == "âš¡ ç–«æƒ…æš´å‘è°ƒæŸ¥":
                outbreak_investigation(df)
            elif analysis_type == "ğŸ§¬ åˆ†å­æµè¡Œç—…å­¦":
                molecular_epidemiology(df)
            elif analysis_type == "ğŸ“Š ç­›æŸ¥è¯•éªŒè¯„ä»·":
                screening_test_evaluation(df)
                
        except Exception as e:
            st.error(f"âŒ æ•°æ®è¯»å–å¤±è´¥: {str(e)}")
    
    else:
        # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®æ ¼å¼
        show_example_data_formats()

def show_example_data_formats():
    """æ˜¾ç¤ºç¤ºä¾‹æ•°æ®æ ¼å¼"""
    st.markdown("### ğŸ“‹ æ•°æ®æ ¼å¼è¦æ±‚")
    
    tab1, tab2, tab3, tab4 = st.tabs(["é˜Ÿåˆ—ç ”ç©¶", "ç—…ä¾‹å¯¹ç…§", "æ¨ªæ–­é¢ç ”ç©¶", "ç–¾ç—…ç›‘æµ‹"])
    
    with tab1:
        st.markdown("#### é˜Ÿåˆ—ç ”ç©¶æ•°æ®æ ¼å¼ç¤ºä¾‹")
        cohort_example = pd.DataFrame({
            'å—è¯•è€…ID': ['P001', 'P002', 'P003', 'P004', 'P005'],
            'å¹´é¾„': [45, 52, 38, 61, 29],
            'æ€§åˆ«': ['ç”·', 'å¥³', 'ç”·', 'å¥³', 'ç”·'],
            'æš´éœ²çŠ¶æ€': ['æš´éœ²', 'æœªæš´éœ²', 'æš´éœ²', 'æœªæš´éœ²', 'æš´éœ²'],
            'éšè®¿æ—¶é—´(å¹´)': [5.2, 4.8, 6.1, 3.9, 5.5],
            'ç»“å±€å‘ç”Ÿ': ['æ˜¯', 'å¦', 'æ˜¯', 'å¦', 'å¦'],
            'ç»“å±€æ—¶é—´(å¹´)': [3.1, 4.8, 2.8, 3.9, 5.5]
        })
        st.dataframe(cohort_example)
    
    with tab2:
        st.markdown("#### ç—…ä¾‹å¯¹ç…§ç ”ç©¶æ•°æ®æ ¼å¼ç¤ºä¾‹")
        case_control_example = pd.DataFrame({
            'å—è¯•è€…ID': ['C001', 'C002', 'C003', 'C004', 'C005'],
            'å¹´é¾„': [55, 48, 62, 39, 51],
            'æ€§åˆ«': ['å¥³', 'ç”·', 'å¥³', 'ç”·', 'å¥³'],
            'ç—…ä¾‹å¯¹ç…§': ['ç—…ä¾‹', 'å¯¹ç…§', 'ç—…ä¾‹', 'å¯¹ç…§', 'ç—…ä¾‹'],
            'æš´éœ²å²': ['æœ‰', 'æ— ', 'æœ‰', 'æ— ', 'æœ‰'],
            'å¸çƒŸå²': ['æ˜¯', 'å¦', 'æ˜¯', 'å¦', 'æ˜¯'],
            'å®¶æ—å²': ['æœ‰', 'æ— ', 'æœ‰', 'æ— ', 'æ— ']
        })
        st.dataframe(case_control_example)
    
    with tab3:
        st.markdown("#### æ¨ªæ–­é¢ç ”ç©¶æ•°æ®æ ¼å¼ç¤ºä¾‹")
        cross_sectional_example = pd.DataFrame({
            'å—è¯•è€…ID': ['S001', 'S002', 'S003', 'S004', 'S005'],
            'å¹´é¾„': [34, 45, 28, 56, 41],
            'æ€§åˆ«': ['ç”·', 'å¥³', 'ç”·', 'å¥³', 'ç”·'],
            'åœ°åŒº': ['åŸå¸‚', 'å†œæ‘', 'åŸå¸‚', 'å†œæ‘', 'åŸå¸‚'],
            'ç–¾ç—…çŠ¶æ€': ['æ‚£ç—…', 'æœªæ‚£ç—…', 'æœªæ‚£ç—…', 'æ‚£ç—…', 'æœªæ‚£ç—…'],
            'å±é™©å› ç´ 1': ['æœ‰', 'æ— ', 'æœ‰', 'æœ‰', 'æ— '],
            'å±é™©å› ç´ 2': ['é«˜', 'ä½', 'ä¸­', 'é«˜', 'ä½']
        })
        st.dataframe(cross_sectional_example)
    
    with tab4:
        st.markdown("#### ç–¾ç—…ç›‘æµ‹æ•°æ®æ ¼å¼ç¤ºä¾‹")
        surveillance_example = pd.DataFrame({
            'æ—¥æœŸ': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05'],
            'åœ°åŒº': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æ­å·'],
            'ç—…ä¾‹æ•°': [12, 8, 15, 6, 9],
            'æ­»äº¡æ•°': [1, 0, 2, 0, 1],
            'äººå£æ•°': [2000000, 2500000, 1800000, 1300000, 1200000],
            'å¹´é¾„ç»„': ['å…¨å¹´é¾„', 'å…¨å¹´é¾„', 'å…¨å¹´é¾„', 'å…¨å¹´é¾„', 'å…¨å¹´é¾„']
        })
        st.dataframe(surveillance_example)

def descriptive_epidemiology(df):
    """æè¿°æ€§æµè¡Œç—…å­¦åˆ†æ"""
    st.markdown("### ğŸ“Š æè¿°æ€§æµè¡Œç—…å­¦åˆ†æ")
    st.markdown("*åˆ†æç–¾ç—…çš„äººç¾¤ã€æ—¶é—´ã€åœ°åŒºåˆ†å¸ƒç‰¹å¾*")
    
    # å˜é‡é€‰æ‹©
    col1, col2 = st.columns(2)
    
    with col1:
        # ç–¾ç—…/ç»“å±€å˜é‡
        outcome_vars = df.columns.tolist()
        outcome_var = st.selectbox("é€‰æ‹©ç–¾ç—…/ç»“å±€å˜é‡", outcome_vars)
    
    with col2:
        # åˆ†æç»´åº¦
        analysis_dimension = st.selectbox(
            "é€‰æ‹©åˆ†æç»´åº¦",
            ["äººç¾¤ç‰¹å¾åˆ†æ", "æ—¶é—´åˆ†å¸ƒåˆ†æ", "åœ°åŒºåˆ†å¸ƒåˆ†æ", "ç»¼åˆåˆ†æ"]
        )
    
    if outcome_var:
        if analysis_dimension == "äººç¾¤ç‰¹å¾åˆ†æ":
            person_analysis(df, outcome_var)
        elif analysis_dimension == "æ—¶é—´åˆ†å¸ƒåˆ†æ":
            time_analysis(df, outcome_var)
        elif analysis_dimension == "åœ°åŒºåˆ†å¸ƒåˆ†æ":
            place_analysis(df, outcome_var)
        elif analysis_dimension == "ç»¼åˆåˆ†æ":
            comprehensive_descriptive_analysis(df, outcome_var)

def person_analysis(df, outcome_var):
    """äººç¾¤ç‰¹å¾åˆ†æ"""
    st.markdown("#### ğŸ‘¥ äººç¾¤ç‰¹å¾åˆ†æ")
    
    # è¯†åˆ«äººç¾¤ç‰¹å¾å˜é‡
    person_vars = identify_person_variables(df)
    
    if not person_vars:
        st.warning("âš ï¸ æœªè¯†åˆ«åˆ°äººç¾¤ç‰¹å¾å˜é‡ï¼ˆå¦‚å¹´é¾„ã€æ€§åˆ«ç­‰ï¼‰")
        return
    
    # é€‰æ‹©äººç¾¤å˜é‡
    selected_person_vars = st.multiselect(
        "é€‰æ‹©äººç¾¤ç‰¹å¾å˜é‡",
        person_vars,
        default=person_vars[:3] if len(person_vars) >= 3 else person_vars
    )
    
    if not selected_person_vars:
        return
    
    # åˆ†ææ¯ä¸ªäººç¾¤ç‰¹å¾
    for person_var in selected_person_vars:
        st.markdown(f"##### ğŸ“Š æŒ‰{person_var}åˆ†å¸ƒ")
        
        # åˆ›å»ºäº¤å‰è¡¨
        if df[outcome_var].dtype in ['object', 'category'] or df[outcome_var].nunique() <= 10:
            # åˆ†ç±»ç»“å±€å˜é‡
            crosstab = pd.crosstab(df[person_var], df[outcome_var], margins=True)
            
            # è®¡ç®—ç‡
            if 'æ‚£ç—…' in df[outcome_var].values or 'æ˜¯' in df[outcome_var].values:
                disease_col = 'æ‚£ç—…' if 'æ‚£ç—…' in df[outcome_var].values else 'æ˜¯'
                if disease_col in crosstab.columns:
                    crosstab['æ‚£ç—…ç‡(%)'] = (crosstab[disease_col] / crosstab['All'] * 100).round(2)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.dataframe(crosstab)
            
            with col2:
                # å¯è§†åŒ–
                if 'æ‚£ç—…ç‡(%)' in crosstab.columns:
                    # æ’é™¤æ€»è®¡è¡Œ
                    plot_data = crosstab[crosstab.index != 'All']
                    
                    fig = px.bar(
                        x=plot_data.index,
                        y=plot_data['æ‚£ç—…ç‡(%)'],
                        title=f"{outcome_var}æŒ‰{person_var}çš„æ‚£ç—…ç‡åˆ†å¸ƒ",
                        labels={'x': person_var, 'y': 'æ‚£ç—…ç‡(%)'}
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
        
        else:
            # è¿ç»­ç»“å±€å˜é‡
            summary_stats = df.groupby(person_var)[outcome_var].agg([
                'count', 'mean', 'std', 'median', 'min', 'max'
            ]).round(3)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.dataframe(summary_stats)
            
            with col2:
                # ç®±çº¿å›¾
                fig = px.box(
                    df, x=person_var, y=outcome_var,
                    title=f"{outcome_var}æŒ‰{person_var}çš„åˆ†å¸ƒ"
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
        
        # ç»Ÿè®¡æ£€éªŒ
        perform_person_analysis_test(df, person_var, outcome_var)

def perform_person_analysis_test(df, person_var, outcome_var):
    """æ‰§è¡Œäººç¾¤ç‰¹å¾åˆ†æçš„ç»Ÿè®¡æ£€éªŒ"""
    st.markdown("**ç»Ÿè®¡æ£€éªŒç»“æœ:**")
    
    try:
        if df[outcome_var].dtype in ['object', 'category'] or df[outcome_var].nunique() <= 10:
            # åˆ†ç±»ç»“å±€å˜é‡ - å¡æ–¹æ£€éªŒ
            crosstab = pd.crosstab(df[person_var], df[outcome_var])
            
            if crosstab.shape[0] >= 2 and crosstab.shape[1] >= 2:
                if crosstab.shape == (2, 2) and crosstab.min().min() < 5:
                    # Fisherç²¾ç¡®æ£€éªŒ
                    _, p_value = fisher_exact(crosstab)
                    test_method = "Fisherç²¾ç¡®æ£€éªŒ"
                else:
                    # å¡æ–¹æ£€éªŒ
                    chi2, p_value, _, _ = chi2_contingency(crosstab)
                    test_method = "å¡æ–¹æ£€éªŒ"
                
                st.write(f"â€¢ æ£€éªŒæ–¹æ³•: {test_method}")
                st.write(f"â€¢ På€¼: {p_value:.4f}")
                
                if p_value < 0.05:
                    st.success("âœ… ä¸åŒäººç¾¤ç‰¹å¾é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚")
                else:
                    st.info("â„¹ï¸ ä¸åŒäººç¾¤ç‰¹å¾é—´æ— æ˜¾è‘—å·®å¼‚")
        
        else:
            # è¿ç»­ç»“å±€å˜é‡
            groups = df[person_var].unique()
            
            if len(groups) == 2:
                # ä¸¤ç»„æ¯”è¾ƒ - tæ£€éªŒ
                group1_data = df[df[person_var] == groups[0]][outcome_var].dropna()
                group2_data = df[df[person_var] == groups[1]][outcome_var].dropna()
                
                t_stat, p_value = ttest_ind(group1_data, group2_data)
                st.write(f"â€¢ æ£€éªŒæ–¹æ³•: ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ")
                st.write(f"â€¢ tç»Ÿè®¡é‡: {t_stat:.4f}")
                st.write(f"â€¢ På€¼: {p_value:.4f}")
                
                if p_value < 0.05:
                    st.success("âœ… ä¸¤ç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚")
                else:
                    st.info("â„¹ï¸ ä¸¤ç»„é—´æ— æ˜¾è‘—å·®å¼‚")
            
            else:
                # å¤šç»„æ¯”è¾ƒ - æ–¹å·®åˆ†æ
                group_data = [df[df[person_var] == group][outcome_var].dropna() for group in groups]
                f_stat, p_value = stats.f_oneway(*group_data)
                
                st.write(f"â€¢ æ£€éªŒæ–¹æ³•: å•å› ç´ æ–¹å·®åˆ†æ")
                st.write(f"â€¢ Fç»Ÿè®¡é‡: {f_stat:.4f}")
                st.write(f"â€¢ På€¼: {p_value:.4f}")
                
                if p_value < 0.05:
                    st.success("âœ… å„ç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚")
                else:
                    st.info("â„¹ï¸ å„ç»„é—´æ— æ˜¾è‘—å·®å¼‚")
    
    except Exception as e:
        st.warning(f"âš ï¸ ç»Ÿè®¡æ£€éªŒå¤±è´¥: {str(e)}")

def identify_person_variables(df):
    """è¯†åˆ«äººç¾¤ç‰¹å¾å˜é‡"""
    person_keywords = [
        'å¹´é¾„', 'æ€§åˆ«', 'èŒä¸š', 'æ•™è‚²', 'æ”¶å…¥', 'å©šå§»', 'æ°‘æ—', 
        'age', 'sex', 'gender', 'occupation', 'education', 'income', 'marital'
    ]
    
    person_vars = []
    
    for col in df.columns:
        # æ£€æŸ¥åˆ—åæ˜¯å¦åŒ…å«äººç¾¤ç‰¹å¾å…³é”®è¯
        if any(keyword in col.lower() for keyword in person_keywords):
            person_vars.append(col)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå…¸å‹çš„åˆ†ç±»å˜é‡
        elif df[col].dtype in ['object', 'category'] and df[col].nunique() <= 20:
            person_vars.append(col)
    
    return person_vars

def time_analysis(df, outcome_var):
    """æ—¶é—´åˆ†å¸ƒåˆ†æ"""
    st.markdown("#### â° æ—¶é—´åˆ†å¸ƒåˆ†æ")
    
    # è¯†åˆ«æ—¶é—´å˜é‡
    time_vars = identify_time_variables(df)
    
    if not time_vars:
        st.warning("âš ï¸ æœªè¯†åˆ«åˆ°æ—¶é—´å˜é‡")
        return
    
    # é€‰æ‹©æ—¶é—´å˜é‡
    time_var = st.selectbox("é€‰æ‹©æ—¶é—´å˜é‡", time_vars)
    
    if not time_var:
        return
    
    # æ—¶é—´åˆ†æç±»å‹
    time_analysis_type = st.selectbox(
        "é€‰æ‹©æ—¶é—´åˆ†æç±»å‹",
        ["æ—¶é—´è¶‹åŠ¿åˆ†æ", "å­£èŠ‚æ€§åˆ†æ", "å‘¨æœŸæ€§åˆ†æ", "æ—¶é—´èšé›†æ€§åˆ†æ"]
    )
    
    if time_analysis_type == "æ—¶é—´è¶‹åŠ¿åˆ†æ":
        temporal_trend_analysis(df, time_var, outcome_var)
    elif time_analysis_type == "å­£èŠ‚æ€§åˆ†æ":
        seasonal_analysis(df, time_var, outcome_var)
    elif time_analysis_type == "å‘¨æœŸæ€§åˆ†æ":
        cyclical_analysis(df, time_var, outcome_var)
    elif time_analysis_type == "æ—¶é—´èšé›†æ€§åˆ†æ":
        temporal_clustering_analysis(df, time_var, outcome_var)

def temporal_trend_analysis(df, time_var, outcome_var):
    """æ—¶é—´è¶‹åŠ¿åˆ†æ"""
    st.markdown("##### ğŸ“ˆ æ—¶é—´è¶‹åŠ¿åˆ†æ")
    
    try:
        # ç¡®ä¿æ—¶é—´å˜é‡ä¸ºæ—¥æœŸæ ¼å¼
        if df[time_var].dtype != 'datetime64[ns]':
            df[time_var] = pd.to_datetime(df[time_var], errors='coerce')
        
        # æŒ‰æ—¶é—´èšåˆæ•°æ®
        time_grouping = st.selectbox(
            "é€‰æ‹©æ—¶é—´èšåˆæ–¹å¼",
            ["æ—¥", "å‘¨", "æœˆ", "å­£åº¦", "å¹´"]
        )
        
        # åˆ›å»ºæ—¶é—´åˆ†ç»„
        if time_grouping == "æ—¥":
            df['æ—¶é—´ç»„'] = df[time_var].dt.date
        elif time_grouping == "å‘¨":
            df['æ—¶é—´ç»„'] = df[time_var].dt.to_period('W')
        elif time_grouping == "æœˆ":
            df['æ—¶é—´ç»„'] = df[time_var].dt.to_period('M')
        elif time_grouping == "å­£åº¦":
            df['æ—¶é—´ç»„'] = df[time_var].dt.to_period('Q')
        elif time_grouping == "å¹´":
            df['æ—¶é—´ç»„'] = df[time_var].dt.to_period('Y')
        
        # è®¡ç®—æ—¶é—´è¶‹åŠ¿
        if df[outcome_var].dtype in ['object', 'category'] or df[outcome_var].nunique() <= 10:
            # åˆ†ç±»ç»“å±€å˜é‡ - è®¡ç®—å‘ç—…ç‡
            if 'æ‚£ç—…' in df[outcome_var].values or 'æ˜¯' in df[outcome_var].values:
                disease_value = 'æ‚£ç—…' if 'æ‚£ç—…' in df[outcome_var].values else 'æ˜¯'
                
                time_trend = df.groupby('æ—¶é—´ç»„').agg({
                    outcome_var: ['count', lambda x: (x == disease_value).sum()]
                }).round(3)
                
                time_trend.columns = ['æ€»æ•°', 'ç—…ä¾‹æ•°']
                time_trend['å‘ç—…ç‡(%)'] = (time_trend['ç—…ä¾‹æ•°'] / time_trend['æ€»æ•°'] * 100).round(2)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.dataframe(time_trend)
                
                with col2:
                    # è¶‹åŠ¿å›¾
                    fig = go.Figure()
                    
                    fig.add_trace(go.Scatter(
                        x=time_trend.index.astype(str),
                        y=time_trend['å‘ç—…ç‡(%)'],
                        mode='lines+markers',
                        name='å‘ç—…ç‡',
                        line=dict(color='red', width=2),
                        marker=dict(size=6)
                    ))
                    
                    fig.update_layout(
                        title=f"{outcome_var}æ—¶é—´è¶‹åŠ¿å›¾",
                        xaxis_title="æ—¶é—´",
                        yaxis_title="å‘ç—…ç‡(%)",
                        height=400
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
        
        else:
            # è¿ç»­ç»“å±€å˜é‡
            time_trend = df.groupby('æ—¶é—´ç»„')[outcome_var].agg([
                'count', 'mean', 'std', 'median'
            ]).round(3)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.dataframe(time_trend)
            
            with col2:
                # è¶‹åŠ¿å›¾
                fig = go.Figure()
                
                fig.add_trace(go.Scatter(
                    x=time_trend.index.astype(str),
                    y=time_trend['mean'],
                    mode='lines+markers',
                    name='å‡å€¼',
                    line=dict(color='blue', width=2),
                    marker=dict(size=6)
                ))
                
                fig.update_layout(
                    title=f"{outcome_var}æ—¶é—´è¶‹åŠ¿å›¾",
                    xaxis_title="æ—¶é—´",
                    yaxis_title=outcome_var,
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        # è¶‹åŠ¿æ£€éªŒ
        perform_trend_test(time_trend, outcome_var)
        
    except Exception as e:
        st.error(f"âŒ æ—¶é—´è¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")

def perform_trend_test(time_trend, outcome_var):
    """æ‰§è¡Œè¶‹åŠ¿æ£€éªŒ"""
    st.markdown("**è¶‹åŠ¿æ£€éªŒç»“æœ:**")
    
    try:
        # Mann-Kendallè¶‹åŠ¿æ£€éªŒ
        if 'å‘ç—…ç‡(%)' in time_trend.columns:
            data_series = time_trend['å‘ç—…ç‡(%)'].dropna()
        elif 'mean' in time_trend.columns:
            data_series = time_trend['mean'].dropna()
        else:
            return
        
        if len(data_series) < 3:
            st.warning("âš ï¸ æ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿æ£€éªŒ")
            return
        
        # ç®€åŒ–çš„Mann-Kendallæ£€éªŒ
        n = len(data_series)
        s = 0
        
        for i in range(n-1):
            for j in range(i+1, n):
                if data_series.iloc[j] > data_series.iloc[i]:
                    s += 1
                elif data_series.iloc[j] < data_series.iloc[i]:
                    s -= 1
        
        # è®¡ç®—æ–¹å·®
        var_s = n * (n - 1) * (2 * n + 5) / 18
        
        # è®¡ç®—Zç»Ÿè®¡é‡
        if s > 0:
            z = (s - 1) / np.sqrt(var_s)
        elif s < 0:
            z = (s + 1) / np.sqrt(var_s)
        else:
            z = 0
        
        # è®¡ç®—på€¼
        p_value = 2 * (1 - stats.norm.cdf(abs(z)))
        
        st.write(f"â€¢ æ£€éªŒæ–¹æ³•: Mann-Kendallè¶‹åŠ¿æ£€éªŒ")
        st.write(f"â€¢ Sç»Ÿè®¡é‡: {s}")
        st.write(f"â€¢ Zç»Ÿè®¡é‡: {z:.4f}")
        st.write(f"â€¢ På€¼: {p_value:.4f}")
        
        if p_value < 0.05:
            if s > 0:
                st.success("âœ… å­˜åœ¨æ˜¾è‘—çš„ä¸Šå‡è¶‹åŠ¿")
            else:
                st.warning("âš ï¸ å­˜åœ¨æ˜¾è‘—çš„ä¸‹é™è¶‹åŠ¿")
        else:
            st.info("â„¹ï¸ æ— æ˜¾è‘—çš„æ—¶é—´è¶‹åŠ¿")
    
    except Exception as e:
        st.warning(f"âš ï¸ è¶‹åŠ¿æ£€éªŒå¤±è´¥: {str(e)}")

def identify_time_variables(df):
    """è¯†åˆ«æ—¶é—´å˜é‡"""
    time_vars = []
    
    for col in df.columns:
        # æ£€æŸ¥åˆ—å
        time_keywords = ['æ—¶é—´', 'æ—¥æœŸ', 'å¹´', 'æœˆ', 'æ—¥', 'date', 'time', 'year', 'month', 'day']
        if any(keyword in col.lower() for keyword in time_keywords):
            time_vars.append(col)
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        elif df[col].dtype in ['datetime64[ns]', 'timedelta64[ns]']:
            time_vars.append(col)
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥è½¬æ¢ä¸ºæ—¥æœŸ
        elif df[col].dtype == 'object':
            try:
                pd.to_datetime(df[col].head(), errors='raise')
                time_vars.append(col)
            except:
                pass
    
    return time_vars

def cohort_study_analysis(df):
    """é˜Ÿåˆ—ç ”ç©¶åˆ†æ"""
    st.markdown("### ğŸ”¬ é˜Ÿåˆ—ç ”ç©¶åˆ†æ")
    st.markdown("*å‰ç»æ€§é˜Ÿåˆ—ç ”ç©¶çš„é£é™©è¯„ä¼°å’Œå› æœæ¨æ–­*")
    
    # å˜é‡é€‰æ‹©
    col1, col2, col3 = st.columns(3)
    
    with col1:
        exposure_var = st.selectbox("é€‰æ‹©æš´éœ²å˜é‡", df.columns.tolist())
    
    with col2:
        outcome_var = st.selectbox("é€‰æ‹©ç»“å±€å˜é‡", df.columns.tolist())
    
    with col3:
        time_var = st.selectbox("é€‰æ‹©éšè®¿æ—¶é—´å˜é‡", df.columns.tolist(), help="éšè®¿æ—¶é—´æˆ–ç”Ÿå­˜æ—¶é—´")
    
    if not all([exposure_var, outcome_var, time_var]):
        return
    
    # åˆ†æç±»å‹é€‰æ‹©
    analysis_type = st.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["é£é™©æ¯”åˆ†æ", "å‘ç—…å¯†åº¦åˆ†æ", "å½’å› é£é™©åˆ†æ", "ç”Ÿå­˜åˆ†æ", "å¤šå› ç´ åˆ†æ"]
    )
    
    if analysis_type == "é£é™©æ¯”åˆ†æ":
        risk_ratio_analysis(df, exposure_var, outcome_var, time_var)
    elif analysis_type == "å‘ç—…å¯†åº¦åˆ†æ":
        incidence_density_analysis(df, exposure_var, outcome_var, time_var)
    elif analysis_type == "å½’å› é£é™©åˆ†æ":
        attributable_risk_analysis(df, exposure_var, outcome_var, time_var)
    elif analysis_type == "ç”Ÿå­˜åˆ†æ":
        cohort_survival_analysis(df, exposure_var, outcome_var, time_var)
    elif analysis_type == "å¤šå› ç´ åˆ†æ":
        multivariable_cohort_analysis(df, exposure_var, outcome_var, time_var)

def risk_ratio_analysis(df, exposure_var, outcome_var, time_var):
    """é£é™©æ¯”åˆ†æ"""
    st.markdown("#### ğŸ“Š é£é™©æ¯”(RR)åˆ†æ")
    
    try:
        # åˆ›å»º2x2è¡¨
        crosstab = pd.crosstab(df[exposure_var], df[outcome_var], margins=True)
        
        st.markdown("##### ğŸ“‹ 2Ã—2åˆ—è”è¡¨")
        st.dataframe(crosstab)
        
        # è®¡ç®—é£é™©æ¯”
        if crosstab.shape == (3, 3):  # åŒ…å«marginsçš„3x3è¡¨
            # æå–2x2æ ¸å¿ƒæ•°æ®
            a = crosstab.iloc[0, 0]  # æš´éœ²+ç»“å±€+
            b = crosstab.iloc[0, 1]  # æš´éœ²+ç»“å±€-
            c = crosstab.iloc[1, 0]  # æš´éœ²-ç»“å±€+
            d = crosstab.iloc[1, 1]  # æš´éœ²-ç»“å±€-
            
            # è®¡ç®—é£é™©
            risk_exposed = a / (a + b)
            risk_unexposed = c / (c + d)
            
            # è®¡ç®—é£é™©æ¯”
            if risk_unexposed > 0:
                rr = risk_exposed / risk_unexposed
            else:
                rr = float('inf')
            
            # è®¡ç®—95%ç½®ä¿¡åŒºé—´
            if a > 0 and c > 0:
                                log_rr = np.log(rr)
                se_log_rr = np.sqrt(1/a - 1/(a+b) + 1/c - 1/(c+d))
                ci_lower = np.exp(log_rr - 1.96 * se_log_rr)
                ci_upper = np.exp(log_rr + 1.96 * se_log_rr)
            else:
                ci_lower, ci_upper = np.nan, np.nan
            
            # æ˜¾ç¤ºç»“æœ
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ“Š é£é™©ä¼°è®¡")
                results_df = pd.DataFrame({
                    'æŒ‡æ ‡': ['æš´éœ²ç»„é£é™©', 'éæš´éœ²ç»„é£é™©', 'é£é™©æ¯”(RR)', '95%CIä¸‹é™', '95%CIä¸Šé™'],
                    'æ•°å€¼': [
                        f"{risk_exposed:.4f} ({risk_exposed*100:.2f}%)",
                        f"{risk_unexposed:.4f} ({risk_unexposed*100:.2f}%)",
                        f"{rr:.4f}",
                        f"{ci_lower:.4f}" if not np.isnan(ci_lower) else "N/A",
                        f"{ci_upper:.4f}" if not np.isnan(ci_upper) else "N/A"
                    ]
                })
                st.dataframe(results_df, hide_index=True)
            
            with col2:
                # é£é™©æ¯”å¯è§†åŒ–
                fig = go.Figure()
                
                # æ·»åŠ é£é™©æ¯”ç‚¹ä¼°è®¡
                fig.add_trace(go.Scatter(
                    x=[rr], y=['é£é™©æ¯”'],
                    mode='markers',
                    marker=dict(size=12, color='red'),
                    name='ç‚¹ä¼°è®¡'
                ))
                
                # æ·»åŠ ç½®ä¿¡åŒºé—´
                if not np.isnan(ci_lower) and not np.isnan(ci_upper):
                    fig.add_trace(go.Scatter(
                        x=[ci_lower, ci_upper], y=['é£é™©æ¯”', 'é£é™©æ¯”'],
                        mode='lines',
                        line=dict(color='red', width=3),
                        name='95%CI'
                    ))
                
                # æ·»åŠ æ— æ•ˆçº¿
                fig.add_vline(x=1, line_dash="dash", line_color="gray")
                
                fig.update_layout(
                    title="é£é™©æ¯”åŠå…¶95%ç½®ä¿¡åŒºé—´",
                    xaxis_title="é£é™©æ¯”",
                    height=300,
                    showlegend=False
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # ç»Ÿè®¡æ£€éªŒ
            perform_rr_test(a, b, c, d)
            
            # ç»“æœè§£é‡Š
            interpret_risk_ratio(rr, ci_lower, ci_upper)
        
        else:
            st.warning("âš ï¸ æ•°æ®æ ¼å¼ä¸é€‚åˆ2Ã—2åˆ†æï¼Œè¯·æ£€æŸ¥æš´éœ²å’Œç»“å±€å˜é‡")
    
    except Exception as e:
        st.error(f"âŒ é£é™©æ¯”åˆ†æå¤±è´¥: {str(e)}")

def perform_rr_test(a, b, c, d):
    """æ‰§è¡Œé£é™©æ¯”çš„ç»Ÿè®¡æ£€éªŒ"""
    st.markdown("##### ğŸ§® ç»Ÿè®¡æ£€éªŒ")
    
    try:
        # å¡æ–¹æ£€éªŒ
        observed = np.array([[a, b], [c, d]])
        chi2, p_value, _, _ = chi2_contingency(observed)
        
        # Fisherç²¾ç¡®æ£€éªŒï¼ˆå¦‚æœæ ·æœ¬é‡å°ï¼‰
        if min(a, b, c, d) < 5:
            _, fisher_p = fisher_exact(observed)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**å¡æ–¹æ£€éªŒ:**")
                st.write(f"â€¢ Ï‡Â² = {chi2:.4f}")
                st.write(f"â€¢ På€¼ = {p_value:.4f}")
            
            with col2:
                st.write("**Fisherç²¾ç¡®æ£€éªŒ:**")
                st.write(f"â€¢ På€¼ = {fisher_p:.4f}")
                
                if fisher_p < 0.05:
                    st.success("âœ… å·®å¼‚å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰")
                else:
                    st.info("â„¹ï¸ å·®å¼‚æ— ç»Ÿè®¡å­¦æ„ä¹‰")
        else:
            st.write("**å¡æ–¹æ£€éªŒ:**")
            st.write(f"â€¢ Ï‡Â² = {chi2:.4f}")
            st.write(f"â€¢ På€¼ = {p_value:.4f}")
            
            if p_value < 0.05:
                st.success("âœ… å·®å¼‚å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰")
            else:
                st.info("â„¹ï¸ å·®å¼‚æ— ç»Ÿè®¡å­¦æ„ä¹‰")
    
    except Exception as e:
        st.warning(f"âš ï¸ ç»Ÿè®¡æ£€éªŒå¤±è´¥: {str(e)}")

def interpret_risk_ratio(rr, ci_lower, ci_upper):
    """è§£é‡Šé£é™©æ¯”ç»“æœ"""
    st.markdown("##### ğŸ’¡ ç»“æœè§£é‡Š")
    
    if np.isnan(rr):
        st.warning("âš ï¸ æ— æ³•è®¡ç®—é£é™©æ¯”")
        return
    
    # åŸºæœ¬è§£é‡Š
    if rr > 1:
        if not np.isnan(ci_lower) and ci_lower > 1:
            st.success(f"âœ… æš´éœ²æ˜¯å±é™©å› ç´ ï¼Œæš´éœ²è€…çš„é£é™©æ˜¯éæš´éœ²è€…çš„ {rr:.2f} å€")
        else:
            st.info(f"â„¹ï¸ æš´éœ²å¯èƒ½æ˜¯å±é™©å› ç´ ï¼Œä½†ç½®ä¿¡åŒºé—´åŒ…å«1ï¼Œéœ€è°¨æ…è§£é‡Š")
    elif rr < 1:
        if not np.isnan(ci_upper) and ci_upper < 1:
            st.success(f"âœ… æš´éœ²æ˜¯ä¿æŠ¤å› ç´ ï¼Œå¯é™ä½ {(1-rr)*100:.1f}% çš„é£é™©")
        else:
            st.info(f"â„¹ï¸ æš´éœ²å¯èƒ½æ˜¯ä¿æŠ¤å› ç´ ï¼Œä½†ç½®ä¿¡åŒºé—´åŒ…å«1ï¼Œéœ€è°¨æ…è§£é‡Š")
    else:
        st.info("â„¹ï¸ æš´éœ²ä¸ç»“å±€æ— å…³è”")
    
    # ä¸´åºŠæ„ä¹‰è¯„ä¼°
    if rr > 2 or rr < 0.5:
        st.warning("âš ï¸ å…³è”å¼ºåº¦è¾ƒå¼ºï¼Œå…·æœ‰é‡è¦çš„ä¸´åºŠæˆ–å…¬å…±å«ç”Ÿæ„ä¹‰")
    elif rr > 1.5 or rr < 0.67:
        st.info("â„¹ï¸ å…³è”å¼ºåº¦ä¸­ç­‰ï¼Œéœ€ç»“åˆå…¶ä»–è¯æ®è¯„ä¼°")
    else:
        st.info("â„¹ï¸ å…³è”å¼ºåº¦è¾ƒå¼±ï¼Œä¸´åºŠæ„ä¹‰æœ‰é™")

def incidence_density_analysis(df, exposure_var, outcome_var, time_var):
    """å‘ç—…å¯†åº¦åˆ†æ"""
    st.markdown("#### ğŸ“ˆ å‘ç—…å¯†åº¦åˆ†æ")
    
    try:
        # æŒ‰æš´éœ²çŠ¶æ€åˆ†ç»„è®¡ç®—å‘ç—…å¯†åº¦
        exposure_groups = df[exposure_var].unique()
        
        density_results = []
        
        for group in exposure_groups:
            group_data = df[df[exposure_var] == group]
            
            # è®¡ç®—ç—…ä¾‹æ•°
            if df[outcome_var].dtype in ['object', 'category']:
                cases = len(group_data[group_data[outcome_var].isin(['æ˜¯', 'æ‚£ç—…', 'Yes', '1', 1])])
            else:
                cases = len(group_data[group_data[outcome_var] == 1])
            
            # è®¡ç®—äººæ—¶
            person_time = group_data[time_var].sum()
            
            # è®¡ç®—å‘ç—…å¯†åº¦
            if person_time > 0:
                incidence_density = cases / person_time
                # è½¬æ¢ä¸ºæ¯1000äººå¹´
                incidence_density_1000 = incidence_density * 1000
            else:
                incidence_density = 0
                incidence_density_1000 = 0
            
            density_results.append({
                'æš´éœ²çŠ¶æ€': group,
                'ç—…ä¾‹æ•°': cases,
                'äººæ—¶': person_time,
                'å‘ç—…å¯†åº¦': incidence_density,
                'å‘ç—…å¯†åº¦(â€°äººå¹´)': incidence_density_1000
            })
        
        # æ˜¾ç¤ºç»“æœ
        density_df = pd.DataFrame(density_results)
        st.dataframe(density_df.round(4))
        
        # è®¡ç®—å‘ç—…å¯†åº¦æ¯”(IDR)
        if len(density_results) == 2:
            idr = density_results[0]['å‘ç—…å¯†åº¦'] / density_results[1]['å‘ç—…å¯†åº¦'] if density_results[1]['å‘ç—…å¯†åº¦'] > 0 else float('inf')
            
            # è®¡ç®—IDRçš„ç½®ä¿¡åŒºé—´
            cases1, cases2 = density_results[0]['ç—…ä¾‹æ•°'], density_results[1]['ç—…ä¾‹æ•°']
            pt1, pt2 = density_results[0]['äººæ—¶'], density_results[1]['äººæ—¶']
            
            if cases1 > 0 and cases2 > 0:
                log_idr = np.log(idr)
                se_log_idr = np.sqrt(1/cases1 + 1/cases2)
                ci_lower = np.exp(log_idr - 1.96 * se_log_idr)
                ci_upper = np.exp(log_idr + 1.96 * se_log_idr)
                
                st.markdown("##### ğŸ“Š å‘ç—…å¯†åº¦æ¯”(IDR)")
                idr_results = pd.DataFrame({
                    'æŒ‡æ ‡': ['å‘ç—…å¯†åº¦æ¯”(IDR)', '95%CIä¸‹é™', '95%CIä¸Šé™'],
                    'æ•°å€¼': [f"{idr:.4f}", f"{ci_lower:.4f}", f"{ci_upper:.4f}"]
                })
                st.dataframe(idr_results, hide_index=True)
                
                # IDRå¯è§†åŒ–
                fig = go.Figure()
                
                fig.add_trace(go.Scatter(
                    x=[idr], y=['å‘ç—…å¯†åº¦æ¯”'],
                    mode='markers',
                    marker=dict(size=12, color='blue'),
                    name='ç‚¹ä¼°è®¡'
                ))
                
                fig.add_trace(go.Scatter(
                    x=[ci_lower, ci_upper], y=['å‘ç—…å¯†åº¦æ¯”', 'å‘ç—…å¯†åº¦æ¯”'],
                    mode='lines',
                    line=dict(color='blue', width=3),
                    name='95%CI'
                ))
                
                fig.add_vline(x=1, line_dash="dash", line_color="gray")
                
                fig.update_layout(
                    title="å‘ç—…å¯†åº¦æ¯”åŠå…¶95%ç½®ä¿¡åŒºé—´",
                    xaxis_title="å‘ç—…å¯†åº¦æ¯”",
                    height=300,
                    showlegend=False
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # è§£é‡Šç»“æœ
                interpret_incidence_density_ratio(idr, ci_lower, ci_upper)
        
        # å‘ç—…å¯†åº¦çš„å¯è§†åŒ–æ¯”è¾ƒ
        fig = px.bar(
            density_df, x='æš´éœ²çŠ¶æ€', y='å‘ç—…å¯†åº¦(â€°äººå¹´)',
            title="ä¸åŒæš´éœ²çŠ¶æ€çš„å‘ç—…å¯†åº¦æ¯”è¾ƒ",
            color='æš´éœ²çŠ¶æ€'
        )
        st.plotly_chart(fig, use_container_width=True)
        
    except Exception as e:
        st.error(f"âŒ å‘ç—…å¯†åº¦åˆ†æå¤±è´¥: {str(e)}")

def interpret_incidence_density_ratio(idr, ci_lower, ci_upper):
    """è§£é‡Šå‘ç—…å¯†åº¦æ¯”ç»“æœ"""
    st.markdown("##### ğŸ’¡ ç»“æœè§£é‡Š")
    
    if idr > 1:
        if ci_lower > 1:
            st.success(f"âœ… æš´éœ²ç»„çš„å‘ç—…å¯†åº¦æ˜¯éæš´éœ²ç»„çš„ {idr:.2f} å€")
        else:
            st.info("â„¹ï¸ æš´éœ²ç»„å‘ç—…å¯†åº¦å¯èƒ½æ›´é«˜ï¼Œä½†ç½®ä¿¡åŒºé—´åŒ…å«1")
    elif idr < 1:
        if ci_upper < 1:
            st.success(f"âœ… æš´éœ²å¯é™ä½å‘ç—…å¯†åº¦ {(1-idr)*100:.1f}%")
        else:
            st.info("â„¹ï¸ æš´éœ²å¯èƒ½é™ä½å‘ç—…å¯†åº¦ï¼Œä½†ç½®ä¿¡åŒºé—´åŒ…å«1")
    else:
        st.info("â„¹ï¸ ä¸¤ç»„å‘ç—…å¯†åº¦ç›¸ä¼¼")

def case_control_analysis(df):
    """ç—…ä¾‹å¯¹ç…§ç ”ç©¶åˆ†æ"""
    st.markdown("### ğŸ¯ ç—…ä¾‹å¯¹ç…§ç ”ç©¶åˆ†æ")
    st.markdown("*å›é¡¾æ€§ç—…ä¾‹å¯¹ç…§ç ”ç©¶çš„æ¯”å€¼æ¯”åˆ†æ*")
    
    # å˜é‡é€‰æ‹©
    col1, col2 = st.columns(2)
    
    with col1:
        case_control_var = st.selectbox("é€‰æ‹©ç—…ä¾‹å¯¹ç…§å˜é‡", df.columns.tolist())
    
    with col2:
        exposure_var = st.selectbox("é€‰æ‹©æš´éœ²å˜é‡", df.columns.tolist())
    
    if not all([case_control_var, exposure_var]):
        return
    
    # åˆ†æç±»å‹
    analysis_type = st.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["æ¯”å€¼æ¯”åˆ†æ", "åŒ¹é…åˆ†æ", "åˆ†å±‚åˆ†æ", "æ¡ä»¶Logisticå›å½’", "å¤šå› ç´ åˆ†æ"]
    )
    
    if analysis_type == "æ¯”å€¼æ¯”åˆ†æ":
        odds_ratio_analysis(df, case_control_var, exposure_var)
    elif analysis_type == "åŒ¹é…åˆ†æ":
        matched_analysis(df, case_control_var, exposure_var)
    elif analysis_type == "åˆ†å±‚åˆ†æ":
        stratified_analysis(df, case_control_var, exposure_var)
    elif analysis_type == "æ¡ä»¶Logisticå›å½’":
        conditional_logistic_analysis(df, case_control_var, exposure_var)
    elif analysis_type == "å¤šå› ç´ åˆ†æ":
        multivariable_case_control_analysis(df, case_control_var, exposure_var)

def odds_ratio_analysis(df, case_control_var, exposure_var):
    """æ¯”å€¼æ¯”åˆ†æ"""
    st.markdown("#### ğŸ“Š æ¯”å€¼æ¯”(OR)åˆ†æ")
    
    try:
        # åˆ›å»º2x2è¡¨
        crosstab = pd.crosstab(df[exposure_var], df[case_control_var], margins=True)
        
        st.markdown("##### ğŸ“‹ 2Ã—2åˆ—è”è¡¨")
        st.dataframe(crosstab)
        
        # è®¡ç®—æ¯”å€¼æ¯”
        if crosstab.shape == (3, 3):
            # æå–2x2æ ¸å¿ƒæ•°æ®
            a = crosstab.iloc[0, 0]  # æš´éœ²+ç—…ä¾‹+
            b = crosstab.iloc[0, 1]  # æš´éœ²+å¯¹ç…§+
            c = crosstab.iloc[1, 0]  # æš´éœ²-ç—…ä¾‹+
            d = crosstab.iloc[1, 1]  # æš´éœ²-å¯¹ç…§+
            
            # è®¡ç®—æ¯”å€¼æ¯”
            if b > 0 and c > 0:
                or_value = (a * d) / (b * c)
            else:
                or_value = float('inf')
            
            # è®¡ç®—95%ç½®ä¿¡åŒºé—´
            if all(x > 0 for x in [a, b, c, d]):
                log_or = np.log(or_value)
                se_log_or = np.sqrt(1/a + 1/b + 1/c + 1/d)
                ci_lower = np.exp(log_or - 1.96 * se_log_or)
                ci_upper = np.exp(log_or + 1.96 * se_log_or)
            else:
                ci_lower, ci_upper = np.nan, np.nan
            
            # æ˜¾ç¤ºç»“æœ
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ“Š æ¯”å€¼æ¯”ä¼°è®¡")
                results_df = pd.DataFrame({
                    'æŒ‡æ ‡': ['æ¯”å€¼æ¯”(OR)', '95%CIä¸‹é™', '95%CIä¸Šé™'],
                    'æ•°å€¼': [
                        f"{or_value:.4f}",
                        f"{ci_lower:.4f}" if not np.isnan(ci_lower) else "N/A",
                        f"{ci_upper:.4f}" if not np.isnan(ci_upper) else "N/A"
                    ]
                })
                st.dataframe(results_df, hide_index=True)
                
                # è®¡ç®—æš´éœ²æ¯”ä¾‹
                exposed_cases = a / (a + c) * 100
                exposed_controls = b / (b + d) * 100
                
                st.write(f"â€¢ ç—…ä¾‹ä¸­æš´éœ²æ¯”ä¾‹: {exposed_cases:.1f}%")
                st.write(f"â€¢ å¯¹ç…§ä¸­æš´éœ²æ¯”ä¾‹: {exposed_controls:.1f}%")
            
            with col2:
                # æ¯”å€¼æ¯”å¯è§†åŒ–
                fig = go.Figure()
                
                fig.add_trace(go.Scatter(
                    x=[or_value], y=['æ¯”å€¼æ¯”'],
                    mode='markers',
                    marker=dict(size=12, color='green'),
                    name='ç‚¹ä¼°è®¡'
                ))
                
                if not np.isnan(ci_lower) and not np.isnan(ci_upper):
                    fig.add_trace(go.Scatter(
                        x=[ci_lower, ci_upper], y=['æ¯”å€¼æ¯”', 'æ¯”å€¼æ¯”'],
                        mode='lines',
                        line=dict(color='green', width=3),
                        name='95%CI'
                    ))
                
                fig.add_vline(x=1, line_dash="dash", line_color="gray")
                
                fig.update_layout(
                    title="æ¯”å€¼æ¯”åŠå…¶95%ç½®ä¿¡åŒºé—´",
                    xaxis_title="æ¯”å€¼æ¯”",
                    height=300,
                    showlegend=False
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # ç»Ÿè®¡æ£€éªŒ
            perform_or_test(a, b, c, d)
            
            # ç»“æœè§£é‡Š
            interpret_odds_ratio(or_value, ci_lower, ci_upper)
        
        else:
            st.warning("âš ï¸ æ•°æ®æ ¼å¼ä¸é€‚åˆ2Ã—2åˆ†æ")
    
    except Exception as e:
        st.error(f"âŒ æ¯”å€¼æ¯”åˆ†æå¤±è´¥: {str(e)}")

def perform_or_test(a, b, c, d):
    """æ‰§è¡Œæ¯”å€¼æ¯”çš„ç»Ÿè®¡æ£€éªŒ"""
    st.markdown("##### ğŸ§® ç»Ÿè®¡æ£€éªŒ")
    
    try:
        observed = np.array([[a, b], [c, d]])
        
        # å¡æ–¹æ£€éªŒ
        chi2, p_chi2, _, _ = chi2_contingency(observed)
        
        # Fisherç²¾ç¡®æ£€éªŒ
        _, p_fisher = fisher_exact(observed)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**å¡æ–¹æ£€éªŒ:**")
            st.write(f"â€¢ Ï‡Â² = {chi2:.4f}")
            st.write(f"â€¢ På€¼ = {p_chi2:.4f}")
        
        with col2:
            st.write("**Fisherç²¾ç¡®æ£€éªŒ:**")
            st.write(f"â€¢ På€¼ = {p_fisher:.4f}")
        
        # é€‰æ‹©åˆé€‚çš„æ£€éªŒç»“æœ
        if min(a, b, c, d) < 5:
            p_value = p_fisher
            test_name = "Fisherç²¾ç¡®æ£€éªŒ"
        else:
            p_value = p_chi2
            test_name = "å¡æ–¹æ£€éªŒ"
        
        if p_value < 0.05:
            st.success(f"âœ… {test_name}æ˜¾ç¤ºå…³è”å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰")
        else:
            st.info(f"â„¹ï¸ {test_name}æ˜¾ç¤ºå…³è”æ— ç»Ÿè®¡å­¦æ„ä¹‰")
    
    except Exception as e:
        st.warning(f"âš ï¸ ç»Ÿè®¡æ£€éªŒå¤±è´¥: {str(e)}")

def interpret_odds_ratio(or_value, ci_lower, ci_upper):
    """è§£é‡Šæ¯”å€¼æ¯”ç»“æœ"""
    st.markdown("##### ğŸ’¡ ç»“æœè§£é‡Š")
    
    if np.isnan(or_value):
        st.warning("âš ï¸ æ— æ³•è®¡ç®—æ¯”å€¼æ¯”")
        return
    
    if or_value > 1:
        if not np.isnan(ci_lower) and ci_lower > 1:
            st.success(f"âœ… æš´éœ²æ˜¯å±é™©å› ç´ ï¼Œæš´éœ²è€…æ‚£ç—…çš„å‡ ç‡æ˜¯éæš´éœ²è€…çš„ {or_value:.2f} å€")
        else:
            st.info("â„¹ï¸ æš´éœ²å¯èƒ½æ˜¯å±é™©å› ç´ ï¼Œä½†ç½®ä¿¡åŒºé—´åŒ…å«1")
    elif or_value < 1:
        if not np.isnan(ci_upper) and ci_upper < 1:
            st.success(f"âœ… æš´éœ²æ˜¯ä¿æŠ¤å› ç´ ï¼Œå¯é™ä½æ‚£ç—…å‡ ç‡ {(1-or_value)*100:.1f}%")
        else:
            st.info("â„¹ï¸ æš´éœ²å¯èƒ½æ˜¯ä¿æŠ¤å› ç´ ï¼Œä½†ç½®ä¿¡åŒºé—´åŒ…å«1")
    else:
        st.info("â„¹ï¸ æš´éœ²ä¸ç–¾ç—…æ— å…³è”")
    
    # å…³è”å¼ºåº¦è¯„ä¼°
    if or_value > 3 or or_value < 0.33:
        st.warning("âš ï¸ å…³è”å¼ºåº¦å¼ºï¼Œå…·æœ‰é‡è¦æ„ä¹‰")
    elif or_value > 2 or or_value < 0.5:
        st.info("â„¹ï¸ å…³è”å¼ºåº¦ä¸­ç­‰")
    else:
        st.info("â„¹ï¸ å…³è”å¼ºåº¦å¼±")

def cross_sectional_analysis(df):
    """æ¨ªæ–­é¢ç ”ç©¶åˆ†æ"""
    st.markdown("### ğŸ“ˆ æ¨ªæ–­é¢ç ”ç©¶åˆ†æ")
    st.markdown("*æ¨ªæ–­é¢ç ”ç©¶çš„æ‚£ç—…ç‡å’Œå…³è”æ€§åˆ†æ*")
    
    # å˜é‡é€‰æ‹©
    col1, col2 = st.columns(2)
    
    with col1:
        outcome_var = st.selectbox("é€‰æ‹©ç–¾ç—…/ç»“å±€å˜é‡", df.columns.tolist())
    
    with col2:
        exposure_var = st.selectbox("é€‰æ‹©æš´éœ²/å±é™©å› ç´ å˜é‡", df.columns.tolist())
    
    if not all([outcome_var, exposure_var]):
        return
    
    # åˆ†æç±»å‹
    analysis_type = st.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["æ‚£ç—…ç‡åˆ†æ", "æ‚£ç—…ç‡æ¯”åˆ†æ", "å…³è”æ€§åˆ†æ", "å¤šå› ç´ åˆ†æ", "è¶‹åŠ¿åˆ†æ"]
    )
    
    if analysis_type == "æ‚£ç—…ç‡åˆ†æ":
        prevalence_analysis(df, outcome_var, exposure_var)
    elif analysis_type == "æ‚£ç—…ç‡æ¯”åˆ†æ":
        prevalence_ratio_analysis(df, outcome_var, exposure_var)
    elif analysis_type == "å…³è”æ€§åˆ†æ":
        cross_sectional_association_analysis(df, outcome_var, exposure_var)
    elif analysis_type == "å¤šå› ç´ åˆ†æ":
        multivariable_cross_sectional_analysis(df, outcome_var, exposure_var)
    elif analysis_type == "è¶‹åŠ¿åˆ†æ":
        cross_sectional_trend_analysis(df, outcome_var, exposure_var)

def prevalence_analysis(df, outcome_var, exposure_var):
    """æ‚£ç—…ç‡åˆ†æ"""
    st.markdown("#### ğŸ“Š æ‚£ç—…ç‡åˆ†æ")
    
    try:
        # æ€»ä½“æ‚£ç—…ç‡
        if df[outcome_var].dtype in ['object', 'category']:
            disease_cases = len(df[df[outcome_var].isin(['æ˜¯', 'æ‚£ç—…', 'Yes', '1', 1])])
        else:
            disease_cases = len(df[df[outcome_var] == 1])
        
        total_subjects = len(df)
        overall_prevalence = disease_cases / total_subjects * 100
        
        st.markdown("##### ğŸ“‹ æ€»ä½“æ‚£ç—…ç‡")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ€»äººæ•°", total_subjects)
        with col2:
            st.metric("æ‚£ç—…äººæ•°", disease_cases)
        with col3:
            st.metric("æ‚£ç—…ç‡", f"{overall_prevalence:.2f}%")
        
        # æŒ‰æš´éœ²çŠ¶æ€åˆ†å±‚çš„æ‚£ç—…ç‡
        st.markdown("##### ğŸ“Š åˆ†å±‚æ‚£ç—…ç‡")
        
        exposure_groups = df[exposure_var].unique()
        prevalence_results = []
        
        for group in exposure_groups:
            group_data = df[df[exposure_var] == group]
            group_total = len(group_data)
            
            if df[outcome_var].dtype in ['object', 'category']:
                group_cases = len(group_data[group_data[outcome_var].isin(['æ˜¯', 'æ‚£ç—…', 'Yes', '1', 1])])
            else:
                group_cases = len(group_data[group_data[outcome_var] == 1])
            
            group_prevalence = group_cases / group_total * 100 if group_total > 0 else 0
            
            # è®¡ç®—95%ç½®ä¿¡åŒºé—´
            if group_total > 0 and group_cases > 0:
                p = group_cases / group_total
                se = np.sqrt(p * (1 - p) / group_total)
                ci_lower = max(0, (p - 1.96 * se) * 100)
                ci_upper = min(100, (p + 1.96 * se) * 100)
            else:
                ci_lower, ci_upper = 0, 0
            
            prevalence_results.append({
                'æš´éœ²çŠ¶æ€': group,
                'æ€»äººæ•°': group_total,
                'æ‚£ç—…äººæ•°': group_cases,
                'æ‚£ç—…ç‡(%)': group_prevalence,
                '95%CIä¸‹é™': ci_lower,
                '95%CIä¸Šé™': ci_upper
            })
        
        prevalence_df = pd.DataFrame(prevalence_results)
        st.dataframe(prevalence_df.round(2))
        
        # æ‚£ç—…ç‡å¯è§†åŒ–
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=prevalence_df['æš´éœ²çŠ¶æ€'],
            y=prevalence_df['æ‚£ç—…ç‡(%)'],
            name='æ‚£ç—…ç‡',
            error_y=dict(
                type='data',
                symmetric=False,
                array=prevalence_df['95%CIä¸Šé™'] - prevalence_df['æ‚£ç—…ç‡(%)'],
                arrayminus=prevalence_df['æ‚£ç—…ç‡(%)'] - prevalence_df['95%CIä¸‹é™']
            )
        ))
        
        fig.update_layout(
            title=f"{outcome_var}åœ¨ä¸åŒ{exposure_var}ä¸­çš„æ‚£ç—…ç‡",
            xaxis_title=exposure_var,
            yaxis_title="æ‚£ç—…ç‡(%)",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # ç»Ÿè®¡æ£€éªŒ
        if len(exposure_groups) >= 2:
            perform_prevalence_test(df, outcome_var, exposure_var)
    
    except Exception as e:
        st.error(f"âŒ æ‚£ç—…ç‡åˆ†æå¤±è´¥: {str(e)}")

def perform_prevalence_test(df, outcome_var, exposure_var):
    """æ‰§è¡Œæ‚£ç—…ç‡å·®å¼‚æ£€éªŒ"""
    st.markdown("##### ğŸ§® æ‚£ç—…ç‡å·®å¼‚æ£€éªŒ")
    
    try:
        # åˆ›å»ºåˆ—è”è¡¨
        crosstab = pd.crosstab(df[exposure_var], df[outcome_var])
        
        # å¡æ–¹æ£€éªŒ
        chi2, p_value, _, _ = chi2_contingency(crosstab)
        
        st.write(f"â€¢ æ£€éªŒæ–¹æ³•: å¡æ–¹æ£€éªŒ")
        st.write(f"â€¢ Ï‡Â² = {chi2:.4f}")
        st.write(f"â€¢ På€¼ = {p_value:.4f}")
        st.write(f"â€¢ è‡ªç”±åº¦ = {(crosstab.shape[0]-1) * (crosstab.shape[1]-1)}")
        
        if p_value < 0.05:
            st.success("âœ… ä¸åŒæš´éœ²çŠ¶æ€é—´æ‚£ç—…ç‡å­˜åœ¨æ˜¾è‘—å·®å¼‚")
        else:
            st.info("â„¹ï¸ ä¸åŒæš´éœ²çŠ¶æ€é—´æ‚£ç—…ç‡æ— æ˜¾è‘—å·®å¼‚")
    
    except Exception as e:
        st.warning(f"âš ï¸ ç»Ÿè®¡æ£€éªŒå¤±è´¥: {str(e)}")

def disease_surveillance(df):
    """ç–¾ç—…ç›‘æµ‹åˆ†æ"""
    st.markdown("### ğŸŒ ç–¾ç—…ç›‘æµ‹åˆ†æ")
    st.markdown("*ç–¾ç—…ç›‘æµ‹æ•°æ®çš„æµè¡Œç—…å­¦åˆ†æ*")
    
    # å˜é‡è¯†åˆ«å’Œé€‰æ‹©
    col1, col2, col3 = st.columns(3)
    
    with col1:
        time_var = st.selectbox("é€‰æ‹©æ—¶é—´å˜é‡", df.columns.tolist())
    
    with col2:
        case_var = st.selectbox("é€‰æ‹©ç—…ä¾‹æ•°å˜é‡", df.columns.tolist())
    
    with col3:
        area_var = st.selectbox("é€‰æ‹©åœ°åŒºå˜é‡", df.columns.tolist(), help="å¯é€‰")
    
    if not all([time_var, case_var]):
        return
    
    # ç›‘æµ‹åˆ†æç±»å‹
        surveillance_type = st.selectbox(
        "é€‰æ‹©ç›‘æµ‹åˆ†æç±»å‹",
        ["æ—¶é—´åºåˆ—åˆ†æ", "ç–«æƒ…é¢„è­¦åˆ†æ", "å‘ç—…ç‡ç›‘æµ‹", "å¼‚å¸¸æ£€æµ‹", "è¶‹åŠ¿é¢„æµ‹"]
    )
    
    if surveillance_type == "æ—¶é—´åºåˆ—åˆ†æ":
        surveillance_time_series(df, time_var, case_var, area_var)
    elif surveillance_type == "ç–«æƒ…é¢„è­¦åˆ†æ":
        outbreak_alert_analysis(df, time_var, case_var, area_var)
    elif surveillance_type == "å‘ç—…ç‡ç›‘æµ‹":
        incidence_surveillance(df, time_var, case_var, area_var)
    elif surveillance_type == "å¼‚å¸¸æ£€æµ‹":
        anomaly_detection(df, time_var, case_var, area_var)
    elif surveillance_type == "è¶‹åŠ¿é¢„æµ‹":
        trend_prediction(df, time_var, case_var, area_var)

def surveillance_time_series(df, time_var, case_var, area_var):
    """ç›‘æµ‹æ—¶é—´åºåˆ—åˆ†æ"""
    st.markdown("#### ğŸ“ˆ æ—¶é—´åºåˆ—åˆ†æ")
    
    try:
        # ç¡®ä¿æ—¶é—´å˜é‡ä¸ºæ—¥æœŸæ ¼å¼
        if df[time_var].dtype != 'datetime64[ns]':
            df[time_var] = pd.to_datetime(df[time_var], errors='coerce')
        
        # æŒ‰æ—¶é—´æ’åº
        df_sorted = df.sort_values(time_var)
        
        # æ—¶é—´èšåˆé€‰æ‹©
        time_unit = st.selectbox("é€‰æ‹©æ—¶é—´èšåˆå•ä½", ["æ—¥", "å‘¨", "æœˆ", "å­£åº¦"])
        
        # æ•°æ®èšåˆ
        if time_unit == "æ—¥":
            df_sorted['æ—¶é—´ç»„'] = df_sorted[time_var].dt.date
        elif time_unit == "å‘¨":
            df_sorted['æ—¶é—´ç»„'] = df_sorted[time_var].dt.to_period('W')
        elif time_unit == "æœˆ":
            df_sorted['æ—¶é—´ç»„'] = df_sorted[time_var].dt.to_period('M')
        elif time_unit == "å­£åº¦":
            df_sorted['æ—¶é—´ç»„'] = df_sorted[time_var].dt.to_period('Q')
        
        # èšåˆç—…ä¾‹æ•°
        if area_var and area_var != time_var:
            # æŒ‰åœ°åŒºå’Œæ—¶é—´èšåˆ
            time_series_data = df_sorted.groupby(['æ—¶é—´ç»„', area_var])[case_var].sum().reset_index()
            
            # å¯è§†åŒ–ä¸åŒåœ°åŒºçš„æ—¶é—´åºåˆ—
            fig = px.line(
                time_series_data, 
                x='æ—¶é—´ç»„', 
                y=case_var, 
                color=area_var,
                title=f"å„åœ°åŒº{case_var}æ—¶é—´åºåˆ—",
                markers=True
            )
            
            fig.update_layout(
                xaxis_title="æ—¶é—´",
                yaxis_title=case_var,
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # æ€»ä½“æ—¶é—´åºåˆ—
            total_series = df_sorted.groupby('æ—¶é—´ç»„')[case_var].sum().reset_index()
            
        else:
            # æ€»ä½“æ—¶é—´åºåˆ—
            total_series = df_sorted.groupby('æ—¶é—´ç»„')[case_var].sum().reset_index()
        
        # æ˜¾ç¤ºæ€»ä½“æ—¶é—´åºåˆ—
        st.markdown("##### ğŸ“Š æ€»ä½“æ—¶é—´åºåˆ—")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.dataframe(total_series.tail(10))
        
        with col2:
            # æ€»ä½“è¶‹åŠ¿å›¾
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=total_series['æ—¶é—´ç»„'].astype(str),
                y=total_series[case_var],
                mode='lines+markers',
                name='ç—…ä¾‹æ•°',
                line=dict(color='red', width=2),
                marker=dict(size=6)
            ))
            
            fig.update_layout(
                title=f"æ€»ä½“{case_var}æ—¶é—´è¶‹åŠ¿",
                xaxis_title="æ—¶é—´",
                yaxis_title=case_var,
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
        
        # æ—¶é—´åºåˆ—ç»Ÿè®¡åˆ†æ
        perform_time_series_analysis(total_series, case_var)
        
    except Exception as e:
        st.error(f"âŒ æ—¶é—´åºåˆ—åˆ†æå¤±è´¥: {str(e)}")

def perform_time_series_analysis(data, case_var):
    """æ‰§è¡Œæ—¶é—´åºåˆ—ç»Ÿè®¡åˆ†æ"""
    st.markdown("##### ğŸ“Š æ—¶é—´åºåˆ—ç»Ÿè®¡ç‰¹å¾")
    
    try:
        values = data[case_var].values
        
        # åŸºæœ¬ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å‡å€¼", f"{np.mean(values):.2f}")
        with col2:
            st.metric("æ ‡å‡†å·®", f"{np.std(values):.2f}")
        with col3:
            st.metric("æœ€å¤§å€¼", f"{np.max(values)}")
        with col4:
            st.metric("æœ€å°å€¼", f"{np.min(values)}")
        
        # è¶‹åŠ¿åˆ†æ
        if len(values) >= 3:
            # ç®€å•çº¿æ€§è¶‹åŠ¿
            x = np.arange(len(values))
            slope, intercept, r_value, p_value, std_err = stats.linregress(x, values)
            
            st.markdown("**è¶‹åŠ¿åˆ†æ:**")
            st.write(f"â€¢ çº¿æ€§è¶‹åŠ¿æ–œç‡: {slope:.4f}")
            st.write(f"â€¢ ç›¸å…³ç³»æ•°: {r_value:.4f}")
            st.write(f"â€¢ På€¼: {p_value:.4f}")
            
            if p_value < 0.05:
                if slope > 0:
                    st.success("âœ… å­˜åœ¨æ˜¾è‘—ä¸Šå‡è¶‹åŠ¿")
                else:
                    st.warning("âš ï¸ å­˜åœ¨æ˜¾è‘—ä¸‹é™è¶‹åŠ¿")
            else:
                st.info("â„¹ï¸ æ— æ˜¾è‘—æ—¶é—´è¶‹åŠ¿")
        
        # å­£èŠ‚æ€§æ£€æµ‹ï¼ˆå¦‚æœæ•°æ®ç‚¹è¶³å¤Ÿï¼‰
        if len(values) >= 12:
            detect_seasonality(values)
    
    except Exception as e:
        st.warning(f"âš ï¸ æ—¶é—´åºåˆ—åˆ†æå¤±è´¥: {str(e)}")

def detect_seasonality(values):
    """æ£€æµ‹å­£èŠ‚æ€§æ¨¡å¼"""
    st.markdown("**å­£èŠ‚æ€§åˆ†æ:**")
    
    try:
        # ç®€å•çš„å­£èŠ‚æ€§æ£€æµ‹ - ä½¿ç”¨è‡ªç›¸å…³
        n = len(values)
        
        # æ£€æµ‹12ä¸ªæœˆçš„å­£èŠ‚æ€§ï¼ˆå¦‚æœæ•°æ®è¶³å¤Ÿï¼‰
        if n >= 24:
            # è®¡ç®—12æœŸæ»åçš„è‡ªç›¸å…³
            lag_12_corr = np.corrcoef(values[:-12], values[12:])[0, 1]
            
            st.write(f"â€¢ 12æœŸæ»åè‡ªç›¸å…³: {lag_12_corr:.4f}")
            
            if abs(lag_12_corr) > 0.3:
                st.success("âœ… æ£€æµ‹åˆ°å¯èƒ½çš„å¹´åº¦å­£èŠ‚æ€§æ¨¡å¼")
            else:
                st.info("â„¹ï¸ æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„å¹´åº¦å­£èŠ‚æ€§")
        
        # æ£€æµ‹å…¶ä»–å‘¨æœŸ
        for lag in [3, 4, 6]:
            if n >= lag * 2:
                corr = np.corrcoef(values[:-lag], values[lag:])[0, 1]
                st.write(f"â€¢ {lag}æœŸæ»åè‡ªç›¸å…³: {corr:.4f}")
    
    except Exception as e:
        st.warning(f"âš ï¸ å­£èŠ‚æ€§æ£€æµ‹å¤±è´¥: {str(e)}")

def outbreak_alert_analysis(df, time_var, case_var, area_var):
    """ç–«æƒ…é¢„è­¦åˆ†æ"""
    st.markdown("#### âš¡ ç–«æƒ…é¢„è­¦åˆ†æ")
    
    try:
        # é¢„è­¦é˜ˆå€¼è®¾ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            threshold_method = st.selectbox(
                "é€‰æ‹©é¢„è­¦é˜ˆå€¼æ–¹æ³•",
                ["å†å²å‡å€¼+2SD", "å†å²å‡å€¼+3SD", "ç™¾åˆ†ä½æ•°æ³•", "è‡ªå®šä¹‰é˜ˆå€¼"]
            )
        
        with col2:
            if threshold_method == "ç™¾åˆ†ä½æ•°æ³•":
                percentile = st.slider("é€‰æ‹©ç™¾åˆ†ä½æ•°", 75, 99, 95)
            elif threshold_method == "è‡ªå®šä¹‰é˜ˆå€¼":
                custom_threshold = st.number_input("è¾“å…¥é¢„è­¦é˜ˆå€¼", value=10.0)
        
        # è®¡ç®—é¢„è­¦é˜ˆå€¼
        historical_data = df[case_var].dropna()
        
        if threshold_method == "å†å²å‡å€¼+2SD":
            threshold = historical_data.mean() + 2 * historical_data.std()
        elif threshold_method == "å†å²å‡å€¼+3SD":
            threshold = historical_data.mean() + 3 * historical_data.std()
        elif threshold_method == "ç™¾åˆ†ä½æ•°æ³•":
            threshold = np.percentile(historical_data, percentile)
        elif threshold_method == "è‡ªå®šä¹‰é˜ˆå€¼":
            threshold = custom_threshold
        
        st.write(f"**é¢„è­¦é˜ˆå€¼: {threshold:.2f}**")
        
        # è¯†åˆ«é¢„è­¦äº‹ä»¶
        df_alert = df.copy()
        if df_alert[time_var].dtype != 'datetime64[ns]':
            df_alert[time_var] = pd.to_datetime(df_alert[time_var], errors='coerce')
        
        df_alert['é¢„è­¦çŠ¶æ€'] = df_alert[case_var] > threshold
        alert_events = df_alert[df_alert['é¢„è­¦çŠ¶æ€'] == True]
        
        # æ˜¾ç¤ºé¢„è­¦ç»Ÿè®¡
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ€»è§‚å¯ŸæœŸæ•°", len(df_alert))
        with col2:
            st.metric("é¢„è­¦æ¬¡æ•°", len(alert_events))
        with col3:
            alert_rate = len(alert_events) / len(df_alert) * 100 if len(df_alert) > 0 else 0
            st.metric("é¢„è­¦ç‡", f"{alert_rate:.1f}%")
        
        # é¢„è­¦äº‹ä»¶åˆ—è¡¨
        if len(alert_events) > 0:
            st.markdown("##### ğŸš¨ é¢„è­¦äº‹ä»¶è¯¦æƒ…")
            
            alert_display = alert_events[[time_var, case_var]]
            if area_var and area_var in alert_events.columns:
                alert_display = alert_events[[time_var, area_var, case_var]]
            
            st.dataframe(alert_display.sort_values(time_var, ascending=False))
        
        # é¢„è­¦æ—¶é—´åºåˆ—å¯è§†åŒ–
        fig = go.Figure()
        
        # æ·»åŠ ç—…ä¾‹æ•°æ—¶é—´åºåˆ—
        fig.add_trace(go.Scatter(
            x=df_alert[time_var],
            y=df_alert[case_var],
            mode='lines+markers',
            name='ç—…ä¾‹æ•°',
            line=dict(color='blue'),
            marker=dict(size=4)
        ))
        
        # æ·»åŠ é¢„è­¦é˜ˆå€¼çº¿
        fig.add_hline(
            y=threshold,
            line_dash="dash",
            line_color="red",
            annotation_text=f"é¢„è­¦é˜ˆå€¼: {threshold:.1f}"
        )
        
        # æ ‡è®°é¢„è­¦ç‚¹
        if len(alert_events) > 0:
            fig.add_trace(go.Scatter(
                x=alert_events[time_var],
                y=alert_events[case_var],
                mode='markers',
                name='é¢„è­¦äº‹ä»¶',
                marker=dict(color='red', size=8, symbol='triangle-up')
            ))
        
        fig.update_layout(
            title="ç–«æƒ…é¢„è­¦ç›‘æµ‹å›¾",
            xaxis_title="æ—¶é—´",
            yaxis_title=case_var,
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # é¢„è­¦æ€§èƒ½è¯„ä¼°
        evaluate_alert_performance(df_alert, case_var, threshold)
        
    except Exception as e:
        st.error(f"âŒ ç–«æƒ…é¢„è­¦åˆ†æå¤±è´¥: {str(e)}")

def evaluate_alert_performance(df, case_var, threshold):
    """è¯„ä¼°é¢„è­¦æ€§èƒ½"""
    st.markdown("##### ğŸ“Š é¢„è­¦æ€§èƒ½è¯„ä¼°")
    
    try:
        # è®¡ç®—é¢„è­¦æ€§èƒ½æŒ‡æ ‡
        true_alerts = len(df[df[case_var] > threshold])
        false_alerts = 0  # ç®€åŒ–å¤„ç†
        missed_alerts = 0  # éœ€è¦çœŸå®ç–«æƒ…æ•°æ®æ¥è®¡ç®—
        
        # æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§ï¼ˆéœ€è¦çœŸå®æ ‡ç­¾ï¼‰
        st.markdown("**é¢„è­¦ç»Ÿè®¡:**")
        st.write(f"â€¢ è§¦å‘é¢„è­¦æ¬¡æ•°: {true_alerts}")
        st.write(f"â€¢ é¢„è­¦è§¦å‘ç‡: {true_alerts/len(df)*100:.1f}%")
        
        # é¢„è­¦é—´éš”åˆ†æ
        alert_dates = df[df[case_var] > threshold].index
        if len(alert_dates) > 1:
            intervals = np.diff(alert_dates)
            avg_interval = np.mean(intervals)
            st.write(f"â€¢ å¹³å‡é¢„è­¦é—´éš”: {avg_interval:.1f} ä¸ªè§‚å¯ŸæœŸ")
        
        # é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ
        st.markdown("**é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ:**")
        
        thresholds = np.linspace(df[case_var].min(), df[case_var].max(), 10)
        alert_rates = []
        
        for t in thresholds:
            rate = len(df[df[case_var] > t]) / len(df) * 100
            alert_rates.append(rate)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=thresholds,
            y=alert_rates,
            mode='lines+markers',
            name='é¢„è­¦ç‡'
        ))
        
        fig.add_vline(x=threshold, line_dash="dash", line_color="red")
        
        fig.update_layout(
            title="é¢„è­¦é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ",
            xaxis_title="é˜ˆå€¼",
            yaxis_title="é¢„è­¦ç‡(%)",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    except Exception as e:
        st.warning(f"âš ï¸ é¢„è­¦æ€§èƒ½è¯„ä¼°å¤±è´¥: {str(e)}")

def screening_test_evaluation(df):
    """ç­›æŸ¥è¯•éªŒè¯„ä»·"""
    st.markdown("### ğŸ“Š ç­›æŸ¥è¯•éªŒè¯„ä»·")
    st.markdown("*è¯Šæ–­è¯•éªŒçš„æ•æ„Ÿæ€§ã€ç‰¹å¼‚æ€§ç­‰æŒ‡æ ‡è¯„ä»·*")
    
    # å˜é‡é€‰æ‹©
    col1, col2 = st.columns(2)
    
    with col1:
        test_result_var = st.selectbox("é€‰æ‹©ç­›æŸ¥è¯•éªŒç»“æœå˜é‡", df.columns.tolist())
    
    with col2:
        gold_standard_var = st.selectbox("é€‰æ‹©é‡‘æ ‡å‡†ç»“æœå˜é‡", df.columns.tolist())
    
    if not all([test_result_var, gold_standard_var]):
        return
    
    # åˆ†æç±»å‹
    evaluation_type = st.selectbox(
        "é€‰æ‹©è¯„ä»·ç±»å‹",
        ["è¯Šæ–­è¯•éªŒè¯„ä»·", "ROCæ›²çº¿åˆ†æ", "å¤šä¸ªè¯•éªŒæ¯”è¾ƒ", "æˆªæ–­å€¼ä¼˜åŒ–", "é¢„æµ‹å€¼åˆ†æ"]
    )
    
    if evaluation_type == "è¯Šæ–­è¯•éªŒè¯„ä»·":
        diagnostic_test_evaluation(df, test_result_var, gold_standard_var)
    elif evaluation_type == "ROCæ›²çº¿åˆ†æ":
        roc_curve_analysis(df, test_result_var, gold_standard_var)
    elif evaluation_type == "å¤šä¸ªè¯•éªŒæ¯”è¾ƒ":
        multiple_tests_comparison(df, test_result_var, gold_standard_var)
    elif evaluation_type == "æˆªæ–­å€¼ä¼˜åŒ–":
        cutoff_optimization(df, test_result_var, gold_standard_var)
    elif evaluation_type == "é¢„æµ‹å€¼åˆ†æ":
        predictive_value_analysis(df, test_result_var, gold_standard_var)

def diagnostic_test_evaluation(df, test_var, gold_var):
    """è¯Šæ–­è¯•éªŒè¯„ä»·"""
    st.markdown("#### ğŸ”¬ è¯Šæ–­è¯•éªŒè¯„ä»·")
    
    try:
        # åˆ›å»º2x2è¡¨
        crosstab = pd.crosstab(df[test_var], df[gold_var], margins=True)
        
        st.markdown("##### ğŸ“‹ è¯Šæ–­è¯•éªŒ2Ã—2è¡¨")
        st.dataframe(crosstab)
        
        # æå–2x2è¡¨æ•°æ®
        if crosstab.shape == (3, 3):
            # å‡è®¾é˜³æ€§ç»“æœåœ¨ç¬¬ä¸€è¡Œ/åˆ—
            a = crosstab.iloc[0, 0]  # çœŸé˜³æ€§
            b = crosstab.iloc[0, 1]  # å‡é˜³æ€§
            c = crosstab.iloc[1, 0]  # å‡é˜´æ€§
            d = crosstab.iloc[1, 1]  # çœŸé˜´æ€§
            
            # è®¡ç®—è¯Šæ–­æŒ‡æ ‡
            sensitivity = a / (a + c) if (a + c) > 0 else 0
            specificity = d / (b + d) if (b + d) > 0 else 0
            ppv = a / (a + b) if (a + b) > 0 else 0  # é˜³æ€§é¢„æµ‹å€¼
            npv = d / (c + d) if (c + d) > 0 else 0  # é˜´æ€§é¢„æµ‹å€¼
            accuracy = (a + d) / (a + b + c + d) if (a + b + c + d) > 0 else 0
            
            # ä¼¼ç„¶æ¯”
            lr_positive = sensitivity / (1 - specificity) if specificity < 1 else float('inf')
            lr_negative = (1 - sensitivity) / specificity if specificity > 0 else float('inf')
            
            # çº¦ç™»æŒ‡æ•°
            youden_index = sensitivity + specificity - 1
            
            # æ˜¾ç¤ºç»“æœ
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("##### ğŸ“Š è¯Šæ–­æ€§èƒ½æŒ‡æ ‡")
                
                metrics_df = pd.DataFrame({
                    'æŒ‡æ ‡': [
                        'æ•æ„Ÿæ€§(Sensitivity)',
                        'ç‰¹å¼‚æ€§(Specificity)', 
                        'é˜³æ€§é¢„æµ‹å€¼(PPV)',
                        'é˜´æ€§é¢„æµ‹å€¼(NPV)',
                        'å‡†ç¡®æ€§(Accuracy)',
                        'é˜³æ€§ä¼¼ç„¶æ¯”(LR+)',
                        'é˜´æ€§ä¼¼ç„¶æ¯”(LR-)',
                        'çº¦ç™»æŒ‡æ•°'
                    ],
                    'æ•°å€¼': [
                        f"{sensitivity:.4f} ({sensitivity*100:.1f}%)",
                        f"{specificity:.4f} ({specificity*100:.1f}%)",
                        f"{ppv:.4f} ({ppv*100:.1f}%)",
                        f"{npv:.4f} ({npv*100:.1f}%)",
                        f"{accuracy:.4f} ({accuracy*100:.1f}%)",
                        f"{lr_positive:.2f}" if lr_positive != float('inf') else "âˆ",
                        f"{lr_negative:.4f}" if lr_negative != float('inf') else "âˆ",
                        f"{youden_index:.4f}"
                    ]
                })
                
                st.dataframe(metrics_df, hide_index=True)
            
            with col2:
                # æ€§èƒ½æŒ‡æ ‡å¯è§†åŒ–
                metrics_viz = ['æ•æ„Ÿæ€§', 'ç‰¹å¼‚æ€§', 'é˜³æ€§é¢„æµ‹å€¼', 'é˜´æ€§é¢„æµ‹å€¼', 'å‡†ç¡®æ€§']
                values_viz = [sensitivity, specificity, ppv, npv, accuracy]
                
                fig = go.Figure()
                
                fig.add_trace(go.Bar(
                    x=metrics_viz,
                    y=values_viz,
                    marker_color=['red', 'blue', 'green', 'orange', 'purple']
                ))
                
                fig.update_layout(
                    title="è¯Šæ–­æ€§èƒ½æŒ‡æ ‡",
                    yaxis_title="æ•°å€¼",
                    yaxis=dict(range=[0, 1]),
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´
            calculate_diagnostic_ci(a, b, c, d, sensitivity, specificity, ppv, npv)
            
            # ç»“æœè§£é‡Š
            interpret_diagnostic_results(sensitivity, specificity, lr_positive, lr_negative)
        
        else:
            st.warning("âš ï¸ æ•°æ®æ ¼å¼ä¸é€‚åˆ2Ã—2åˆ†æ")
    
    except Exception as e:
        st.error(f"âŒ è¯Šæ–­è¯•éªŒè¯„ä»·å¤±è´¥: {str(e)}")

def calculate_diagnostic_ci(a, b, c, d, sensitivity, specificity, ppv, npv):
    """è®¡ç®—è¯Šæ–­æŒ‡æ ‡çš„ç½®ä¿¡åŒºé—´"""
    st.markdown("##### ğŸ“Š 95%ç½®ä¿¡åŒºé—´")
    
    try:
        # æ•æ„Ÿæ€§ç½®ä¿¡åŒºé—´
        if (a + c) > 0:
            sens_ci = proportion_confint(a, a + c, alpha=0.05, method='wilson')
        else:
            sens_ci = (0, 0)
        
        # ç‰¹å¼‚æ€§ç½®ä¿¡åŒºé—´
        if (b + d) > 0:
            spec_ci = proportion_confint(d, b + d, alpha=0.05, method='wilson')
        else:
            spec_ci = (0, 0)
        
        # PPVç½®ä¿¡åŒºé—´
        if (a + b) > 0:
            ppv_ci = proportion_confint(a, a + b, alpha=0.05, method='wilson')
        else:
            ppv_ci = (0, 0)
        
        # NPVç½®ä¿¡åŒºé—´
        if (c + d) > 0:
            npv_ci = proportion_confint(d, c + d, alpha=0.05, method='wilson')
        else:
            npv_ci = (0, 0)
        
        ci_df = pd.DataFrame({
            'æŒ‡æ ‡': ['æ•æ„Ÿæ€§', 'ç‰¹å¼‚æ€§', 'é˜³æ€§é¢„æµ‹å€¼', 'é˜´æ€§é¢„æµ‹å€¼'],
            'ç‚¹ä¼°è®¡': [
                f"{sensitivity:.3f}",
                f"{specificity:.3f}",
                f"{ppv:.3f}",
                f"{npv:.3f}"
            ],
            '95%CIä¸‹é™': [
                f"{sens_ci[0]:.3f}",
                f"{spec_ci[0]:.3f}",
                f"{ppv_ci[0]:.3f}",
                f"{npv_ci[0]:.3f}"
            ],
            '95%CIä¸Šé™': [
                f"{sens_ci[1]:.3f}",
                f"{spec_ci[1]:.3f}",
                f"{ppv_ci[1]:.3f}",
                f"{npv_ci[1]:.3f}"
            ]
        })
        
        st.dataframe(ci_df, hide_index=True)
    
    except ImportError:
        st.warning("âš ï¸ éœ€è¦å®‰è£…statsmodelsåº“è®¡ç®—ç½®ä¿¡åŒºé—´")
    except Exception as e:
        st.warning(f"âš ï¸ ç½®ä¿¡åŒºé—´è®¡ç®—å¤±è´¥: {str(e)}")

def proportion_confint(count, nobs, alpha=0.05, method='wilson'):
    """è®¡ç®—æ¯”ä¾‹çš„ç½®ä¿¡åŒºé—´ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
    p = count / nobs
    z = 1.96  # 95% CI
    
    if method == 'wilson':
        # Wilsonæ–¹æ³•
        n = nobs
        p_adj = (count + z**2/2) / (n + z**2)
        margin = z * np.sqrt(p_adj * (1 - p_adj) / (n + z**2))
        return (max(0, p_adj - margin), min(1, p_adj + margin))
    else:
        # æ­£æ€è¿‘ä¼¼
        se = np.sqrt(p * (1 - p) / nobs)
        margin = z * se
        return (max(0, p - margin), min(1, p + margin))

def interpret_diagnostic_results(sensitivity, specificity, lr_pos, lr_neg):
    """è§£é‡Šè¯Šæ–­ç»“æœ"""
    st.markdown("##### ğŸ’¡ ç»“æœè§£é‡Š")
    
    # æ•æ„Ÿæ€§è§£é‡Š
    if sensitivity >= 0.9:
        st.success(f"âœ… æ•æ„Ÿæ€§ä¼˜ç§€({sensitivity*100:.1f}%)ï¼Œèƒ½å¾ˆå¥½åœ°è¯†åˆ«æ‚£ç—…è€…")
    elif sensitivity >= 0.8:
        st.info(f"â„¹ï¸ æ•æ„Ÿæ€§è‰¯å¥½({sensitivity*100:.1f}%)ï¼Œèƒ½è¾ƒå¥½åœ°è¯†åˆ«æ‚£ç—…è€…")
    else:
        st.warning(f"âš ï¸ æ•æ„Ÿæ€§è¾ƒä½({sensitivity*100:.1f}%)ï¼Œå¯èƒ½é—æ¼è¾ƒå¤šæ‚£ç—…è€…")
    
    # ç‰¹å¼‚æ€§è§£é‡Š
    if specificity >= 0.9:
        st.success(f"âœ… ç‰¹å¼‚æ€§ä¼˜ç§€({specificity*100:.1f}%)ï¼Œèƒ½å¾ˆå¥½åœ°æ’é™¤éæ‚£ç—…è€…")
    elif specificity >= 0.8:
        st.info(f"â„¹ï¸ ç‰¹å¼‚æ€§è‰¯å¥½({specificity*100:.1f}%)ï¼Œèƒ½è¾ƒå¥½åœ°æ’é™¤éæ‚£ç—…è€…")
    else:
        st.warning(f"âš ï¸ ç‰¹å¼‚æ€§è¾ƒä½({specificity*100:.1f}%)ï¼Œå¯èƒ½è¯¯è¯Šè¾ƒå¤šéæ‚£ç—…è€…")
    
    # ä¼¼ç„¶æ¯”è§£é‡Š
    if lr_pos > 10:
        st.success(f"âœ… é˜³æ€§ä¼¼ç„¶æ¯”å¾ˆé«˜({lr_pos:.1f})ï¼Œé˜³æ€§ç»“æœæœ‰å¾ˆå¼ºçš„è¯Šæ–­ä»·å€¼")
    elif lr_pos > 5:
        st.info(f"â„¹ï¸ é˜³æ€§ä¼¼ç„¶æ¯”è¾ƒé«˜({lr_pos:.1f})ï¼Œé˜³æ€§ç»“æœæœ‰ä¸€å®šè¯Šæ–­ä»·å€¼")
    elif lr_pos > 2:
        st.info(f"â„¹ï¸ é˜³æ€§ä¼¼ç„¶æ¯”ä¸­ç­‰({lr_pos:.1f})ï¼Œé˜³æ€§ç»“æœæœ‰è½»å¾®è¯Šæ–­ä»·å€¼")
    else:
        st.warning(f"âš ï¸ é˜³æ€§ä¼¼ç„¶æ¯”è¾ƒä½({lr_pos:.1f})ï¼Œé˜³æ€§ç»“æœè¯Šæ–­ä»·å€¼æœ‰é™")
    
    if lr_neg < 0.1:
        st.success(f"âœ… é˜´æ€§ä¼¼ç„¶æ¯”å¾ˆä½({lr_neg:.3f})ï¼Œé˜´æ€§ç»“æœèƒ½å¾ˆå¥½åœ°æ’é™¤ç–¾ç—…")
    elif lr_neg < 0.2:
        st.info(f"â„¹ï¸ é˜´æ€§ä¼¼ç„¶æ¯”è¾ƒä½({lr_neg:.3f})ï¼Œé˜´æ€§ç»“æœèƒ½è¾ƒå¥½åœ°æ’é™¤ç–¾ç—…")
    elif lr_neg < 0.5:
        st.info(f"â„¹ï¸ é˜´æ€§ä¼¼ç„¶æ¯”ä¸­ç­‰({lr_neg:.3f})ï¼Œé˜´æ€§ç»“æœæœ‰ä¸€å®šæ’é™¤ä»·å€¼")
    else:
        st.warning(f"âš ï¸ é˜´æ€§ä¼¼ç„¶æ¯”è¾ƒé«˜({lr_neg:.3f})ï¼Œé˜´æ€§ç»“æœæ’é™¤ä»·å€¼æœ‰é™")

# ä¸»å‡½æ•°è°ƒç”¨
if __name__ == "__main__":
    epidemiology_analysis()


