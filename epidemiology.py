import streamlit as st
import pandas as pd
import numpy as np
import scipy.stats as stats
from scipy.stats import chi2_contingency, fisher_exact
import plotly.express as px
import plotly.graph_objects as go

def epidemiology_ui():
    st.header("ğŸ¦  æµè¡Œç—…å­¦åˆ†æ")
    
    # åˆ†æç±»å‹é€‰æ‹©
    analysis_type = st.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹",
        ["ç ”ç©¶è®¾è®¡", "é˜Ÿåˆ—ç ”ç©¶åˆ†æ", "ç—…ä¾‹å¯¹ç…§ç ”ç©¶åˆ†æ", "æ¨ªæ–­é¢ç ”ç©¶åˆ†æ"]
    )
    
    if analysis_type == "ç ”ç©¶è®¾è®¡":
        study_design_ui()
    elif analysis_type == "é˜Ÿåˆ—ç ”ç©¶åˆ†æ":
        cohort_study_analysis()
    elif analysis_type == "ç—…ä¾‹å¯¹ç…§ç ”ç©¶åˆ†æ":
        case_control_analysis()
    elif analysis_type == "æ¨ªæ–­é¢ç ”ç©¶åˆ†æ":
        cross_sectional_analysis()

def study_design_ui():
    st.subheader("ğŸ“‹ æµè¡Œç—…å­¦ç ”ç©¶è®¾è®¡")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ç ”ç©¶ç±»å‹é€‰æ‹©**")
        study_type = st.selectbox(
            "é€‰æ‹©ç ”ç©¶ç±»å‹",
            ["æ¨ªæ–­é¢ç ”ç©¶", "é˜Ÿåˆ—ç ”ç©¶", "ç—…ä¾‹å¯¹ç…§ç ”ç©¶", "ä¸´åºŠè¯•éªŒ"]
        )
        
        if study_type == "é˜Ÿåˆ—ç ”ç©¶":
            st.write("**é˜Ÿåˆ—ç ”ç©¶å‚æ•°**")
            follow_up_time = st.number_input("éšè®¿æ—¶é—´ï¼ˆå¹´ï¼‰", value=5.0, min_value=0.1, max_value=50.0)
            expected_incidence = st.number_input("é¢„æœŸå‘ç—…ç‡ï¼ˆ%ï¼‰", value=10.0, min_value=0.1, max_value=100.0)
            
        elif study_type == "ç—…ä¾‹å¯¹ç…§ç ”ç©¶":
            st.write("**ç—…ä¾‹å¯¹ç…§ç ”ç©¶å‚æ•°**")
            case_control_ratio = st.number_input("å¯¹ç…§ä¸ç—…ä¾‹æ¯”ä¾‹", value=1, min_value=1, max_value=10)
            expected_or = st.number_input("é¢„æœŸæ¯”å€¼æ¯”", value=2.0, min_value=0.1, max_value=10.0)
    
    with col2:
        st.write("**æ ·æœ¬é‡ä¼°ç®—**")
        alpha = st.number_input("Î±æ°´å¹³", value=0.05, min_value=0.01, max_value=0.1, step=0.01)
        power = st.number_input("æ£€éªŒæ•ˆèƒ½(1-Î²)", value=0.8, min_value=0.5, max_value=0.99, step=0.01)
        
        if st.button("ğŸ”¢ è®¡ç®—æ ·æœ¬é‡", type="primary"):
            try:
                if study_type == "é˜Ÿåˆ—ç ”ç©¶":
                    sample_size = calculate_cohort_sample_size(
                        expected_incidence/100, alpha, power, follow_up_time
                    )
                elif study_type == "ç—…ä¾‹å¯¹ç…§ç ”ç©¶":
                    sample_size = calculate_case_control_sample_size(
                        expected_or, alpha, power, case_control_ratio
                    )
                else:
                    sample_size = calculate_cross_sectional_sample_size(alpha, power)
                
                display_sample_size_results(sample_size, study_type)
                
            except Exception as e:
                st.error(f"è®¡ç®—å¤±è´¥: {str(e)}")

def calculate_cohort_sample_size(incidence_rate, alpha, power, follow_up_time):
    """è®¡ç®—é˜Ÿåˆ—ç ”ç©¶æ ·æœ¬é‡"""
    from scipy.stats import norm
    
    z_alpha = norm.ppf(1 - alpha/2)
    z_beta = norm.ppf(power)
    
    # ç®€åŒ–çš„æ ·æœ¬é‡è®¡ç®—
    n = ((z_alpha + z_beta)**2 * (1 + 1/incidence_rate)) / (np.log(2)**2)
    n = int(np.ceil(n))
    
    return {
        'total_sample_size': n,
        'exposed_group': n // 2,
        'unexposed_group': n // 2,
        'details': {
            'é¢„æœŸå‘ç—…ç‡': f"{incidence_rate*100:.1f}%",
            'éšè®¿æ—¶é—´': f"{follow_up_time}å¹´",
            'Î±æ°´å¹³': alpha,
            'æ£€éªŒæ•ˆèƒ½': power
        }
    }

def calculate_case_control_sample_size(odds_ratio, alpha, power, ratio):
    """è®¡ç®—ç—…ä¾‹å¯¹ç…§ç ”ç©¶æ ·æœ¬é‡"""
    from scipy.stats import norm
    
    z_alpha = norm.ppf(1 - alpha/2)
    z_beta = norm.ppf(power)
    
    # å‡è®¾æš´éœ²ç‡ä¸º30%
    p1 = 0.3
    p2 = (odds_ratio * p1) / (1 + p1 * (odds_ratio - 1))
    
    n_cases = ((z_alpha + z_beta)**2 * (1/p1 + 1/p2 + 1/(ratio*p1) + 1/(ratio*p2))) / ((p2 - p1)**2)
    n_cases = int(np.ceil(n_cases))
    n_controls = n_cases * ratio
    
    return {
        'total_sample_size': n_cases + n_controls,
        'cases': n_cases,
        'controls': n_controls,
        'details': {
            'é¢„æœŸæ¯”å€¼æ¯”': odds_ratio,
            'å¯¹ç…§ç—…ä¾‹æ¯”': f"{ratio}:1",
            'Î±æ°´å¹³': alpha,
            'æ£€éªŒæ•ˆèƒ½': power
        }
    }

def calculate_cross_sectional_sample_size(alpha, power):
    """è®¡ç®—æ¨ªæ–­é¢ç ”ç©¶æ ·æœ¬é‡"""
    from scipy.stats import norm
    
    z_alpha = norm.ppf(1 - alpha/2)
    z_beta = norm.ppf(power)
    
    # å‡è®¾æ‚£ç—…ç‡ä¸º15%
    prevalence = 0.15
    n = ((z_alpha + z_beta)**2 * prevalence * (1 - prevalence)) / (0.05**2)
    n = int(np.ceil(n))
    
    return {
        'total_sample_size': n,
        'details': {
            'é¢„æœŸæ‚£ç—…ç‡': f"{prevalence*100:.1f}%",
            'ç²¾åº¦': "Â±5%",
            'Î±æ°´å¹³': alpha,
            'æ£€éªŒæ•ˆèƒ½': power
        }
    }

def display_sample_size_results(results, study_type):
    """æ˜¾ç¤ºæ ·æœ¬é‡è®¡ç®—ç»“æœ"""
    
    st.subheader("ğŸ“Š æ ·æœ¬é‡è®¡ç®—ç»“æœ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ€»æ ·æœ¬é‡", results['total_sample_size'])
    
    if study_type == "é˜Ÿåˆ—ç ”ç©¶":
        with col2:
            st.metric("æš´éœ²ç»„", results['exposed_group'])
        with col3:
            st.metric("éæš´éœ²ç»„", results['unexposed_group'])
    elif study_type == "ç—…ä¾‹å¯¹ç…§ç ”ç©¶":
        with col2:
            st.metric("ç—…ä¾‹æ•°", results['cases'])
        with col3:
            st.metric("å¯¹ç…§æ•°", results['controls'])
    
    st.write("**è¯¦ç»†ä¿¡æ¯:**")
    for key, value in results['details'].items():
        st.write(f"- **{key}:** {value}")

def cohort_study_analysis():
    st.subheader("ğŸ‘¥ é˜Ÿåˆ—ç ”ç©¶åˆ†æ")
    
    if st.session_state.cleaned_data is None:
        st.warning("è¯·å…ˆå¯¼å…¥å¹¶æ¸…ç†æ•°æ®")
        return
    
    df = st.session_state.cleaned_data
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.write("**å˜é‡é€‰æ‹©**")
        
        # æš´éœ²å˜é‡
        categorical_vars = df.select_dtypes(include=['object', 'category']).columns.tolist()
        exposure_var = st.selectbox("æš´éœ²å˜é‡", ["è¯·é€‰æ‹©"] + categorical_vars)
        
        # ç»“å±€å˜é‡
        outcome_var = st.selectbox("ç»“å±€å˜é‡", ["è¯·é€‰æ‹©"] + categorical_vars)
        
        # æ—¶é—´å˜é‡ï¼ˆå¯é€‰ï¼‰
        numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
        time_var = st.selectbox("æ—¶é—´å˜é‡ï¼ˆå¯é€‰ï¼‰", ["æ— "] + numeric_vars)
        
        run_cohort = st.button("ğŸš€ è¿è¡Œé˜Ÿåˆ—åˆ†æ", type="primary")
    
    with col2:
        if run_cohort and exposure_var != "è¯·é€‰æ‹©" and outcome_var != "è¯·é€‰æ‹©":
            try:
                results = perform_cohort_analysis(df, exposure_var, outcome_var, time_var)
                display_cohort_results(results, exposure_var, outcome_var)
                
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {str(e)}")

def perform_cohort_analysis(df, exposure_var, outcome_var, time_var):
    """æ‰§è¡Œé˜Ÿåˆ—ç ”ç©¶åˆ†æ"""
    
    # åˆ›å»º2x2è¡¨
    crosstab = pd.crosstab(df[exposure_var], df[outcome_var], margins=True)
    
    # è·å–å››æ ¼è¡¨æ•°æ®
    exposed_outcome = crosstab.iloc[1, 1]  # a
    exposed_no_outcome = crosstab.iloc[1, 0]  # b
    unexposed_outcome = crosstab.iloc[0, 1]  # c
    unexposed_no_outcome = crosstab.iloc[0, 0]  # d
    
    # è®¡ç®—å‘ç—…ç‡
    incidence_exposed = exposed_outcome / (exposed_outcome + exposed_no_outcome)
    incidence_unexposed = unexposed_outcome / (unexposed_outcome + unexposed_no_outcome)
    
    # è®¡ç®—ç›¸å¯¹å±é™©åº¦(RR)
    relative_risk = incidence_exposed / incidence_unexposed if incidence_unexposed > 0 else np.inf
    
    # è®¡ç®—å½’å› å±é™©åº¦(AR)
    attributable_risk = incidence_exposed - incidence_unexposed
    
    # è®¡ç®—å½’å› å±é™©åº¦ç™¾åˆ†æ¯”(AR%)
    attributable_risk_percent = (attributable_risk / incidence_exposed) * 100 if incidence_exposed > 0 else 0
    
    # è®¡ç®—äººç¾¤å½’å› å±é™©åº¦(PAR)
    total_incidence = crosstab.iloc[2, 1] / crosstab.iloc[2, 2]
    population_attributable_risk = total_incidence - incidence_unexposed
    
    # è®¡ç®—äººç¾¤å½’å› å±é™©åº¦ç™¾åˆ†æ¯”(PAR%)
    population_attributable_risk_percent = (population_attributable_risk / total_incidence) * 100 if total_incidence > 0 else 0
    
    # å¡æ–¹æ£€éªŒ
    chi2, p_value, dof, expected = chi2_contingency(crosstab.iloc[:-1, :-1])
    
    # è®¡ç®—95%ç½®ä¿¡åŒºé—´ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    rr_ci_lower = relative_risk * np.exp(-1.96 * np.sqrt(1/exposed_outcome + 1/unexposed_outcome - 1/(exposed_outcome + exposed_no_outcome) - 1/(unexposed_outcome + unexposed_no_outcome)))
    rr_ci_upper = relative_risk * np.exp(1.96 * np.sqrt(1/exposed_outcome + 1/unexposed_outcome - 1/(exposed_outcome + exposed_no_outcome) - 1/(unexposed_outcome + unexposed_no_outcome)))
    
    results = {
        'crosstab': crosstab,
        'incidence_exposed': incidence_exposed,
        'incidence_unexposed': incidence_unexposed,
        'relative_risk': relative_risk,
        'rr_ci': (rr_ci_lower, rr_ci_upper),
        'attributable_risk': attributable_risk,
        'attributable_risk_percent': attributable_risk_percent,
        'population_attributable_risk': population_attributable_risk,
        'population_attributable_risk_percent': population_attributable_risk_percent,
        'chi2_test': {'chi2': chi2, 'p_value': p_value}
    }
    
    return results

def display_cohort_results(results, exposure_var, outcome_var):
    """æ˜¾ç¤ºé˜Ÿåˆ—ç ”ç©¶ç»“æœ"""
    
    # 2x2è¡¨
    st.write("**2Ã—2åˆ—è”è¡¨**")
    st.dataframe(results['crosstab'])
    
    # ä¸»è¦æŒ‡æ ‡
    st.write("**ä¸»è¦æµè¡Œç—…å­¦æŒ‡æ ‡**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æš´éœ²ç»„å‘ç—…ç‡", f"{results['incidence_exposed']:.4f}")
        st.metric("éæš´éœ²ç»„å‘ç—…ç‡", f"{results['incidence_unexposed']:.4f}")
    
    with col2:
        st.metric("ç›¸å¯¹å±é™©åº¦(RR)", f"{results['relative_risk']:.4f}")
        st.write(f"95%CI: ({results['rr_ci'][0]:.4f}, {results['rr_ci'][1]:.4f})")
        
    with col3:
        st.metric("å½’å› å±é™©åº¦(AR)", f"{results['attributable_risk']:.4f}")
        st.metric("å½’å› å±é™©åº¦%", f"{results['attributable_risk_percent']:.2f}%")
    
    # äººç¾¤æŒ‡æ ‡
    st.write("**äººç¾¤æ°´å¹³æŒ‡æ ‡**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("äººç¾¤å½’å› å±é™©åº¦(PAR)", f"{results['population_attributable_risk']:.4f}")
    
    with col2:
        st.metric("äººç¾¤å½’å› å±é™©åº¦%(PAR%)", f"{results['population_attributable_risk_percent']:.2f}%")
    
    # ç»Ÿè®¡æ£€éªŒ
    st.write("**ç»Ÿè®¡æ£€éªŒ**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("å¡æ–¹ç»Ÿè®¡é‡", f"{results['chi2_test']['chi2']:.4f}")
    
    with col2:
        st.metric("På€¼", f"{results['chi2_test']['p_value']:.4f}")
    
    with col3:
        significance = "æ˜¾è‘—" if results['chi2_test']['p_value'] < 0.05 else "ä¸æ˜¾è‘—"
        st.metric("ç»Ÿè®¡å­¦æ„ä¹‰", significance)

def case_control_analysis():
    st.subheader("ğŸ” ç—…ä¾‹å¯¹ç…§ç ”ç©¶åˆ†æ")
    
    if st.session_state.cleaned_data is None:
        st.warning("è¯·å…ˆå¯¼å…¥å¹¶æ¸…ç†æ•°æ®")
        return
    
    df = st.session_state.cleaned_data
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.write("**å˜é‡é€‰æ‹©**")
        
        # ç—…ä¾‹å¯¹ç…§å˜é‡
        categorical_vars = df.select_dtypes(include=['object', 'category']).columns.tolist()
        case_control_var = st.selectbox("ç—…ä¾‹å¯¹ç…§å˜é‡", ["è¯·é€‰æ‹©"] + categorical_vars)
        
        # æš´éœ²å˜é‡
        exposure_var = st.selectbox("æš´éœ²å˜é‡", ["è¯·é€‰æ‹©"] + categorical_vars, key="cc_exposure")
        
        # åŒ¹é…å˜é‡ï¼ˆå¯é€‰ï¼‰
        matching_vars = st.multiselect("åŒ¹é…å˜é‡ï¼ˆå¯é€‰ï¼‰", categorical_vars)
        
        run_case_control = st.button("ğŸš€ è¿è¡Œç—…ä¾‹å¯¹ç…§åˆ†æ", type="primary")
    
    with col2:
        if run_case_control and case_control_var != "è¯·é€‰æ‹©" and exposure_var != "è¯·é€‰æ‹©":
            try:
                results = perform_case_control_analysis(df, case_control_var, exposure_var, matching_vars)
                display_case_control_results(results, case_control_var, exposure_var)
                
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {str(e)}")

def perform_case_control_analysis(df, case_control_var, exposure_var, matching_vars):
    """æ‰§è¡Œç—…ä¾‹å¯¹ç…§ç ”ç©¶åˆ†æ"""
    
    # åˆ›å»º2x2è¡¨
    crosstab = pd.crosstab(df[case_control_var], df[exposure_var], margins=True)
    
    # è·å–å››æ ¼è¡¨æ•°æ®ï¼ˆå‡è®¾ç—…ä¾‹ä¸ºç¬¬äºŒä¸ªç±»åˆ«ï¼Œæš´éœ²ä¸ºç¬¬äºŒä¸ªç±»åˆ«ï¼‰
    case_exposed = crosstab.iloc[1, 1]  # a
    case_unexposed = crosstab.iloc[1, 0]  # b
    control_exposed = crosstab.iloc[0, 1]  # c
    control_unexposed = crosstab.iloc[0, 0]  # d
    
    # è®¡ç®—æ¯”å€¼æ¯”(OR)
    odds_ratio = (case_exposed * control_unexposed) / (case_unexposed * control_exposed) if (case_unexposed * control_exposed) > 0 else np.inf
    
    # è®¡ç®—95%ç½®ä¿¡åŒºé—´
    log_or = np.log(odds_ratio) if odds_ratio > 0 and odds_ratio != np.inf else 0
    se_log_or = np.sqrt(1/case_exposed + 1/case_unexposed + 1/control_exposed + 1/control_unexposed) if all(x > 0 for x in [case_exposed, case_unexposed, control_exposed, control_unexposed]) else 0
    
    or_ci_lower = np.exp(log_or - 1.96 * se_log_or)
    or_ci_upper = np.exp(log_or + 1.96 * se_log_or)
    
    # è®¡ç®—æš´éœ²ç‡
    exposure_rate_cases = case_exposed / (case_exposed + case_unexposed)
    exposure_rate_controls = control_exposed / (control_exposed + control_unexposed)
    
    # ç»Ÿè®¡æ£€éªŒ
    if crosstab.iloc[:-1, :-1].shape == (2, 2):
        # Fisherç²¾ç¡®æ£€éªŒ
        oddsratio_fisher, p_value_fisher = fisher_exact(crosstab.iloc[:-1, :-1])
        
        # å¡æ–¹æ£€éªŒ
        chi2, p_value_chi2, dof, expected = chi2_contingency(crosstab.iloc[:-1, :-1])
    else:
        p_value_fisher = np.nan
        chi2, p_value_chi2 = np.nan, np.nan
    
    results = {
        'crosstab': crosstab,
        'odds_ratio': odds_ratio,
        'or_ci': (or_ci_lower, or_ci_upper),
        'exposure_rate_cases': exposure_rate_cases,
        'exposure_rate_controls': exposure_rate_controls,
        'fisher_test': {'p_value': p_value_fisher},
        'chi2_test': {'chi2': chi2, 'p_value': p_value_chi2}
    }
    
    return results

def display_case_control_results(results, case_control_var, exposure_var):
    """æ˜¾ç¤ºç—…ä¾‹å¯¹ç…§ç ”ç©¶ç»“æœ"""
    
    # 2x2è¡¨
    st.write("**2Ã—2åˆ—è”è¡¨**")
    st.dataframe(results['crosstab'])
    
    # ä¸»è¦æŒ‡æ ‡
    st.write("**ä¸»è¦æµè¡Œç—…å­¦æŒ‡æ ‡**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ç—…ä¾‹ç»„æš´éœ²ç‡", f"{results['exposure_rate_cases']:.4f}")
        st.metric("å¯¹ç…§ç»„æš´éœ²ç‡", f"{results['exposure_rate_controls']:.4f}")
    
    with col2:
        st.metric("æ¯”å€¼æ¯”(OR)", f"{results['odds_ratio']:.4f}")
        st.write(f"95%CI: ({results['or_ci'][0]:.4f}, {results['or_ci'][1]:.4f})")
    
    with col3:
        # ORè§£é‡Š
        if results['odds_ratio'] > 1:
            interpretation = "æš´éœ²å¢åŠ ç–¾ç—…é£é™©"
        elif results['odds_ratio'] < 1:
            interpretation = "æš´éœ²é™ä½ç–¾ç—…é£é™©"
        else:
            interpretation = "æš´éœ²ä¸ç–¾ç—…æ— å…³è”"
        
        st.metric("å…³è”å¼ºåº¦", interpretation)
    
    # ç»Ÿè®¡æ£€éªŒ
    st.write("**ç»Ÿè®¡æ£€éªŒ**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Fisherç²¾ç¡®æ£€éªŒPå€¼", f"{results['fisher_test']['p_value']:.4f}" if not np.isnan(results['fisher_test']['p_value']) else "N/A")
    
    with col2:
        st.metric("å¡æ–¹ç»Ÿè®¡é‡", f"{results['chi2_test']['chi2']:.4f}" if not np.isnan(results['chi2_test']['chi2']) else "N/A")
    
    with col3:
        st.metric("å¡æ–¹æ£€éªŒPå€¼", f"{results['chi2_test']['p_value']:.4f}" if not np.isnan(results['chi2_test']['p_value']) else "N/A")
    
    with col4:
        p_val = results['fisher_test']['p_value'] if not np.isnan(results['fisher_test']['p_value']) else results['chi2_test']['p_value']
        significance = "æ˜¾è‘—" if not np.isnan(p_val) and p_val < 0.05 else "ä¸æ˜¾è‘—"
        st.metric("ç»Ÿè®¡å­¦æ„ä¹‰", significance)

def cross_sectional_analysis():
    st.subheader("ğŸ“Š æ¨ªæ–­é¢ç ”ç©¶åˆ†æ")
    
    if st.session_state.cleaned_data is None:
        st.warning("è¯·å…ˆå¯¼å…¥å¹¶æ¸…ç†æ•°æ®")
        return
    
    df = st.session_state.cleaned_data
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.write("**å˜é‡é€‰æ‹©**")
        
        # ç–¾ç—…/ç»“å±€å˜é‡
        categorical_vars = df.select_dtypes(include=['object', 'category']).columns.tolist()
        disease_var = st.selectbox("ç–¾ç—…/ç»“å±€å˜é‡", ["è¯·é€‰æ‹©"] + categorical_vars)
        
        # æš´éœ²/å±é™©å› ç´ å˜é‡
        exposure_var = st.selectbox("æš´éœ²/å±é™©å› ç´ å˜é‡", ["è¯·é€‰æ‹©"] + categorical_vars, key="cs_exposure")
        
        # åˆ†å±‚å˜é‡ï¼ˆå¯é€‰ï¼‰
        stratify_var = st.selectbox("åˆ†å±‚å˜é‡ï¼ˆå¯é€‰ï¼‰", ["æ— "] + categorical_vars)
        
        run_cross_sectional = st.button("ğŸš€ è¿è¡Œæ¨ªæ–­é¢åˆ†æ", type="primary")
    
    with col2:
        if run_cross_sectional and disease_var != "è¯·é€‰æ‹©" and exposure_var != "è¯·é€‰æ‹©":
            try:
                results = perform_cross_sectional_analysis(df, disease_var, exposure_var, stratify_var)
                display_cross_sectional_results(results, disease_var, exposure_var)
                
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {str(e)}")

def perform_cross_sectional_analysis(df, disease_var, exposure_var, stratify_var):
    """æ‰§è¡Œæ¨ªæ–­é¢ç ”ç©¶åˆ†æ"""
    
    results = {
        'overall': {},
        'stratified': {}
    }
    
    # æ€»ä½“åˆ†æ
    crosstab = pd.crosstab(df[exposure_var], df[disease_var], margins=True)
    
    # è®¡ç®—æ‚£ç—…ç‡
    exposed_diseased = crosstab.iloc[1, 1]
    exposed_total = crosstab.iloc[1, 2]
    unexposed_diseased = crosstab.iloc[0, 1]
    unexposed_total = crosstab.iloc[0, 2]
    
    prevalence_exposed = exposed_diseased / exposed_total if exposed_total > 0 else 0
    prevalence_unexposed = unexposed_diseased / unexposed_total if unexposed_total > 0 else 0
    
    # è®¡ç®—æ‚£ç—…ç‡æ¯”(PR)
    prevalence_ratio = prevalence_exposed / prevalence_unexposed if prevalence_unexposed > 0 else np.inf
    
    # è®¡ç®—æ‚£ç—…ç‡å·®(PD)
    prevalence_difference = prevalence_exposed - prevalence_unexposed
    
    # è®¡ç®—æ¯”å€¼æ¯”(OR)
    exposed_not_diseased = exposed_total - exposed_diseased
    unexposed_not_diseased = unexposed_total - unexposed_diseased
    
    odds_ratio = (exposed_diseased * unexposed_not_diseased) / (exposed_not_diseased * unexposed_diseased) if (exposed_not_diseased * unexposed_diseased) > 0 else np.inf
    
    # ç»Ÿè®¡æ£€éªŒ
    chi2, p_value, dof, expected = chi2_contingency(crosstab.iloc[:-1, :-1])
    
    results['overall'] = {
        'crosstab': crosstab,
        'prevalence_exposed': prevalence_exposed,
        'prevalence_unexposed': prevalence_unexposed,
        'prevalence_ratio': prevalence_ratio,
        'prevalence_difference': prevalence_difference,
        'odds_ratio': odds_ratio,
        'chi2_test': {'chi2': chi2, 'p_value': p_value}
    }
    
    # åˆ†å±‚åˆ†æ
    if stratify_var != "æ— ":
        strata = df[stratify_var].unique()
        
        for stratum in strata:
            stratum_data = df[df[stratify_var] == stratum]
            stratum_crosstab = pd.crosstab(stratum_data[exposure_var], stratum_data[disease_var], margins=True)
            
            # è®¡ç®—åˆ†å±‚æŒ‡æ ‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            if stratum_crosstab.shape[0] >= 3 and stratum_crosstab.shape[1] >= 3:
                s_exposed_diseased = stratum_crosstab.iloc[1, 1]
                s_exposed_total = stratum_crosstab.iloc[1, 2]
                s_unexposed_diseased = stratum_crosstab.iloc[0, 1]
                s_unexposed_total = stratum_crosstab.iloc[0, 2]
                
                s_prevalence_exposed = s_exposed_diseased / s_exposed_total if s_exposed_total > 0 else 0
                s_prevalence_unexposed = s_unexposed_diseased / s_unexposed_total if s_unexposed_total > 0 else 0
                s_prevalence_ratio = s_prevalence_exposed / s_prevalence_unexposed if s_prevalence_unexposed > 0 else np.inf
                
                results['stratified'][str(stratum)] = {
                    'crosstab': stratum_crosstab,
                    'prevalence_exposed': s_prevalence_exposed,
                    'prevalence_unexposed': s_prevalence_unexposed,
                    'prevalence_ratio': s_prevalence_ratio
                }
    
    return results

def display_cross_sectional_results(results, disease_var, exposure_var):
    """æ˜¾ç¤ºæ¨ªæ–­é¢ç ”ç©¶ç»“æœ"""
    
    # æ€»ä½“åˆ†æç»“æœ
    st.write("**æ€»ä½“åˆ†æç»“æœ**")
    
    # 2x2è¡¨
    st.write("2Ã—2åˆ—è”è¡¨:")
    st.dataframe(results['overall']['crosstab'])
    
    # ä¸»è¦æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æš´éœ²ç»„æ‚£ç—…ç‡", f"{results['overall']['prevalence_exposed']:.4f}")
    
    with col2:
        st.metric("éæš´éœ²ç»„æ‚£ç—…ç‡", f"{results['overall']['prevalence_unexposed']:.4f}")
    
    with col3:
        st.metric("æ‚£ç—…ç‡æ¯”(PR)", f"{results['overall']['prevalence_ratio']:.4f}")
    
    with col4:
        st.metric("æ‚£ç—…ç‡å·®(PD)", f"{results['overall']['prevalence_difference']:.4f}")
    
    # å…¶ä»–æŒ‡æ ‡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ¯”å€¼æ¯”(OR)", f"{results['overall']['odds_ratio']:.4f}")
    
    with col2:
        st.metric("å¡æ–¹ç»Ÿè®¡é‡", f"{results['overall']['chi2_test']['chi2']:.4f}")
    
    with col3:
        st.metric("På€¼", f"{results['overall']['chi2_test']['p_value']:.4f}")
    
    # åˆ†å±‚åˆ†æç»“æœ
    if results['stratified']:
        st.write("**åˆ†å±‚åˆ†æç»“æœ**")
        
        stratified_results = []
        for stratum, data in results['stratified'].items():
            stratified_results.append({
                'åˆ†å±‚': stratum,
                'æš´éœ²ç»„æ‚£ç—…ç‡': f"{data['prevalence_exposed']:.4f}",
                'éæš´éœ²ç»„æ‚£ç—…ç‡': f"{data['prevalence_unexposed']:.4f}",
                'æ‚£ç—…ç‡æ¯”': f"{data['prevalence_ratio']:.4f}"
            })
        
        stratified_df = pd.DataFrame(stratified_results)
        st.dataframe(stratified_df, use_container_width=True)
    
    # å¯è§†åŒ–
    st.write("**æ•°æ®å¯è§†åŒ–**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ‚£ç—…ç‡æ¯”è¾ƒæŸ±çŠ¶å›¾
        prevalence_data = pd.DataFrame({
            'ç»„åˆ«': ['æš´éœ²ç»„', 'éæš´éœ²ç»„'],
            'æ‚£ç—…ç‡': [results['overall']['prevalence_exposed'], results['overall']['prevalence_unexposed']]
        })
        
        fig = px.bar(prevalence_data, x='ç»„åˆ«', y='æ‚£ç—…ç‡', 
                    title="æš´éœ²ç»„ä¸éæš´éœ²ç»„æ‚£ç—…ç‡æ¯”è¾ƒ")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # 2x2è¡¨çƒ­åŠ›å›¾
        crosstab_values = results['overall']['crosstab'].iloc[:-1, :-1]
        fig = px.imshow(crosstab_values, 
                       title="2Ã—2åˆ—è”è¡¨çƒ­åŠ›å›¾",
                       labels=dict(x=disease_var, y=exposure_var))
        st.plotly_chart(fig, use_container_width=True)

