# data_management.py
"""
æ•°æ®ç®¡ç†ä¸­å¿ƒ (é‡æ„ç‰ˆ)

Streamlit å…¥å£ç¤ºä¾‹ï¼š
-------------------------------------------
import streamlit as st
from data_management import data_management_ui
data_management_ui()
-------------------------------------------
"""

from __future__ import annotations

import streamlit as st
import pandas as pd
import numpy as np
import io
import json
from datetime import datetime
from typing import Dict, List, Tuple
import plotly.express as px
import plotly.graph_objects as go


# ============ Session æ•°æ®é›†ç®¡ç† ============ #

def _session_dataset_key(name: str) -> str:
    return f"dataset_{name}"


def save_dataset_to_session(name: str, df: pd.DataFrame) -> None:
    st.session_state[_session_dataset_key(name)] = {
        "name": name,
        "data": df,
        "upload_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }


def delete_dataset_from_session(name: str) -> None:
    st.session_state.pop(_session_dataset_key(name), None)


def list_datasets() -> Dict[str, pd.DataFrame]:
    ds = {}
    for k, v in st.session_state.items():
        if k.startswith("dataset_") and isinstance(v, dict) and "data" in v:
            ds[v["name"]] = v["data"]
    return ds


# ============ æ–‡ä»¶è¯»å–å·¥å…· ============ #

@st.cache_data(show_spinner=False)
def _read_uploaded_file(file) -> pd.DataFrame | None:
    """
    æ ¹æ®æ‰©å±•åè‡ªåŠ¨è§£æï¼Œè¿”å› DataFrame
    æ”¯æŒ csv / tsv / xlsx / json / sav / dta / sas7bdat / parquet
    """
    name = file.name.lower()
    try:
        if name.endswith(".csv"):
            return pd.read_csv(file)
        if name.endswith((".tsv", ".txt")):
            return pd.read_csv(file, sep="\t")
        if name.endswith((".xlsx", ".xls")):
            return pd.read_excel(file)
        if name.endswith(".json"):
            return pd.read_json(file)
        if name.endswith(".parquet"):
            return pd.read_parquet(file)
        if name.endswith(".sav"):
            return pd.read_spss(file)
        if name.endswith(".dta"):
            return pd.read_stata(file)
        if name.endswith((".sas7bdat", ".sas")):
            return pd.read_sas(file)
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è§£æå¤±è´¥: {e}")
    return None


# ============ 1. æ•°æ®å¯¼å…¥ ============ #

def data_import_section() -> None:
    st.markdown("### ğŸ“¥ æ•°æ®å¯¼å…¥")

    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ•°æ®æ–‡ä»¶",
        type=[
            "csv",
            "tsv",
            "txt",
            "xlsx",
            "xls",
            "json",
            "sav",
            "dta",
            "sas7bdat",
            "parquet",
        ],
        help="æ”¯æŒ CSV/TSVã€Excelã€JSONã€SPSSã€Stataã€SASã€Parquet ç­‰æ ¼å¼",
    )

    if uploaded_file is not None:
        df = _read_uploaded_file(uploaded_file)
        if df is not None:
            st.success(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸï¼å…± {df.shape[0]} è¡Œ {df.shape[1]} åˆ—ã€‚")
            st.dataframe(df.head())
            default_name = uploaded_file.name.split(".")[0]
            new_name = st.text_input("ä¸ºæ•°æ®é›†å‘½å", value=default_name)
            if st.button("ğŸ’¾ ä¿å­˜åˆ°ä¼šè¯"):
                save_dataset_to_session(new_name, df)
                st.success("å·²ä¿å­˜ï¼")
    st.markdown("---")
    st.markdown("#### å·²åŠ è½½æ•°æ®é›†")
    show_loaded_datasets()


def show_loaded_datasets() -> None:
    datasets = list_datasets()
    if not datasets:
        st.info("æš‚æ— æ•°æ®é›†")
        return
    for name, df in datasets.items():
        with st.expander(f"ğŸ“‚ {name} ({df.shape[0]}Ã—{df.shape[1]})"):
            st.dataframe(df.head())
            col1, col2 = st.columns(2)
            with col1:
                csv = df.to_csv(index=False).encode("utf-8-sig")
                st.download_button("â¬‡ï¸ ä¸‹è½½ CSV", csv, file_name=f"{name}.csv", mime="text/csv")
            with col2:
                if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"del_{name}"):
                    delete_dataset_from_session(name)
                    st.experimental_rerun()


# ============ 2. æ•°æ®æ¢ç´¢ ============ #

def data_exploration_section() -> None:
    st.markdown("### ğŸ” æ•°æ®æ¢ç´¢")
    datasets = list_datasets()
    if not datasets:
        st.info("è¯·å…ˆåœ¨ã€æ•°æ®å¯¼å…¥ã€ä¸­åŠ è½½æ•°æ®")
        return

    name = st.selectbox("é€‰æ‹©æ•°æ®é›†", list(datasets.keys()))
    df = datasets[name]

    sub_tabs = st.tabs(["ğŸ‘ï¸ æ¦‚è§ˆ", "ğŸ“ˆ åˆ†å¸ƒ", "ğŸ”— ç›¸å…³æ€§"])
    # --- æ¦‚è§ˆ
    with sub_tabs[0]:
        st.write("#### åŸºæœ¬ä¿¡æ¯")
        st.write(df.describe(include="all").T)
        st.write("#### ç¼ºå¤±å€¼æ¦‚è§ˆ")
        miss = df.isna().sum().to_frame("ç¼ºå¤±æ•°")
        miss["ç¼ºå¤±ç‡"] = (miss["ç¼ºå¤±æ•°"] / len(df)).round(3)
        st.dataframe(miss)

    # --- åˆ†å¸ƒ
    with sub_tabs[1]:
        col = st.selectbox("é€‰æ‹©å˜é‡ç»˜åˆ¶åˆ†å¸ƒå›¾", df.columns)
        if pd.api.types.is_numeric_dtype(df[col]):
            fig = px.histogram(df, x=col, marginal="box", nbins=30)
        else:
            fig = px.histogram(df, x=col, color=col)
        st.plotly_chart(fig, use_container_width=True)

    # --- ç›¸å…³æ€§
    with sub_tabs[2]:
        num_cols = df.select_dtypes("number").columns
        if len(num_cols) < 2:
            st.info("æ•°å€¼å˜é‡ä¸è¶³ 2 ä¸ªï¼Œæ— æ³•ç»˜åˆ¶ç›¸å…³æ€§çƒ­å›¾")
        else:
            corr = df[num_cols].corr()
            fig = px.imshow(
                corr,
                text_auto=True,
                aspect="auto",
                color_continuous_scale="RdBu_r",
                origin="lower",
                title="ç›¸å…³ç³»æ•°çƒ­å›¾",
            )
            st.plotly_chart(fig, use_container_width=True)


# ============ 3. æ•°æ®æ¸…æ´— ============ #

def data_cleaning_section() -> None:
    st.markdown("### ğŸ§¹ æ•°æ®æ¸…æ´—")

    datasets = list_datasets()
    if not datasets:
        st.info("è¯·å…ˆåŠ è½½æ•°æ®")
        return
    name = st.selectbox("é€‰æ‹©è¦æ¸…æ´—çš„æ•°æ®é›†", list(datasets.keys()), key="clean_ds")
    df = datasets[name].copy()

    st.markdown("#### ç¼ºå¤±å€¼å¤„ç†")
    miss_cols = df.columns[df.isna().any()].tolist()
    if miss_cols:
        with st.expander(f"æœ‰ç¼ºå¤±å€¼çš„åˆ— ({len(miss_cols)})", expanded=False):
            st.dataframe(df[miss_cols].isna().sum())

        col_sel = st.multiselect("é€‰æ‹©è¦å¡«å……ç¼ºå¤±å€¼çš„åˆ—", miss_cols)
        fill_strategy = st.selectbox("å¡«å……ç­–ç•¥", ["å‡å€¼", "ä¸­ä½æ•°", "ä¼—æ•°", "å¸¸æ•°"])
        const_val = None
        if fill_strategy == "å¸¸æ•°":
            const_val = st.text_input("å¡«å……å€¼", "0")
        if st.button("ğŸ©¹ æ‰§è¡Œå¡«å……"):
            for c in col_sel:
                if fill_strategy == "å‡å€¼":
                    df[c].fillna(df[c].mean(), inplace=True)
                elif fill_strategy == "ä¸­ä½æ•°":
                    df[c].fillna(df[c].median(), inplace=True)
                elif fill_strategy == "ä¼—æ•°":
                    df[c].fillna(df[c].mode().iloc[0], inplace=True)
                else:
                    df[c].fillna(const_val, inplace=True)
            st.success("ç¼ºå¤±å€¼å¡«å……å®Œæˆ")

    st.markdown("#### é‡å¤å€¼å¤„ç†")
    dup_count = df.duplicated().sum()
    st.write(f"æ£€æµ‹åˆ° {dup_count} è¡Œé‡å¤")
    if dup_count > 0 and st.button("ğŸš® åˆ é™¤é‡å¤è¡Œ"):
        df.drop_duplicates(inplace=True)
        st.success("å·²åˆ é™¤é‡å¤è¡Œ")

    st.markdown("---")
    new_name = st.text_input("ä¸ºæ¸…æ´—åçš„æ•°æ®é›†å‘½å", value=f"{name}_clean")
    if st.button("ğŸ’¾ ä¿å­˜æ¸…æ´—ç»“æœ"):
        save_dataset_to_session(new_name, df)
        st.success("ä¿å­˜æˆåŠŸï¼")


# ============ 4. å˜é‡ç®¡ç† ============ #

def variable_management_section() -> None:
    st.markdown("### ğŸ“ å˜é‡ç®¡ç†")

    datasets = list_datasets()
    if not datasets:
        st.info("è¯·å…ˆåŠ è½½æ•°æ®")
        return
    name = st.selectbox("é€‰æ‹©æ•°æ®é›†", list(datasets.keys()), key="var_ds")
    df = datasets[name].copy()

    st.markdown("#### é‡å‘½åå˜é‡")
    col1, col2 = st.columns(2)
    with col1:
        old_name = st.selectbox("åŸå˜é‡å", df.columns)
    with col2:
        new_name = st.text_input("æ–°å˜é‡å")
    if st.button("âœï¸ é‡å‘½å"):
        if new_name:
            df.rename(columns={old_name: new_name}, inplace=True)
            st.success("å·²é‡å‘½å")

    st.markdown("#### å˜é‡ç±»å‹è½¬æ¢")
    col = st.selectbox("é€‰æ‹©å˜é‡", df.columns, key="dtype_col")
    target_type = st.selectbox("è½¬æ¢ä¸º", ["æ•°å€¼", "åˆ†ç±»", "æ—¥æœŸ"])
    if st.button("ğŸ”„ è½¬æ¢ç±»å‹"):
        try:
            if target_type == "æ•°å€¼":
                df[col] = pd.to_numeric(df[col], errors="coerce")
            elif target_type == "åˆ†ç±»":
                df[col] = df[col].astype("category")
            else:
                df[col] = pd.to_datetime(df[col], errors="coerce")
            st.success("ç±»å‹è½¬æ¢æˆåŠŸ")
        except Exception as e:
            st.error(f"è½¬æ¢å¤±è´¥: {e}")

    st.markdown("---")
    new_name2 = st.text_input("ä¿å­˜ä¸ºæ–°æ•°æ®é›†å", value=f"{name}_var")
    if st.button("ğŸ’¾ ä¿å­˜å˜é‡ç®¡ç†ç»“æœ"):
        save_dataset_to_session(new_name2, df)
        st.success("ä¿å­˜æˆåŠŸï¼")


# ============ 5. æ•°æ®å¯¼å‡º ============ #

def data_export_section() -> None:
    st.markdown("### ğŸ“¤ æ•°æ®å¯¼å‡º")

    datasets = list_datasets()
    if not datasets:
        st.info("è¯·å…ˆåŠ è½½æ•°æ®")
        return
    name = st.selectbox("é€‰æ‹©æ•°æ®é›†", list(datasets.keys()), key="export_ds")
    df = datasets[name]

    fmt = st.selectbox("å¯¼å‡ºæ ¼å¼", ["csv", "xlsx", "json", "parquet"])
    if st.button("â¬‡ï¸ ç”Ÿæˆæ–‡ä»¶"):
        try:
            if fmt == "csv":
                data = df.to_csv(index=False).encode("utf-8-sig")
            elif fmt == "xlsx":
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
                    df.to_excel(writer, index=False)
                data = buffer.getvalue()
            elif fmt == "json":
                data = df.to_json(orient="records").encode()
            else:
                buffer = io.BytesIO()
                df.to_parquet(buffer, index=False)
                data = buffer.getvalue()

            st.download_button(
                label="ğŸ“¥ ç‚¹å‡»ä¸‹è½½",
                data=data,
                file_name=f"{name}.{fmt}",
                mime="application/octet-stream",
            )
        except Exception as e:
            st.error(f"å¯¼å‡ºå¤±è´¥: {e}")


# ============ ä¸» UI ============ #

def data_management_ui() -> None:
    st.set_page_config(page_title="æ•°æ®ç®¡ç†ä¸­å¿ƒ", page_icon="ğŸ“Š", layout="wide")
    st.markdown("# ğŸ“Š æ•°æ®ç®¡ç†ä¸­å¿ƒ")
    st.markdown("*ä¸“ä¸šçš„æ•°æ®å¯¼å…¥ã€æ¸…æ´—ã€æ¢ç´¢å’Œç®¡ç†å·¥å…·*")

    tab1, tab2, tab3, tab4, tab5 = st.tabs(
        ["ğŸ“¥ æ•°æ®å¯¼å…¥", "ğŸ” æ•°æ®æ¢ç´¢", "ğŸ§¹ æ•°æ®æ¸…æ´—", "ğŸ“ å˜é‡ç®¡ç†", "ğŸ“¤ æ•°æ®å¯¼å‡º"]
    )

    with tab1:
        data_import_section()
    with tab2:
        data_exploration_section()
    with tab3:
        data_cleaning_section()
    with tab4:
        variable_management_section()
    with tab5:
        data_export_section()


# ============ å…¥å£ä¿æŠ¤ ============ #

if __name__ == "__main__":
    data_management_ui()
