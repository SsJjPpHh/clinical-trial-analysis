import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
import io
import base64
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def data_management_ui():
    """æ•°æ®ç®¡ç†ç•Œé¢ - å•†ä¸šåŒ–å‡çº§ç‰ˆ"""
    st.markdown("## ğŸ“Š æ•°æ®ç®¡ç†ä¸­å¿ƒ")
    st.markdown("*ä¸“ä¸šçš„æ•°æ®å¯¼å…¥ã€æ¸…æ´—ã€æ¢ç´¢å’Œç®¡ç†å·¥å…·*")
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“¤ æ•°æ®å¯¼å…¥", "ğŸ” æ•°æ®æ¢ç´¢", "ğŸ› ï¸ æ•°æ®æ¸…æ´—", 
        "ğŸ“‹ å˜é‡ç®¡ç†", "ğŸ’¾ æ•°æ®å¯¼å‡º"
    ])
    
    with tab1:
        data_import_section()
    
    with tab2:
        data_exploration_section()
    
    with tab3:
        data_cleaning_section
    
    with tab4:
        variable_management_section()
    
    with tab5:
        data_export_section()

def data_import_section():
    """æ•°æ®å¯¼å…¥éƒ¨åˆ†"""
    st.markdown("### ğŸ“¤ æ•°æ®å¯¼å…¥")
    
    # å¯¼å…¥æ–¹å¼é€‰æ‹©
    import_method = st.radio(
        "é€‰æ‹©æ•°æ®å¯¼å…¥æ–¹å¼",
        ["ğŸ“ æ–‡ä»¶ä¸Šä¼ ", "ğŸ”— æ•°æ®åº“è¿æ¥", "ğŸŒ ç¤ºä¾‹æ•°æ®", "âœï¸ æ‰‹åŠ¨è¾“å…¥"],
        horizontal=True
    )
    
    if import_method == "ğŸ“ æ–‡ä»¶ä¸Šä¼ ":
        file_upload_interface()
    elif import_method == "ğŸ”— æ•°æ®åº“è¿æ¥":
        database_connection_interface()
    elif import_method == "ğŸŒ ç¤ºä¾‹æ•°æ®":
        sample_data_interface()
    elif import_method == "âœï¸ æ‰‹åŠ¨è¾“å…¥":
        manual_input_interface()

def file_upload_interface():
    """æ–‡ä»¶ä¸Šä¼ ç•Œé¢"""
    st.markdown("#### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
    
    # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ä¿¡æ¯
    with st.expander("ğŸ“‹ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("""
            **è¡¨æ ¼æ–‡ä»¶:**
            - ğŸ“Š Excel (.xlsx, .xls)
            - ğŸ“„ CSV (.csv)
            - ğŸ“‹ TSV (.tsv)
            """)
        with col2:
            st.markdown("""
            **ç»Ÿè®¡è½¯ä»¶:**
            - ğŸ”¢ SPSS (.sav)
            - ğŸ“ˆ Stata (.dta)
            - ğŸ…°ï¸ SAS (.sas7bdat)
            """)
        with col3:
            st.markdown("""
            **å…¶ä»–æ ¼å¼:**
            - ğŸ“Š JSON (.json)
            - ğŸ—ƒï¸ Parquet (.parquet)
            - ğŸ“ TXT (.txt)
            """)
    
    # æ–‡ä»¶ä¸Šä¼ å™¨
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ•°æ®æ–‡ä»¶ (æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ )",
        type=['csv', 'xlsx', 'xls', 'sav', 'dta', 'json', 'parquet', 'txt'],
        accept_multiple_files=True,
        help="æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„æˆ–ç‚¹å‡»é€‰æ‹©æ–‡ä»¶"
    )
    
    if uploaded_files:
        st.success(f"âœ… å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        for i, uploaded_file in enumerate(uploaded_files):
            with st.expander(f"ğŸ“„ {uploaded_file.name} ({uploaded_file.size:,} bytes)", expanded=True):
                process_uploaded_file(uploaded_file, i)

def process_uploaded_file(uploaded_file, index):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹æ˜¾ç¤ºä¸åŒçš„è¯»å–é€‰é¡¹
        if file_extension == 'csv':
            df = process_csv_file(uploaded_file, index)
        elif file_extension in ['xlsx', 'xls']:
            df = process_excel_file(uploaded_file, index)
        elif file_extension == 'json':
            df = pd.read_json(uploaded_file)
        elif file_extension == 'parquet':
            df = pd.read_parquet(uploaded_file)
        elif file_extension == 'txt':
            df = process_text_file(uploaded_file, index)
        else:
            st.warning(f"âš ï¸ æš‚ä¸æ”¯æŒ {file_extension} æ ¼å¼çš„é«˜çº§é€‰é¡¹")
            df = pd.read_csv(uploaded_file)
        
        if df is not None:
            # æ•°æ®è´¨é‡æ£€æŸ¥
            quality_score = perform_data_quality_check(df)
            
            # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
            display_data_info(df, uploaded_file.name, quality_score)
            
            # ä¿å­˜åˆ°session state
            dataset_key = f'dataset_{index}_{uploaded_file.name}'
            st.session_state[dataset_key] = {
                'data': df,
                'name': uploaded_file.name,
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'quality_score': quality_score,
                'file_size': uploaded_file.size
            }
            
            st.success(f"âœ… æ–‡ä»¶ {uploaded_file.name} å¯¼å…¥æˆåŠŸ! æ•°æ®è´¨é‡è¯„åˆ†: {quality_score:.1f}/10")
            
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        st.info("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€ç¼–ç è®¾ç½®æˆ–æ•°æ®å®Œæ•´æ€§")

def process_csv_file(uploaded_file, index):
    """å¤„ç†CSVæ–‡ä»¶"""
    st.markdown("**CSVæ–‡ä»¶è¯»å–é€‰é¡¹:**")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        encoding = st.selectbox(
            "ç¼–ç æ ¼å¼", 
            ['utf-8', 'gbk', 'gb2312', 'latin-1'], 
            key=f"encoding_{index}"
        )
    with col2:
        separator = st.selectbox(
            "åˆ†éš”ç¬¦", 
            [',', ';', '\t', '|', ' '], 
            key=f"sep_{index}"
        )
    with col3:
        header_row = st.number_input(
            "æ ‡é¢˜è¡Œ", 
            min_value=0, 
            value=0, 
            key=f"header_{index}"
        )
    with col4:
        skip_rows = st.number_input(
            "è·³è¿‡è¡Œæ•°", 
            min_value=0, 
            value=0, 
            key=f"skip_{index}"
        )
    
    try:
        df = pd.read_csv(
            uploaded_file, 
            encoding=encoding, 
            sep=separator, 
            header=header_row if header_row >= 0 else None,
            skiprows=skip_rows
        )
        return df
    except Exception as e:
        st.error(f"CSVè¯»å–é”™è¯¯: {str(e)}")
        return None

def process_excel_file(uploaded_file, index):
    """å¤„ç†Excelæ–‡ä»¶"""
    st.markdown("**Excelæ–‡ä»¶è¯»å–é€‰é¡¹:**")
    
    # å…ˆè¯»å–æ–‡ä»¶è·å–å·¥ä½œè¡¨å
    try:
        excel_file = pd.ExcelFile(uploaded_file)
        sheet_names = excel_file.sheet_names
        
        col1, col2, col3 = st.columns(3)
        with col1:
            sheet_name = st.selectbox(
                "é€‰æ‹©å·¥ä½œè¡¨", 
                sheet_names, 
                key=f"sheet_{index}"
            )
        with col2:
            header_row = st.number_input(
                "æ ‡é¢˜è¡Œ", 
                min_value=0, 
                value=0, 
                key=f"header_excel_{index}"
            )
        with col3:
            skip_rows = st.number_input(
                "è·³è¿‡è¡Œæ•°", 
                min_value=0, 
                value=0, 
                key=f"skip_excel_{index}"
            )
        
        df = pd.read_excel(
            uploaded_file, 
            sheet_name=sheet_name, 
            header=header_row if header_row >= 0 else None,
            skiprows=skip_rows
        )
        return df
        
    except Exception as e:
        st.error(f"Excelè¯»å–é”™è¯¯: {str(e)}")
        return None

def process_text_file(uploaded_file, index):
    """å¤„ç†æ–‡æœ¬æ–‡ä»¶"""
    st.markdown("**æ–‡æœ¬æ–‡ä»¶è¯»å–é€‰é¡¹:**")
    
    col1, col2 = st.columns(2)
    with col1:
        delimiter = st.text_input("åˆ†éš”ç¬¦", value="\t", key=f"txt_delim_{index}")
    with col2:
        encoding = st.selectbox("ç¼–ç ", ['utf-8', 'gbk', 'latin-1'], key=f"txt_enc_{index}")
    
    try:
        df = pd.read_csv(uploaded_file, sep=delimiter, encoding=encoding)
        return df
    except Exception as e:
        st.error(f"æ–‡æœ¬æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
        return None

def perform_data_quality_check(df):
    """æ‰§è¡Œæ•°æ®è´¨é‡æ£€æŸ¥"""
    score = 10.0
    
    # ç¼ºå¤±å€¼æ£€æŸ¥ (æœ€å¤šæ‰£2åˆ†)
    missing_ratio = df.isnull().sum().sum() / (df.shape[0] * df.shape[1])
    if missing_ratio > 0.5:
        score -= 2
    elif missing_ratio > 0.2:
        score -= 1
    elif missing_ratio > 0.1:
        score -= 0.5
    
    # é‡å¤è¡Œæ£€æŸ¥ (æœ€å¤šæ‰£1åˆ†)
    duplicate_ratio = df.duplicated().sum() / len(df)
    if duplicate_ratio > 0.1:
        score -= 1
    elif duplicate_ratio > 0.05:
        score -= 0.5
    
    # æ•°æ®ç±»å‹ä¸€è‡´æ€§æ£€æŸ¥ (æœ€å¤šæ‰£1åˆ†)
    type_issues = 0
    for col in df.columns:
        if df[col].dtype == 'object':
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ˜¯æ•°å€¼å‹
            try:
                pd.to_numeric(df[col].dropna())
                type_issues += 1
            except:
                pass
    
    if type_issues > len(df.columns) * 0.3:
        score -= 1
    elif type_issues > len(df.columns) * 0.1:
        score -= 0.5
    
    return max(0, score)

def display_data_info(df, filename, quality_score):
    """æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯"""
    st.markdown(f"#### ğŸ“‹ æ•°æ®æ¦‚è§ˆ - {filename}")
    
    # æ•°æ®è´¨é‡è¯„åˆ†
    quality_color = "ğŸŸ¢" if quality_score >= 8 else "ğŸŸ¡" if quality_score >= 6 else "ğŸ”´"
    st.markdown(f"**æ•°æ®è´¨é‡è¯„åˆ†: {quality_color} {quality_score:.1f}/10**")
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    
    with col1:
        st.metric("ğŸ“Š æ€»è¡Œæ•°", f"{df.shape[0]:,}")
    with col2:
        st.metric("ğŸ“‹ æ€»åˆ—æ•°", f"{df.shape[1]:,}")
    with col3:
        missing_count = df.isnull().sum().sum()
        st.metric("âŒ ç¼ºå¤±å€¼", f"{missing_count:,}")
    with col4:
        duplicate_count = df.duplicated().sum()
        st.metric("ğŸ”„ é‡å¤è¡Œ", f"{duplicate_count:,}")
    with col5:
        numeric_cols = df.select_dtypes(include=[np.number]).shape[1]
        st.metric("ğŸ”¢ æ•°å€¼åˆ—", f"{numeric_cols:,}")
    with col6:
        text_cols = df.select_dtypes(include=['object']).shape[1]
        st.metric("ğŸ”¤ æ–‡æœ¬åˆ—", f"{text_cols:,}")
    
    # æ•°æ®é¢„è§ˆ
    st.markdown("##### ğŸ“„ æ•°æ®é¢„è§ˆ")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        preview_rows = st.slider("é¢„è§ˆè¡Œæ•°", 5, min(50, len(df)), 10, key=f"preview_{filename}")
    with col2:
        show_all_cols = st.checkbox("æ˜¾ç¤ºæ‰€æœ‰åˆ—", key=f"cols_{filename}")
    with col3:
        show_dtypes = st.checkbox("æ˜¾ç¤ºæ•°æ®ç±»å‹", key=f"dtypes_{filename}")
    
    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
    preview_df = df.head(preview_rows)
    if not show_all_cols and df.shape[1] > 10:
        preview_df = preview_df.iloc[:, :10]
        st.info(f"æ˜¾ç¤ºå‰10åˆ—ï¼Œå…±{df.shape[1]}åˆ—")
    
    st.dataframe(preview_df, use_container_width=True)
    
    # æ•°æ®ç±»å‹å’Œè´¨é‡ä¿¡æ¯
    if show_dtypes or st.button(f"ğŸ“Š æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯", key=f"detail_{filename}"):
        with st.expander("ğŸ” è¯¦ç»†æ•°æ®ä¿¡æ¯", expanded=True):
            
            # åˆ›å»ºè¯¦ç»†ä¿¡æ¯è¡¨
            detail_info = []
            for col in df.columns:
                col_data = df[col]
                detail_info.append({
                    'åˆ—å': col,
                    'æ•°æ®ç±»å‹': str(col_data.dtype),
                    'éç©ºå€¼æ•°': col_data.count(),
                    'ç¼ºå¤±å€¼æ•°': col_data.isnull().sum(),
                    'ç¼ºå¤±ç‡(%)': round(col_data.isnull().sum() / len(df) * 100, 2),
                    'å”¯ä¸€å€¼æ•°': col_data.nunique(),
                    'é‡å¤å€¼æ•°': len(df) - col_data.nunique(),
                    'å†…å­˜ä½¿ç”¨': f"{col_data.memory_usage(deep=True) / 1024:.1f} KB"
                })
            
            detail_df = pd.DataFrame(detail_info)
            st.dataframe(detail_df, use_container_width=True)
            
            # æ•°æ®è´¨é‡é—®é¢˜æé†’
            issues = []
            if df.isnull().sum().sum() > 0:
                issues.append(f"âš ï¸ å‘ç° {df.isnull().sum().sum()} ä¸ªç¼ºå¤±å€¼")
            if df.duplicated().sum() > 0:
                issues.append(f"âš ï¸ å‘ç° {df.duplicated().sum()} ä¸ªé‡å¤è¡Œ")
            
            # æ£€æŸ¥å¯èƒ½çš„æ•°æ®ç±»å‹é—®é¢˜
            type_suggestions = []
            for col in df.select_dtypes(include=['object']).columns:
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    pd.to_numeric(df[col].dropna())
                    type_suggestions.append(f"ğŸ’¡ åˆ— '{col}' å¯èƒ½åº”è¯¥æ˜¯æ•°å€¼ç±»å‹")
                except:
                    pass
                
                # æ£€æŸ¥æ—¥æœŸæ ¼å¼
                if col.lower() in ['date', 'time', 'æ—¥æœŸ', 'æ—¶é—´'] or 'date' in col.lower():
                    type_suggestions.append(f"ğŸ’¡ åˆ— '{col}' å¯èƒ½æ˜¯æ—¥æœŸç±»å‹")
            
            if issues or type_suggestions:
                st.markdown("##### ğŸ” æ•°æ®è´¨é‡å»ºè®®")
                for issue in issues:
                    st.warning(issue)
                for suggestion in type_suggestions:
                    st.info(suggestion)

def database_connection_interface():
    """æ•°æ®åº“è¿æ¥ç•Œé¢"""
    st.markdown("#### ğŸ”— æ•°æ®åº“è¿æ¥")
    st.info("ğŸš§ æ•°æ®åº“è¿æ¥åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼")
    
    # é¢„ç•™æ•°æ®åº“è¿æ¥é€‰é¡¹
    db_type = st.selectbox(
        "æ•°æ®åº“ç±»å‹",
        ["MySQL", "PostgreSQL", "SQLite", "SQL Server", "Oracle"]
    )
    
    col1, col2 = st.columns(2)
    with col1:
        host = st.text_input("ä¸»æœºåœ°å€", placeholder="localhost")
        database = st.text_input("æ•°æ®åº“å", placeholder="database_name")
    with col2:
        port = st.number_input("ç«¯å£", value=3306)
        username = st.text_input("ç”¨æˆ·å", placeholder="username")
    
    password = st.text_input("å¯†ç ", type="password")
    
    if st.button("ğŸ”Œ æµ‹è¯•è¿æ¥"):
        st.warning("æ•°æ®åº“è¿æ¥åŠŸèƒ½å¼€å‘ä¸­...")

def sample_data_interface():
    """ç¤ºä¾‹æ•°æ®ç•Œé¢"""
    st.markdown("#### ğŸŒ ç¤ºä¾‹æ•°æ®é›†")
    st.markdown("*é€‰æ‹©å†…ç½®ç¤ºä¾‹æ•°æ®é›†è¿›è¡Œå­¦ä¹ å’Œæµ‹è¯•*")
    
    # ç¤ºä¾‹æ•°æ®é›†
    sample_datasets = {
        "ğŸ§ª ä¸´åºŠè¯•éªŒæ•°æ®": {
            "description": "éšæœºå¯¹ç…§è¯•éªŒç¤ºä¾‹æ•°æ®ï¼ŒåŒ…å«åŸºçº¿ç‰¹å¾ã€ç–—æ•ˆæŒ‡æ ‡å’Œå®‰å…¨æ€§æ•°æ®",
            "size": "500è¡Œ Ã— 15åˆ—",
            "generator": generate_clinical_trial_data
        },
        "ğŸ¦  æµè¡Œç—…å­¦æ•°æ®": {
            "description": "é˜Ÿåˆ—ç ”ç©¶ç¤ºä¾‹æ•°æ®ï¼ŒåŒ…å«æš´éœ²å› ç´ ã€åå˜é‡å’Œç»“å±€å˜é‡",
            "size": "1000è¡Œ Ã— 12åˆ—", 
            "generator": generate_epidemiology_data
        },
        "ğŸ“Š ç”Ÿå­˜åˆ†ææ•°æ®": {
            "description": "ç”Ÿå­˜åˆ†æç¤ºä¾‹æ•°æ®ï¼ŒåŒ…å«ç”Ÿå­˜æ—¶é—´ã€åˆ å¤±çŠ¶æ€å’Œåå˜é‡",
            "size": "300è¡Œ Ã— 8åˆ—",
            "generator": generate_survival_data
        },
        "ğŸ”¬ å®éªŒå®¤æ•°æ®": {
            "description": "å®éªŒå®¤æ£€æµ‹ç»“æœæ•°æ®ï¼ŒåŒ…å«å¤šä¸ªç”ŸåŒ–æŒ‡æ ‡å’Œå‚è€ƒèŒƒå›´",
            "size": "800è¡Œ Ã— 20åˆ—",
            "generator": generate_lab_data
        }
    }
    
    for name, info in sample_datasets.items():
        with st.expander(f"{name} ({info['size']})", expanded=False):
            st.markdown(f"**æè¿°:** {info['description']}")
            
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f"**æ•°æ®è§„æ¨¡:** {info['size']}")
            with col2:
                if st.button("ğŸ“¥ åŠ è½½æ•°æ®", key=f"load_{name}"):
                    df = info['generator']()
                    dataset_key = f'dataset_sample_{name}'
                    st.session_state[dataset_key] = {
                        'data': df,
                        'name': f"ç¤ºä¾‹_{name}",
                        'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'quality_score': 9.5,
                        'file_size': len(df) * len(df.columns) * 8  # ä¼°ç®—å¤§å°
                    }
                    st.success(f"âœ… å·²åŠ è½½ {name}")
                    st.rerun()

def generate_clinical_trial_data():
    """ç”Ÿæˆä¸´åºŠè¯•éªŒç¤ºä¾‹æ•°æ®"""
    np.random.seed(42)
    n = 500
    
    # åŸºçº¿ç‰¹å¾
    data = {
        'å—è¯•è€…ID': [f'S{i:04d}' for i in range(1, n+1)],
        'æ²»ç–—ç»„': np.random.choice(['è¯•éªŒç»„', 'å¯¹ç…§ç»„'], n),
        'å¹´é¾„': np.random.normal(65, 12, n).astype(int),
        'æ€§åˆ«': np.random.choice(['ç”·', 'å¥³'], n),
        'ä½“é‡kg': np.random.normal(70, 15, n).round(1),
        'èº«é«˜cm': np.random.normal(165, 10, n).round(1),
        'åŸºçº¿è¡€å‹æ”¶ç¼©å‹': np.random.normal(140, 20, n).astype(int),
        'åŸºçº¿è¡€å‹èˆ’å¼ å‹': np.random.normal(90, 15, n).astype(int),
        'åŸºçº¿èƒ†å›ºé†‡': np.random.normal(5.2, 1.2, n).round(2),
        'ç³–å°¿ç—…å²': np.random.choice(['æ˜¯', 'å¦'], n, p=[0.3, 0.7]),
        'å¸çƒŸå²': np.random.choice(['æ˜¯', 'å¦'], n, p=[0.4, 0.6]),
        'éšè®¿æ—¶é—´å¤©': np.random.normal(180, 30, n).astype(int),
        'ä¸»è¦ç»ˆç‚¹è¾¾æˆ': np.random.choice(['æ˜¯', 'å¦'], n, p=[0.6, 0.4]),
        'ä¸è‰¯äº‹ä»¶': np.random.choice(['æ— ', 'è½»åº¦', 'ä¸­åº¦', 'é‡åº¦'], n, p=[0.6, 0.25, 0.1, 0.05]),
        'ä¾ä»æ€§ç™¾åˆ†æ¯”': np.random.normal(85, 15, n).round(1)
    }
    
    return pd.DataFrame(data)

def generate_epidemiology_data():
    """ç”Ÿæˆæµè¡Œç—…å­¦ç¤ºä¾‹æ•°æ®"""
    np.random.seed(42)
    n = 1000
    
    data = {
        'ID': range(1, n+1),
        'å¹´é¾„': np.random.normal(45, 15, n).astype(int),
        'æ€§åˆ«': np.random.choice(['ç”·', 'å¥³'], n),
        'æ•™è‚²ç¨‹åº¦': np.random.choice(['å°å­¦', 'ä¸­å­¦', 'å¤§å­¦', 'ç ”ç©¶ç”Ÿ'], n, p=[0.2, 0.4, 0.3, 0.1]),
        'æ”¶å…¥æ°´å¹³': np.random.choice(['ä½', 'ä¸­', 'é«˜'], n, p=[0.3, 0.5, 0.2]),
        'å¸çƒŸçŠ¶æ€': np.random.choice(['ä»ä¸', 'æ›¾ç»', 'ç°åœ¨'], n, p=[0.5, 0.3, 0.2]),
        'é¥®é…’é¢‘ç‡': np.random.choice(['ä»ä¸', 'å¶å°”', 'ç»å¸¸'], n, p=[0.4, 0.4, 0.2]),
        'è¿åŠ¨é¢‘ç‡': np.random.choice(['ä»ä¸', 'å¶å°”', 'ç»å¸¸'], n, p=[0.3, 0.4, 0.3]),
        'BMI': np.random.normal(24, 4, n).round(1),
        'è¡€å‹mmHg': np.random.normal(120, 20, n).astype(int),
        'éšè®¿å¹´æ•°': np.random.uniform(1, 10, n).round(1),
        'ç–¾ç—…å‘ç”Ÿ': np.random.choice([0, 1], n, p=[0.8, 0.2])
    }
    
    return pd.DataFrame(data)

def generate_survival_data():
    """ç”Ÿæˆç”Ÿå­˜åˆ†æç¤ºä¾‹æ•°æ®"""
    np.random.seed(42)
    n = 300
    
    # ç”Ÿæˆç”Ÿå­˜æ—¶é—´ï¼ˆæŒ‡æ•°åˆ†å¸ƒï¼‰
    survival_time = np.random.exponential(20, n)
    # ç”Ÿæˆåˆ å¤±æ—¶é—´
    censoring_time = np.random.exponential(30, n)
    # è§‚å¯Ÿæ—¶é—´å–æœ€å°å€¼
    observed_time = np.minimum(survival_time, censoring_time)
    # äº‹ä»¶å‘ç”Ÿæ ‡å¿—
    event = (survival_time <= censoring_time).astype(int)
    
    data = {
        'æ‚£è€…ID': [f'P{i:03d}' for i in range(1, n+1)],
        'å¹´é¾„': np.random.normal(60, 15, n).astype(int),
        'æ€§åˆ«': np.random.choice(['ç”·', 'å¥³'], n),
        'æ²»ç–—æ–¹æ¡ˆ': np.random.choice(['A', 'B', 'C'], n),
        'è‚¿ç˜¤åˆ†æœŸ': np.random.choice(['I', 'II', 'III', 'IV'], n, p=[0.2, 0.3, 0.3, 0.2]),
        'ç”Ÿå­˜æ—¶é—´æœˆ': observed_time.round(1),
        'äº‹ä»¶å‘ç”Ÿ': event,
        'éšè®¿çŠ¶æ€': ['äº‹ä»¶' if e else 'åˆ å¤±' for e in event]
    }
    
    return pd.DataFrame(data)

def generate_lab_data():
    """ç”Ÿæˆå®éªŒå®¤æ•°æ®"""
    np.random.seed(42)
    n = 800
    
    data = {
        'æ ·æœ¬ID': [f'L{i:04d}' for i in range(1, n+1)],
        'æ£€æµ‹æ—¥æœŸ': pd.date_range('2023-01-01', periods=n, freq='H'),
        'æ‚£è€…å¹´é¾„': np.random.normal(50, 20, n).astype(int),
        'æ‚£è€…æ€§åˆ«': np.random.choice(['ç”·', 'å¥³'], n),
        'ç™½ç»†èƒè®¡æ•°': np.random.normal(6.5, 2.0, n).round(2),
        'çº¢ç»†èƒè®¡æ•°': np.random.normal(4.5, 0.5, n).round(2),
        'è¡€çº¢è›‹ç™½': np.random.normal(140, 20, n).round(1),
        'è¡€å°æ¿è®¡æ•°': np.random.normal(250, 50, n).astype(int),
        'æ€»èƒ†å›ºé†‡': np.random.normal(5.0, 1.0, n).round(2),
        'ç”˜æ²¹ä¸‰é…¯': np.random.normal(1.5, 0.8, n).round(2),
        'ç©ºè…¹è¡€ç³–': np.random.normal(5.5, 1.5, n).round(2),
        'è‚Œé…': np.random.normal(80, 20, n).round(1),
        'å°¿ç´ æ°®': np.random.normal(5.0, 2.0, n).round(2),
        'ALT': np.random.normal(30, 15, n).round(1),
        'AST': np.random.normal(25, 12, n).round(1),
        'æ€»èƒ†çº¢ç´ ': np.random.normal(15, 8, n).round(2),
        'ç™½è›‹ç™½': np.random.normal(40, 5, n).round(1),
        'CRP': np.random.exponential(5, n).round(2),
        'ESR': np.random.normal(15, 10, n).astype(int),
        'æ£€æµ‹ç»“æœ': np.random.choice(['æ­£å¸¸', 'å¼‚å¸¸'], n, p=[0.7, 0.3])
    }
    
    return pd.DataFrame(data)

def manual_input_interface():
    """æ‰‹åŠ¨è¾“å…¥ç•Œé¢"""
    st.markdown("#### âœï¸ æ‰‹åŠ¨è¾“å…¥æ•°æ®")
    
    input_method = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼",
        ["ğŸ“ è¡¨æ ¼ç¼–è¾‘å™¨", "ğŸ“‹ CSVæ ¼å¼è¾“å…¥"],
        horizontal=True
    )
    
    if input_method == "ğŸ“ è¡¨æ ¼ç¼–è¾‘å™¨":
        st.markdown("**ä½¿ç”¨è¡¨æ ¼ç¼–è¾‘å™¨åˆ›å»ºæ•°æ®:**")
        
        # è®¾ç½®è¡¨æ ¼ç»´åº¦
        col1, col2 = st.columns(2)
        with col1:
            n_rows = st.number_input("è¡Œæ•°", min_value=1, max_value=100, value=5)
        with col2:
            n_cols = st.number_input("åˆ—æ•°", min_value=1, max_value=20, value=3)
        
        # åˆ›å»ºç©ºæ•°æ®æ¡†
        if 'manual_data' not in st.session_state:
            st.session_state.manual_data = pd.DataFrame(
                np.empty((n_rows, n_cols), dtype=object),
                columns=[f'åˆ—{i+1}' for i in range(n_cols)]
            )
        
        # æ•°æ®ç¼–è¾‘å™¨
        edited_df = st.data_editor(
            st.session_state.manual_data,
            use_container_width=True,
            num_rows="dynamic"
        )
        
        if st.button("ğŸ’¾ ä¿å­˜æ‰‹åŠ¨è¾“å…¥æ•°æ®"):
            dataset_key = 'dataset_manual_input'
            st.session_state[dataset_key] = {
                'data': edited_df,
                'name': 'æ‰‹åŠ¨è¾“å…¥æ•°æ®',
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'quality_score': 8.0,
                'file_size': len(edited_df) * len(edited_df.columns) * 8
            }
            st.success("âœ… æ‰‹åŠ¨è¾“å…¥æ•°æ®å·²ä¿å­˜!")
    
    else:
        st.markdown("**CSVæ ¼å¼è¾“å…¥ (ç²˜è´´CSVæ ¼å¼çš„æ•°æ®):**")
        csv_input = st.text_area(
            "è¾“å…¥CSVæ ¼å¼æ•°æ®",
            height=200,
            placeholder="åˆ—1,åˆ—2,åˆ—3\nå€¼1,å€¼2,å€¼3\nå€¼4,å€¼5,å€¼6"
        )
        
        if csv_input and st.button("ğŸ“¥ è§£æCSVæ•°æ®"):
            try:
                df = pd.read_csv(io.StringIO(csv_input))
                dataset_key = 'dataset_csv_input'
                st.session_state[dataset_key] = {
                    'data': df,
                    'name': 'CSVè¾“å…¥æ•°æ®',
                    'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'quality_score': 8.0,
                    'file_size': len(df) * len(df.columns) * 8
                }
                st.success("âœ… CSVæ•°æ®è§£ææˆåŠŸ!")
                st.dataframe(df, use_container_width=True)
            except Exception as e:
                st.error(f"âŒ CSVè§£æå¤±è´¥: {str(e)}")

def data_exploration_section():
    """æ•°æ®æ¢ç´¢éƒ¨åˆ†"""
    st.markdown("### ğŸ” æ•°æ®æ¢ç´¢åˆ†æ")
    st.markdown("*æ·±å…¥äº†è§£æ‚¨çš„æ•°æ®ç‰¹å¾ã€åˆ†å¸ƒå’Œå…³ç³»*")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    datasets = get_available_datasets()
    if not datasets:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ 'æ•°æ®å¯¼å…¥' æ ‡ç­¾é¡µä¸­å¯¼å…¥æ•°æ®")
        return
    
    # é€‰æ‹©æ•°æ®é›†
    selected_dataset = st.selectbox(
        "ğŸ“Š é€‰æ‹©è¦æ¢ç´¢çš„æ•°æ®é›†", 
        list(datasets.keys()),
        help="é€‰æ‹©å·²å¯¼å…¥çš„æ•°æ®é›†è¿›è¡Œæ¢ç´¢åˆ†æ"
    )
    df = datasets[selected_dataset]['data']
    
    # æ˜¾ç¤ºæ•°æ®é›†åŸºæœ¬ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“Š æ•°æ®å½¢çŠ¶", f"{df.shape[0]} Ã— {df.shape[1]}")
    with col2:
        st.metric("ğŸ’¾ å†…å­˜ä½¿ç”¨", f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB")
    with col3:
        st.metric("ğŸ“ˆ æ•°å€¼åˆ—", f"{df.select_dtypes(include=[np.number]).shape[1]}")
    with col4:
        st.metric("ğŸ”¤ åˆ†ç±»åˆ—", f"{df.select_dtypes(include=['object']).shape[1]}")
    
    # æ¢ç´¢é€‰é¡¹
    exploration_type = st.radio(
        "ğŸ¯ é€‰æ‹©æ¢ç´¢ç±»å‹",
        ["ğŸ“Š æè¿°æ€§ç»Ÿè®¡", "ğŸ“ˆ æ•°æ®åˆ†å¸ƒ", "ğŸ”— ç›¸å…³æ€§åˆ†æ", "ğŸ“‹ äº¤å‰è¡¨åˆ†æ", "ğŸ¨ æ•°æ®å¯è§†åŒ–"],
        horizontal=True
    )
    
    if exploration_type == "ğŸ“Š æè¿°æ€§ç»Ÿè®¡":
        descriptive_statistics(df)
    elif exploration_type == "ğŸ“ˆ æ•°æ®åˆ†å¸ƒ":
        distribution_analysis(df)
    elif exploration_type == "ğŸ”— ç›¸å…³æ€§åˆ†æ":
        correlation_analysis(df)
    elif exploration_type == "ğŸ“‹ äº¤å‰è¡¨åˆ†æ":
        crosstab_analysis(df)
    elif exploration_type == "ğŸ¨ æ•°æ®å¯è§†åŒ–":
        data_visualization(df)

def get_available_datasets():
    """è·å–å¯ç”¨çš„æ•°æ®é›†"""
    datasets = {}
    for key, value in st.session_state.items():
        if key.startswith('dataset_') and isinstance(value, dict) and 'data' in value:
            datasets[value.get('name', key)] = value
    return datasets

def descriptive_statistics(df):
    """æè¿°æ€§ç»Ÿè®¡åˆ†æ"""
    st.markdown("#### ğŸ“Š æè¿°æ€§ç»Ÿè®¡åˆ†æ")
    
    # æ•°å€¼å˜é‡ç»Ÿè®¡
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if len(numeric_cols) > 0:
        st.markdown("##### ğŸ”¢ æ•°å€¼å˜é‡ç»Ÿè®¡")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            selected_numeric = st.multiselect(
                "é€‰æ‹©æ•°å€¼å˜é‡", 
                numeric_cols, 
                default=numeric_cols[:5] if len(numeric_cols) >= 5 else numeric_cols,
                help="é€‰æ‹©è¦åˆ†æçš„æ•°å€¼å˜é‡"
            )
        with col2:
            stat_options = st.multiselect(
                "é€‰æ‹©ç»Ÿè®¡é‡", 
                ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'skew', 'kurt'],
                default=['count', 'mean', 'std', 'min', '50%', 'max'],
                help="é€‰æ‹©è¦è®¡ç®—çš„ç»Ÿè®¡æŒ‡æ ‡"
            )
        
        if selected_numeric and stat_options:
            # è®¡ç®—æè¿°æ€§ç»Ÿè®¡
            desc_stats = df[selected_numeric].describe()
            
            # æ·»åŠ ååº¦å’Œå³°åº¦
            if 'skew' in stat_options:
                desc_stats.loc['skew'] = df[selected_numeric].skew()
            if 'kurt' in stat_options:
                desc_stats.loc['kurt'] = df[selected_numeric].kurtosis()
            
            # æ˜¾ç¤ºç»Ÿè®¡è¡¨
            st.dataframe(
                desc_stats.loc[stat_options].round(3), 
                use_container_width=True
            )
            
            # ç»Ÿè®¡è§£é‡Š
            with st.expander("ğŸ“– ç»Ÿè®¡æŒ‡æ ‡è§£é‡Š"):
                st.markdown("""
                - **count**: éç¼ºå¤±å€¼æ•°é‡
                - **mean**: å¹³å‡å€¼
                - **std**: æ ‡å‡†å·®
                - **min/max**: æœ€å°å€¼/æœ€å¤§å€¼
                - **25%/50%/75%**: å››åˆ†ä½æ•°
                - **skew**: ååº¦ (>0å³å, <0å·¦å)
                - **kurt**: å³°åº¦ (>0å°–å³°, <0å¹³å³°)
                """)
    
    # åˆ†ç±»å˜é‡ç»Ÿè®¡
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    if len(categorical_cols) > 0:
        st.markdown("##### ğŸ”¤ åˆ†ç±»å˜é‡ç»Ÿè®¡")
        
        selected_categorical = st.selectbox(
            "é€‰æ‹©åˆ†ç±»å˜é‡", 
            categorical_cols,
            help="é€‰æ‹©è¦åˆ†æçš„åˆ†ç±»å˜é‡"
        )
        
        if selected_categorical:
            col1, col2 = st.columns(2)
            
            with col1:
                # é¢‘æ•°ç»Ÿè®¡
                value_counts = df[selected_categorical].value_counts()
                st.markdown("**é¢‘æ•°ç»Ÿè®¡:**")
                
                freq_df = pd.DataFrame({
                    'ç±»åˆ«': value_counts.index,
                    'é¢‘æ•°': value_counts.values,
                    'é¢‘ç‡(%)': (value_counts.values / len(df) * 100).round(2)
                })
                st.dataframe(freq_df, use_container_width=True)
            
            with col2:
                # é¥¼å›¾
                fig = px.pie(
                    values=value_counts.values,
                    names=value_counts.index,
                    title=f"{selected_categorical} åˆ†å¸ƒ",
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)

def distribution_analysis(df):
    """æ•°æ®åˆ†å¸ƒåˆ†æ"""
    st.markdown("#### ğŸ“ˆ æ•°æ®åˆ†å¸ƒåˆ†æ")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ•°å€¼å‹å˜é‡")
        return
    
    # é€‰æ‹©å˜é‡
    col1, col2 = st.columns(2)
    with col1:
        selected_var = st.selectbox("é€‰æ‹©å˜é‡", numeric_cols)
    with col2:
        plot_type = st.selectbox(
            "å›¾è¡¨ç±»å‹", 
            ["ç›´æ–¹å›¾", "å¯†åº¦å›¾", "ç®±çº¿å›¾", "Q-Qå›¾", "å°æç´å›¾"]
        )
    
    if selected_var:
        data_series = df[selected_var].dropna()
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # ç»˜åˆ¶åˆ†å¸ƒå›¾
            if plot_type == "ç›´æ–¹å›¾":
                fig = px.histogram(
                    df, x=selected_var, 
                    title=f"{selected_var} åˆ†å¸ƒç›´æ–¹å›¾",
                    marginal="box",
                    nbins=30
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
                
            elif plot_type == "å¯†åº¦å›¾":
                fig = go.Figure()
                fig.add_trace(go.Histogram(
                    x=data_series,
                    histnorm='probability density',
                    name='ç›´æ–¹å›¾',
                    opacity=0.7
                ))
                
                # æ·»åŠ æ ¸å¯†åº¦ä¼°è®¡
                from scipy.stats import gaussian_kde
                kde = gaussian_kde(data_series)
                x_range = np.linspace(data_series.min(), data_series.max(), 100)
                fig.add_trace(go.Scatter(
                    x=x_range,
                    y=kde(x_range),
                    mode='lines',
                    name='å¯†åº¦æ›²çº¿',
                    line=dict(color='red', width=2)
                ))
                
                fig.update_layout(
                    title=f"{selected_var} å¯†åº¦åˆ†å¸ƒå›¾",
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
                
            elif plot_type == "ç®±çº¿å›¾":
                fig = px.box(
                    df, y=selected_var,
                    title=f"{selected_var} ç®±çº¿å›¾",
                    points="outliers"
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
                
            elif plot_type == "Q-Qå›¾":
                from scipy import stats
                fig = go.Figure()
                
                # è®¡ç®—Q-Qå›¾æ•°æ®
                (osm, osr), (slope, intercept, r) = stats.probplot(data_series, dist="norm")
                
                fig.add_trace(go.Scatter(
                    x=osm, y=osr,
                    mode='markers',
                    name='è§‚æµ‹å€¼',
                    marker=dict(color='blue', size=6)
                ))
                
                fig.add_trace(go.Scatter(
                    x=osm, y=slope * osm + intercept,
                    mode='lines',
                    name='ç†è®ºçº¿',
                    line=dict(color='red', width=2)
                ))
                
                fig.update_layout(
                    title=f"{selected_var} Q-Qå›¾ (æ­£æ€æ€§æ£€éªŒ)",
                    xaxis_title="ç†è®ºåˆ†ä½æ•°",
                    yaxis_title="æ ·æœ¬åˆ†ä½æ•°",
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
                
            elif plot_type == "å°æç´å›¾":
                fig = px.violin(
                    df, y=selected_var,
                    title=f"{selected_var} å°æç´å›¾",
                    box=True,
                    points="outliers"
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # åˆ†å¸ƒç»Ÿè®¡ä¿¡æ¯
            st.markdown("**åˆ†å¸ƒç»Ÿè®¡:**")
            
            stats_info = {
                "æ ·æœ¬æ•°": len(data_series),
                "å‡å€¼": data_series.mean(),
                "ä¸­ä½æ•°": data_series.median(),
                "æ ‡å‡†å·®": data_series.std(),
                "ååº¦": data_series.skew(),
                "å³°åº¦": data_series.kurtosis(),
                "æœ€å°å€¼": data_series.min(),
                "æœ€å¤§å€¼": data_series.max(),
                "å››åˆ†ä½è·": data_series.quantile(0.75) - data_series.quantile(0.25)
            }
            
            for key, value in stats_info.items():
                if isinstance(value, (int, float)):
                    st.metric(key, f"{value:.3f}")
                else:
                    st.metric(key, value)
            
            # æ­£æ€æ€§æ£€éªŒ
            st.markdown("**æ­£æ€æ€§æ£€éªŒ:**")
            from scipy.stats import shapiro, normaltest
            
            if len(data_series) <= 5000:  # Shapiro-Wilké€‚ç”¨äºå°æ ·æœ¬
                stat, p_value = shapiro(data_series)
                test_name = "Shapiro-Wilk"
            else:
                stat, p_value = normaltest(data_series)
                test_name = "D'Agostino"
            
            st.write(f"**{test_name} æ£€éªŒ:**")
            st.write(f"ç»Ÿè®¡é‡: {stat:.4f}")
            st.write(f"på€¼: {p_value:.4f}")
            
            if p_value > 0.05:
                st.success("âœ… æ¥å—æ­£æ€åˆ†å¸ƒå‡è®¾")
            else:
                st.warning("âš ï¸ æ‹’ç»æ­£æ€åˆ†å¸ƒå‡è®¾")

def correlation_analysis(df):
    """ç›¸å…³æ€§åˆ†æ"""
    st.markdown("#### ğŸ”— ç›¸å…³æ€§åˆ†æ")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) < 2:
        st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼å‹å˜é‡è¿›è¡Œç›¸å…³æ€§åˆ†æ")
        return
    
    # é€‰æ‹©å˜é‡
    col1, col2 = st.columns(2)
    with col1:
        selected_vars = st.multiselect(
            "é€‰æ‹©å˜é‡", 
            numeric_cols,
            default=numeric_cols[:min(8, len(numeric_cols))],
            help="é€‰æ‹©è¦åˆ†æç›¸å…³æ€§çš„å˜é‡"
        )
    with col2:
        corr_method = st.selectbox(
            "ç›¸å…³ç³»æ•°ç±»å‹",
            ["pearson", "spearman", "kendall"],
            help="Pearson: çº¿æ€§ç›¸å…³; Spearman: å•è°ƒç›¸å…³; Kendall: ç§©ç›¸å…³"
        )
    
    if len(selected_vars) >= 2:
        # è®¡ç®—ç›¸å…³çŸ©é˜µ
        corr_matrix = df[selected_vars].corr(method=corr_method)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # ç›¸å…³æ€§çƒ­åŠ›å›¾
            fig = px.imshow(
                corr_matrix,
                text_auto=True,
                aspect="auto",
                title=f"ç›¸å…³æ€§çŸ©é˜µçƒ­åŠ›å›¾ ({corr_method.title()})",
                color_continuous_scale="RdBu_r",
                zmin=-1, zmax=1
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # æ˜¾ç¤ºç›¸å…³çŸ©é˜µæ•°å€¼
            st.markdown("**ç›¸å…³ç³»æ•°çŸ©é˜µ:**")
            st.dataframe(corr_matrix.round(3), use_container_width=True)
            
            # æ‰¾å‡ºå¼ºç›¸å…³å¯¹
            st.markdown("**å¼ºç›¸å…³å˜é‡å¯¹:**")
            strong_corr = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) > 0.7:
                        strong_corr.append({
                            'å˜é‡1': corr_matrix.columns[i],
                            'å˜é‡2': corr_matrix.columns[j],
                            'ç›¸å…³ç³»æ•°': corr_val
                        })
            
            if strong_corr:
                strong_corr_df = pd.DataFrame(strong_corr)
                st.dataframe(strong_corr_df.round(3), use_container_width=True)
            else:
                st.info("æ²¡æœ‰å‘ç°å¼ºç›¸å…³å˜é‡å¯¹ (|r| > 0.7)")
        
        # æ•£ç‚¹å›¾çŸ©é˜µ
        if st.checkbox("æ˜¾ç¤ºæ•£ç‚¹å›¾çŸ©é˜µ") and len(selected_vars) <= 6:
            st.markdown("##### ğŸ“Š æ•£ç‚¹å›¾çŸ©é˜µ")
            fig = px.scatter_matrix(
                df[selected_vars],
                title="å˜é‡é—´æ•£ç‚¹å›¾çŸ©é˜µ"
            )
            fig.update_layout(height=600)
            st.plotly_chart(fig, use_container_width=True)

def crosstab_analysis(df):
    """äº¤å‰è¡¨åˆ†æ"""
    st.markdown("#### ğŸ“‹ äº¤å‰è¡¨åˆ†æ")
    
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    if len(categorical_cols) < 2:
        st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªåˆ†ç±»å˜é‡è¿›è¡Œäº¤å‰è¡¨åˆ†æ")
        return
    
    # é€‰æ‹©å˜é‡
    col1, col2 = st.columns(2)
    with col1:
        var1 = st.selectbox("é€‰æ‹©è¡Œå˜é‡", categorical_cols)
    with col2:
        var2 = st.selectbox("é€‰æ‹©åˆ—å˜é‡", [col for col in categorical_cols if col != var1])
    
    if var1 and var2:
        # åˆ›å»ºäº¤å‰è¡¨
        crosstab = pd.crosstab(df[var1], df[var2], margins=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**é¢‘æ•°äº¤å‰è¡¨:**")
            st.dataframe(crosstab, use_container_width=True)
            
            # ç™¾åˆ†æ¯”äº¤å‰è¡¨
            crosstab_pct = pd.crosstab(df[var1], df[var2], normalize='all') * 100
            st.markdown("**ç™¾åˆ†æ¯”äº¤å‰è¡¨:**")
            st.dataframe(crosstab_pct.round(2), use_container_width=True)
        
        with col2:
            # å †ç§¯æŸ±çŠ¶å›¾
            crosstab_no_margin = pd.crosstab(df[var1], df[var2])
            fig = px.bar(
                crosstab_no_margin,
                title=f"{var1} vs {var2} åˆ†å¸ƒ",
                barmode='stack'
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # çƒ­åŠ›å›¾
            fig2 = px.imshow(
                crosstab_no_margin,
                text_auto=True,
                aspect="auto",
                title="äº¤å‰è¡¨çƒ­åŠ›å›¾"
            )
            fig2.update_layout(height=400)
            st.plotly_chart(fig2, use_container_width=True)
        
        # å¡æ–¹æ£€éªŒ
        st.markdown("##### ğŸ§® å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ")
        from scipy.stats import chi2_contingency
        
        chi2, p_value, dof, expected = chi2_contingency(crosstab_no_margin)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å¡æ–¹ç»Ÿè®¡é‡", f"{chi2:.4f}")
        with col2:
            st.metric("på€¼", f"{p_value:.4f}")
        with col3:
            st.metric("è‡ªç”±åº¦", dof)
        with col4:
            if p_value < 0.05:
                st.success("æ˜¾è‘—ç›¸å…³")
            else:
                st.info("æ— æ˜¾è‘—ç›¸å…³")

def data_visualization(df):
    """æ•°æ®å¯è§†åŒ–"""
    st.markdown("#### ğŸ¨ æ•°æ®å¯è§†åŒ–")
    
    # å›¾è¡¨ç±»å‹é€‰æ‹©
    chart_type = st.selectbox(
        "é€‰æ‹©å›¾è¡¨ç±»å‹",
        [
            "ğŸ“Š æŸ±çŠ¶å›¾", "ğŸ“ˆ æŠ˜çº¿å›¾", "ğŸ”µ æ•£ç‚¹å›¾", "ğŸ“¦ ç®±çº¿å›¾", 
            "ğŸ¥§ é¥¼å›¾", "ğŸ» å°æç´å›¾", "ğŸ”¥ çƒ­åŠ›å›¾", "ğŸ“Š ç›´æ–¹å›¾"
        ]
    )
    
    if chart_type == "ğŸ“Š æŸ±çŠ¶å›¾":
        create_bar_chart(df)
    elif chart_type == "ğŸ“ˆ æŠ˜çº¿å›¾":
        create_line_chart(df)
    elif chart_type == "ğŸ”µ æ•£ç‚¹å›¾":
        create_scatter_plot(df)
    elif chart_type == "ğŸ“¦ ç®±çº¿å›¾":
        create_box_plot(df)
    elif chart_type == "ğŸ¥§ é¥¼å›¾":
        create_pie_chart(df)
    elif chart_type == "ğŸ» å°æç´å›¾":
        create_violin_plot(df)
    elif chart_type == "ğŸ”¥ çƒ­åŠ›å›¾":
        create_heatmap(df)
    elif chart_type == "ğŸ“Š ç›´æ–¹å›¾":
        create_histogram(df)

def create_bar_chart(df):
    """åˆ›å»ºæŸ±çŠ¶å›¾"""
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        x_var = st.selectbox("Xè½´å˜é‡", categorical_cols)
    with col2:
        y_var = st.selectbox("Yè½´å˜é‡", numeric_cols)
    with col3:
        color_var = st.selectbox("é¢œè‰²åˆ†ç»„", [None] + categorical_cols)
    
    if x_var and y_var:
        fig = px.bar(
            df, x=x_var, y=y_var, color=color_var,
            title=f"{y_var} by {x_var}",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def create_line_chart(df):
    """åˆ›å»ºæŠ˜çº¿å›¾"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    all_cols = df.columns.tolist()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        x_var = st.selectbox("Xè½´å˜é‡", all_cols)
    with col2:
        y_var = st.selectbox("Yè½´å˜é‡", numeric_cols)
    with col3:
        color_var = st.selectbox("é¢œè‰²åˆ†ç»„", [None] + df.select_dtypes(include=['object']).columns.tolist())
    
    if x_var and y_var:
        fig = px.line(
            df, x=x_var, y=y_var, color=color_var,
            title=f"{y_var} vs {x_var}",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def create_scatter_plot(df):
    """åˆ›å»ºæ•£ç‚¹å›¾"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    col1, col2 = st.columns(2)
    with col1:
        x_var = st.selectbox("Xè½´å˜é‡", numeric_cols)
        color_var = st.selectbox("é¢œè‰²å˜é‡", [None] + categorical_cols + numeric_cols)
    with col2:
        y_var = st.selectbox("Yè½´å˜é‡", numeric_cols)
        size_var = st.selectbox("å¤§å°å˜é‡", [None] + numeric_cols)
    
    if x_var and y_var:
        fig = px.scatter(
            df, x=x_var, y=y_var, color=color_var, size=size_var,
            title=f"{y_var} vs {x_var}",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def create_box_plot(df):
    """åˆ›å»ºç®±çº¿å›¾"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    col1, col2 = st.columns(2)
    with col1:
        y_var = st.selectbox("æ•°å€¼å˜é‡", numeric_cols)
    with col2:
        x_var = st.selectbox("åˆ†ç»„å˜é‡", [None] + categorical_cols)
    
    if y_var:
        fig = px.box(
            df, x=x_var, y=y_var,
            title=f"{y_var} ç®±çº¿å›¾",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def create_pie_chart(df):
    """åˆ›å»ºé¥¼å›¾"""
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    if not categorical_cols:
        st.warning("âš ï¸ æ²¡æœ‰åˆ†ç±»å˜é‡å¯ç”¨äºé¥¼å›¾")
        return
    
    selected_var = st.selectbox("é€‰æ‹©åˆ†ç±»å˜é‡", categorical_cols)
    
    if selected_var:
        value_counts = df[selected_var].value_counts()
        fig = px.pie(
            values=value_counts.values,
            names=value_counts.index,
            title=f"{selected_var} åˆ†å¸ƒé¥¼å›¾",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def create_violin_plot(df):
    """åˆ›å»ºå°æç´å›¾"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    col1, col2 = st.columns(2)
    with col1:
        y_var = st.selectbox("æ•°å€¼å˜é‡", numeric_cols)
    with col2:
        x_var = st.selectbox("åˆ†ç»„å˜é‡", [None] + categorical_cols)
    
    if y_var:
        fig = px.violin(
            df, x=x_var, y=y_var,
            title=f"{y_var} å°æç´å›¾",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def create_heatmap(df):
    """åˆ›å»ºçƒ­åŠ›å›¾"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if len(numeric_cols) < 2:
        st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼å˜é‡åˆ›å»ºçƒ­åŠ›å›¾")
        return
    
    selected_vars = st.multiselect(
        "é€‰æ‹©å˜é‡", 
        numeric_cols,
        default=numeric_cols[:min(10, len(numeric_cols))]
    )
    
    if len(selected_vars) >= 2:
        corr_matrix = df[selected_vars].corr()
        fig = px.imshow(
            corr_matrix,
            text_auto=True,
            aspect="auto",
            title="ç›¸å…³æ€§çƒ­åŠ›å›¾",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def create_histogram(df):
    """åˆ›å»ºç›´æ–¹å›¾"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        st.warning("âš ï¸ æ²¡æœ‰æ•°å€¼å˜é‡å¯ç”¨äºç›´æ–¹å›¾")
        return
    
    col1, col2 = st.columns(2)
    with col1:
        selected_var = st.selectbox("é€‰æ‹©å˜é‡", numeric_cols)
    with col2:
        bins = st.slider("ç›´æ–¹å›¾ç®±æ•°", 10, 100, 30)
    
    if selected_var:
        fig = px.histogram(
            df, x=selected_var,
            nbins=bins,
            title=f"{selected_var} åˆ†å¸ƒç›´æ–¹å›¾",
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

def data_cleaning_section():
    """æ•°æ®æ¸…æ´—éƒ¨åˆ†"""
    st.markdown("### ğŸ› ï¸ æ•°æ®æ¸…æ´—")
    st.markdown("*æ¸…ç†å’Œé¢„å¤„ç†æ‚¨çš„æ•°æ®ï¼Œç¡®ä¿æ•°æ®è´¨é‡*")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    datasets = get_available_datasets()
    if not datasets:
        st.warning("âš ï¸ è¯·å…ˆå¯¼å…¥æ•°æ®")
        return
    
    # é€‰æ‹©æ•°æ®é›†
    selected_dataset = st.selectbox("é€‰æ‹©æ•°æ®é›†", list(datasets.keys()))
    df = datasets[selected_dataset]['data'].copy()
    
    # æ¸…æ´—é€‰é¡¹
    cleaning_type = st.radio(
        "é€‰æ‹©æ¸…æ´—ç±»å‹",
        ["ğŸ§¹ ç¼ºå¤±å€¼å¤„ç†", "ğŸ”„ é‡å¤å€¼å¤„ç†", "ğŸ¯ å¼‚å¸¸å€¼æ£€æµ‹", "ğŸ”§ æ•°æ®ç±»å‹è½¬æ¢", "ğŸ“ æ•°æ®æ ‡å‡†åŒ–"],
        horizontal=True
    )
    
    if cleaning_type == "ğŸ§¹ ç¼ºå¤±å€¼å¤„ç†":
        missing_value_handling(df, selected_dataset)
    elif cleaning_type == "ğŸ”„ é‡å¤å€¼å¤„ç†":
        duplicate_handling(df, selected_dataset)
    elif cleaning_type == "ğŸ¯ å¼‚å¸¸å€¼æ£€æµ‹":
        outlier_detection(df, selected_dataset)
    elif cleaning_type == "ğŸ”§ æ•°æ®ç±»å‹è½¬æ¢":
        data_type_conversion(df, selected_dataset)
    elif cleaning_type == "ğŸ“ æ•°æ®æ ‡å‡†åŒ–":
        data_standardization(df, selected_dataset)

def missing_value_handling(df, dataset_name):
    """ç¼ºå¤±å€¼å¤„ç†"""
    st.markdown("#### ğŸ§¹ ç¼ºå¤±å€¼å¤„ç†")
    
    # ç¼ºå¤±å€¼æ¦‚è§ˆ
    missing_summary = df.isnull().sum()
    missing_summary = missing_summary[missing_summary > 0].sort_values(ascending=False)
    
    if len(missing_summary) == 0:
        st.success("âœ… æ•°æ®ä¸­æ²¡æœ‰ç¼ºå¤±å€¼!")
        return
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("**ç¼ºå¤±å€¼ç»Ÿè®¡:**")
        missing_df = pd.DataFrame({
            'åˆ—å': missing_summary.index,
            'ç¼ºå¤±æ•°': missing_summary.values,
            'ç¼ºå¤±ç‡(%)': (missing_summary.values / len(df) * 100).round(2)
        })
        st.dataframe(missing_df, use_container_width=True)
    
    with col2:
        # ç¼ºå¤±å€¼å¯è§†åŒ–
        fig = px.bar(
            missing_df, x='åˆ—å', y='ç¼ºå¤±ç‡(%)',
            title="ç¼ºå¤±å€¼åˆ†å¸ƒ",
            color='ç¼ºå¤±ç‡(%)',
            color_continuous_scale='Reds'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # ç¼ºå¤±å€¼å¤„ç†é€‰é¡¹
    st.markdown("**å¤„ç†æ–¹æ³•:**")
    
    col1, col2 = st.columns(2)
    with col1:
        selected_columns = st.multiselect(
            "é€‰æ‹©è¦å¤„ç†çš„åˆ—",
            missing_summary.index.tolist(),
            default=missing_summary.index.tolist()
        )
    
    with col2:
        handling_method = st.selectbox(
            "å¤„ç†æ–¹æ³•",
            ["åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ", "åˆ é™¤å«ç¼ºå¤±å€¼çš„åˆ—", "å‡å€¼å¡«å……", "ä¸­ä½æ•°å¡«å……", "ä¼—æ•°å¡«å……", "å‰å‘å¡«å……", "åå‘å¡«å……", "æ’å€¼å¡«å……", "è‡ªå®šä¹‰å€¼å¡«å……"]
        )
    
    if selected_columns and st.button("ğŸ”§ æ‰§è¡Œå¤„ç†"):
        df_cleaned = df.copy()
        
        if handling_method == "åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ":
            df_cleaned = df_cleaned.dropna(subset=selected_columns)
            st.success(f"âœ… å·²åˆ é™¤ {len(df) - len(df_cleaned)} è¡Œå«ç¼ºå¤±å€¼çš„æ•°æ®")
            
        elif handling_method == "åˆ é™¤å«ç¼ºå¤±å€¼çš„åˆ—":
            df_cleaned = df_cleaned.drop(columns=selected_columns)
            st.success(f"âœ… å·²åˆ é™¤ {len(selected_columns)} åˆ—")
            
        elif handling_method == "å‡å€¼å¡«å……":
            for col in selected_columns:
                if df[col].dtype in ['int64', 'float64']:
                    df_cleaned[col].fillna(df[col].mean(), inplace=True)
            st.success("âœ… å·²ç”¨å‡å€¼å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼")
            
        elif handling_method == "ä¸­ä½æ•°å¡«å……":
            for col in selected_columns:
                if df[col].dtype in ['int64', 'float64']:
                    df_cleaned[col].fillna(df[col].median(), inplace=True)
            st.success("âœ… å·²ç”¨ä¸­ä½æ•°å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼")
            
        elif handling_method == "ä¼—æ•°å¡«å……":
            for col in selected_columns:
                mode_val = df[col].mode()
                if len(mode_val) > 0:
                    df_cleaned[col].fillna(mode_val[0], inplace=True)
            st.success("âœ… å·²ç”¨ä¼—æ•°å¡«å……ç¼ºå¤±å€¼")
            
        elif handling_method == "å‰å‘å¡«å……":
            df_cleaned[selected_columns] = df_cleaned[selected_columns].fillna(method='ffill')
            st.success("âœ… å·²æ‰§è¡Œå‰å‘å¡«å……")
            
        elif handling_method == "åå‘å¡«å……":
            df_cleaned[selected_columns] = df_cleaned[selected_columns].fillna(method='bfill')
            st.success("âœ… å·²æ‰§è¡Œåå‘å¡«å……")
            
        elif handling_method == "æ’å€¼å¡«å……":
            for col in selected_columns:
                if df[col].dtype in ['int64', 'float64']:
                    df_cleaned[col] = df_cleaned[col].interpolate()
            st.success("âœ… å·²æ‰§è¡Œæ’å€¼å¡«å……")
            
        elif handling_method == "è‡ªå®šä¹‰å€¼å¡«å……":
            fill_value = st.text_input("è¾“å…¥å¡«å……å€¼")
            if fill_value:
                df_cleaned[selected_columns] = df_cleaned[selected_columns].fillna(fill_value)
                st.success(f"âœ… å·²ç”¨ '{fill_value}' å¡«å……ç¼ºå¤±å€¼")
        
        # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
        if st.button("ğŸ’¾ ä¿å­˜æ¸…æ´—åçš„æ•°æ®"):
            new_dataset_key = f'dataset_cleaned_{dataset_name}'
            st.session_state[new_dataset_key] = {
                'data': df_cleaned,
                'name': f'å·²æ¸…æ´—_{dataset_name}',
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'quality_score': perform_data_quality_check(df_cleaned),
                'file_size': len(df_cleaned) * len(df_cleaned.columns) * 8
            }
            st.success("âœ… æ¸…æ´—åçš„æ•°æ®å·²ä¿å­˜!")

def duplicate_handling(df, dataset_name):
    """é‡å¤å€¼å¤„ç†"""
    st.markdown("#### ğŸ”„ é‡å¤å€¼å¤„ç†")
    
    # æ£€æŸ¥é‡å¤å€¼
    duplicate_count = df.duplicated().sum()
    total_rows = len(df)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»è¡Œæ•°", total_rows)
    with col2:
        st.metric("é‡å¤è¡Œæ•°", duplicate_count)
    with col3:
        st.metric("é‡å¤ç‡(%)", f"{duplicate_count/total_rows*100:.2f}")
    
    if duplicate_count == 0:
        st.success("âœ… æ•°æ®ä¸­æ²¡æœ‰é‡å¤è¡Œ!")
        return
    
    # æ˜¾ç¤ºé‡å¤è¡Œ
    if st.checkbox("æ˜¾ç¤ºé‡å¤è¡Œ"):
        duplicate_rows = df[df.duplicated(keep=False)]
        st.dataframe(duplicate_rows, use_container_width=True)
    
    # é‡å¤å€¼å¤„ç†é€‰é¡¹
    col1, col2 = st.columns(2)
    with col1:
        subset_cols = st.multiselect(
            "åŸºäºå“ªäº›åˆ—åˆ¤æ–­é‡å¤ (ç•™ç©ºè¡¨ç¤ºæ‰€æœ‰åˆ—)",
            df.columns.tolist()
        )
    
    with col2:
        keep_option = st.selectbox(
            "ä¿ç•™ç­–ç•¥",
            ["first", "last", "False"],
            format_func=lambda x: {"first": "ä¿ç•™ç¬¬ä¸€ä¸ª", "last": "ä¿ç•™æœ€åä¸€ä¸ª", "False": "å…¨éƒ¨åˆ é™¤"}[x]
        )
    
    if st.button("ğŸ—‘ï¸ åˆ é™¤é‡å¤è¡Œ"):
        df_dedup = df.copy()
        
        if subset_cols:
            df_dedup = df_dedup.drop_duplicates(subset=subset_cols, keep=keep_option if keep_option != "False" else False)
        else:
            df_dedup = df_dedup.drop_duplicates(keep=keep_option if keep_option != "False" else False)
        
        removed_count = len(df) - len(df_dedup)
        st.success(f"âœ… å·²åˆ é™¤ {removed_count} è¡Œé‡å¤æ•°æ®")
        
        # ä¿å­˜å»é‡åçš„æ•°æ®
        if st.button("ğŸ’¾ ä¿å­˜å»é‡åçš„æ•°æ®"):
            new_dataset_key = f'dataset_dedup_{dataset_name}'
            st.session_state[new_dataset_key] = {
                'data': df_dedup,
                'name': f'å·²å»é‡_{dataset_name}',
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'quality_score': perform_data_quality_check(df_dedup),
                'file_size': len(df_dedup) * len(df_dedup.columns) * 8
            }
            st.success("âœ… å»é‡åçš„æ•°æ®å·²ä¿å­˜!")

def outlier_detection(df, dataset_name):
    """å¼‚å¸¸å€¼æ£€æµ‹"""
    st.markdown("#### ğŸ¯ å¼‚å¸¸å€¼æ£€æµ‹")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        st.warning("âš ï¸ æ²¡æœ‰æ•°å€¼å‹å˜é‡å¯æ£€æµ‹å¼‚å¸¸å€¼")
        return
    
    # é€‰æ‹©æ£€æµ‹æ–¹æ³•
    detection_method = st.selectbox(
        "å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•",
        ["IQRæ–¹æ³•", "Z-Scoreæ–¹æ³•", "æ”¹è¿›Z-Scoreæ–¹æ³•", "å­¤ç«‹æ£®æ—"]
    )
    
    selected_cols = st.multiselect(
        "é€‰æ‹©è¦æ£€æµ‹çš„åˆ—",
        numeric_cols,
        default=numeric_cols[:3] if len(numeric_cols) >= 3 else numeric_cols
    )
    
    if not selected_cols:
        return
    
    outliers_info = {}
    
    for col in selected_cols:
        data = df[col].dropna()
        
        if detection_method == "IQRæ–¹æ³•":
            Q1 = data.quantile(0.25)
            Q3 = data.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
            
        elif detection_method == "Z-Scoreæ–¹æ³•":
            z_scores = np.abs(stats.zscore(data))
            threshold = st.slider(f"Z-Scoreé˜ˆå€¼ ({col})", 2.0, 4.0, 3.0, 0.1)
            outlier_indices = np.where(z_scores > threshold)[0]
            outliers = df.iloc[outlier_indices]
            
        elif detection_method == "æ”¹è¿›Z-Scoreæ–¹æ³•":
            median = np.median(data)
            mad = np.median(np.abs(data - median))
            modified_z_scores = 0.6745 * (data - median) / mad
            threshold = st.slider(f"æ”¹è¿›Z-Scoreé˜ˆå€¼ ({col})", 2.0, 4.0, 3.5, 0.1)
            outlier_indices = np.where(np.abs(modified_z_scores) > threshold)[0]
            outliers = df.iloc[outlier_indices]
            
        elif detection_method == "å­¤ç«‹æ£®æ—":
            from sklearn.ensemble import IsolationForest
            isolation_forest = IsolationForest(contamination=0.1, random_state=42)
            outlier_labels = isolation_forest.fit_predict(data.values.reshape(-1, 1))
            outlier_indices = np.where(outlier_labels == -1)[0]
            outliers = df.iloc[outlier_indices]
        
        outliers_info[col] = {
            'count': len(outliers),
            'percentage': len(outliers) / len(df) * 100,
            'data': outliers
        }
    
    # æ˜¾ç¤ºå¼‚å¸¸å€¼ç»Ÿè®¡
    st.markdown("**å¼‚å¸¸å€¼ç»Ÿè®¡:**")
    
    outlier_summary = pd.DataFrame({
        'åˆ—å': list(outliers_info.keys()),
        'å¼‚å¸¸å€¼æ•°é‡': [info['count'] for info in outliers_info.values()],
        'å¼‚å¸¸å€¼æ¯”ä¾‹(%)': [round(info['percentage'], 2) for info in outliers_info.values()]
    })
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.dataframe(outlier_summary, use_container_width=True)
    
    with col2:
        fig = px.bar(
            outlier_summary, x='åˆ—å', y='å¼‚å¸¸å€¼æ¯”ä¾‹(%)',
            title="å¼‚å¸¸å€¼åˆ†å¸ƒ",
            color='å¼‚å¸¸å€¼æ¯”ä¾‹(%)',
            color_continuous_scale='Oranges'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # æ˜¾ç¤ºå¼‚å¸¸å€¼è¯¦æƒ…
    for col, info in outliers_info.items():
        if info['count'] > 0:
            with st.expander(f"ğŸ“Š {col} çš„å¼‚å¸¸å€¼è¯¦æƒ… ({info['count']} ä¸ª)"):
                st.dataframe(info['data'], use_container_width=True)
                
                # å¼‚å¸¸å€¼å¯è§†åŒ–
                fig = px.box(df, y=col, title=f"{col} ç®±çº¿å›¾ (å¼‚å¸¸å€¼æ ‡è®°)")
                st.plotly_chart(fig, use_container_width=True)
    
    # å¼‚å¸¸å€¼å¤„ç†
    st.markdown("**å¼‚å¸¸å€¼å¤„ç†:**")
    handling_method = st.selectbox(
        "å¤„ç†æ–¹æ³•",
        ["åˆ é™¤å¼‚å¸¸å€¼", "ç”¨ä¸­ä½æ•°æ›¿æ¢", "ç”¨å‡å€¼æ›¿æ¢", "ä¿ç•™å¼‚å¸¸å€¼"]
    )
    
    if st.button("ğŸ”§ å¤„ç†å¼‚å¸¸å€¼"):
        df_processed = df.copy()
        
        for col, info in outliers_info.items():
            if info['count'] > 0:
                outlier_indices = info['data'].index
                
                if handling_method == "åˆ é™¤å¼‚å¸¸å€¼":
                    df_processed = df_processed.drop(outlier_indices)
                elif handling_method == "ç”¨ä¸­ä½æ•°æ›¿æ¢":
                    median_val = df[col].median()
                    df_processed.loc[outlier_indices, col] = median_val
                elif handling_method == "ç”¨å‡å€¼æ›¿æ¢":
                    mean_val = df[col].mean()
                    df_processed.loc[outlier_indices, col] = mean_val
        
        if handling_method != "ä¿ç•™å¼‚å¸¸å€¼":
            st.success(f"âœ… å¼‚å¸¸å€¼å¤„ç†å®Œæˆ")
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            if st.button("ğŸ’¾ ä¿å­˜å¤„ç†åçš„æ•°æ®"):
                new_dataset_key = f'dataset_outlier_processed_{dataset_name}'
                st.session_state[new_dataset_key] = {
                    'data': df_processed,
                    'name': f'å¼‚å¸¸å€¼å·²å¤„ç†_{dataset_name}',
                    'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'quality_score': perform_data_quality_check(df_processed),
                    'file_size': len(df_processed) * len(df_processed.columns) * 8
                }
                st.success("âœ… å¤„ç†åçš„æ•°æ®å·²ä¿å­˜!")

def data_type_conversion(df, dataset_name):
    """æ•°æ®ç±»å‹è½¬æ¢"""
    st.markdown("#### ğŸ”§ æ•°æ®ç±»å‹è½¬æ¢")
    
    # æ˜¾ç¤ºå½“å‰æ•°æ®ç±»å‹
    st.markdown("**å½“å‰æ•°æ®ç±»å‹:**")
    
    dtype_info = pd.DataFrame({
        'åˆ—å': df.columns,
        'å½“å‰ç±»å‹': [str(dtype) for dtype in df.dtypes],
        'éç©ºå€¼æ•°': [df[col].count() for col in df.columns],
        'ç¤ºä¾‹å€¼': [str(df[col].dropna().iloc[0]) if len(df[col].dropna()) > 0 else 'N/A' for col in df.columns]
    })
    
    st.dataframe(dtype_info, use_container_width=True)
    
    # ç±»å‹è½¬æ¢é€‰é¡¹
    st.markdown("**ç±»å‹è½¬æ¢:**")
    
    col1, col2 = st.columns(2)
    with col1:
        selected_col = st.selectbox("é€‰æ‹©è¦è½¬æ¢çš„åˆ—", df.columns.tolist())
    with col2:
        target_type = st.selectbox(
            "ç›®æ ‡ç±»å‹",
            ["int64", "float64", "object", "datetime64", "category", "bool"]
        )
    
    if selected_col and st.button("ğŸ”„ æ‰§è¡Œè½¬æ¢"):
        df_converted = df.copy()
        
        try:
            if target_type == "int64":
                df_converted[selected_col] = pd.to_numeric(df_converted[selected_col], errors='coerce').astype('Int64')
            elif target_type == "float64":
                df_converted[selected_col] = pd.to_numeric(df_converted[selected_col], errors='coerce')
            elif target_type == "object":
                df_converted[selected_col] = df_converted[selected_col].astype(str)
            elif target_type == "datetime64":
                df_converted[selected_col] = pd.to_datetime(df_converted[selected_col], errors='coerce')
            elif target_type == "category":
                df_converted[selected_col] = df_converted[selected_col].astype('category')
            elif target_type == "bool":
                df_converted[selected_col] = df_converted[selected_col].astype(bool)
            
            st.success(f"âœ… åˆ— '{selected_col}' å·²è½¬æ¢ä¸º {target_type} ç±»å‹")
            
            # æ˜¾ç¤ºè½¬æ¢åçš„ä¿¡æ¯
            st.markdown("**è½¬æ¢åä¿¡æ¯:**")
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"è½¬æ¢å‰ç±»å‹: {df[selected_col].dtype}")
                st.write(f"è½¬æ¢åç±»å‹: {df_converted[selected_col].dtype}")
            with col2:
                st.write(f"è½¬æ¢å‰éç©ºå€¼: {df[selected_col].count()}")
                st.write(f"è½¬æ¢åéç©ºå€¼: {df_converted[selected_col].count()}")
            
            # ä¿å­˜è½¬æ¢åçš„æ•°æ®
            if st.button("ğŸ’¾ ä¿å­˜è½¬æ¢åçš„æ•°æ®"):
                new_dataset_key = f'dataset_converted_{dataset_name}'
                st.session_state[new_dataset_key] = {
                    'data': df_converted,
                    'name': f'ç±»å‹å·²è½¬æ¢_{dataset_name}',
                    'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'quality_score': perform_data_quality_check(df_converted),
                    'file_size': len(df_converted) * len(df_converted.columns) * 8
                }
                st.success("âœ… è½¬æ¢åçš„æ•°æ®å·²ä¿å­˜!")
                
        except Exception as e:
            st.error(f"âŒ è½¬æ¢å¤±è´¥: {str(e)}")

def data_standardization(df, dataset_name):
    """æ•°æ®æ ‡å‡†åŒ–"""
    st.markdown("#### ğŸ“ æ•°æ®æ ‡å‡†åŒ–")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        st.warning("âš ï¸ æ²¡æœ‰æ•°å€¼å‹å˜é‡å¯è¿›è¡Œæ ‡å‡†åŒ–")
        return
    
    # æ ‡å‡†åŒ–æ–¹æ³•é€‰æ‹©
    standardization_method = st.selectbox(
        "æ ‡å‡†åŒ–æ–¹æ³•",
        ["Z-Scoreæ ‡å‡†åŒ–", "Min-Maxæ ‡å‡†åŒ–", "Robustæ ‡å‡†åŒ–", "å•ä½å‘é‡æ ‡å‡†åŒ–"]
    )
    
    selected_cols = st.multiselect(
        "é€‰æ‹©è¦æ ‡å‡†åŒ–çš„åˆ—",
        numeric_cols,
        default=numeric_cols
    )
    
    if selected_cols and st.button("ğŸ“Š æ‰§è¡Œæ ‡å‡†åŒ–"):
        df_standardized = df.copy()
        
        from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer
        
        if standardization_method == "Z-Scoreæ ‡å‡†åŒ–":
            scaler = StandardScaler()
        elif standardization_method == "Min-Maxæ ‡å‡†åŒ–":
            scaler = MinMaxScaler()
        elif standardization_method == "Robustæ ‡å‡†åŒ–":
            scaler = RobustScaler()
        elif standardization_method == "å•ä½å‘é‡æ ‡å‡†åŒ–":
            scaler = Normalizer()
        
        # æ‰§è¡Œæ ‡å‡†åŒ–
        df_standardized[selected_cols] = scaler.fit_transform(df[selected_cols])
        
        st.success(f"âœ… å·²å®Œæˆ {standardization_method}")
        
        # æ˜¾ç¤ºæ ‡å‡†åŒ–å‰åå¯¹æ¯”
        st.markdown("**æ ‡å‡†åŒ–å‰åå¯¹æ¯”:**")
        
        comparison_data = []
        for col in selected_cols:
            comparison_data.append({
                'åˆ—å': col,
                'åŸå§‹å‡å€¼': df[col].mean(),
                'åŸå§‹æ ‡å‡†å·®': df[col].std(),
                'æ ‡å‡†åŒ–åå‡å€¼': df_standardized[col].mean(),
                'æ ‡å‡†åŒ–åæ ‡å‡†å·®': df_standardized[col].std()
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df.round(4), use_container_width=True)
        
        # å¯è§†åŒ–å¯¹æ¯”
        if len(selected_cols) <= 4:
            fig = make_subplots(
                rows=2, cols=len(selected_cols),
                subplot_titles=[f'{col} (åŸå§‹)' for col in selected_cols] + [f'{col} (æ ‡å‡†åŒ–)' for col in selected_cols]
            )
            
            for i, col in enumerate(selected_cols):
                # åŸå§‹æ•°æ®åˆ†å¸ƒ
                fig.add_trace(
                    go.Histogram(x=df[col], name=f'{col}_åŸå§‹', showlegend=False),
                    row=1, col=i+1
                )
                # æ ‡å‡†åŒ–ååˆ†å¸ƒ
                fig.add_trace(
                    go.Histogram(x=df_standardized[col], name=f'{col}_æ ‡å‡†åŒ–', showlegend=False),
                    row=2, col=i+1
                )
            
            fig.update_layout(height=500, title="æ ‡å‡†åŒ–å‰ååˆ†å¸ƒå¯¹æ¯”")
            st.plotly_chart(fig, use_container_width=True)
        
        # ä¿å­˜æ ‡å‡†åŒ–åçš„æ•°æ®
        if st.button("ğŸ’¾ ä¿å­˜æ ‡å‡†åŒ–åçš„æ•°æ®"):
            new_dataset_key = f'dataset_standardized_{dataset_name}'
            st.session_state[new_dataset_key] = {
                'data': df_standardized,
                'name': f'å·²æ ‡å‡†åŒ–_{dataset_name}',
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'quality_score': perform_data_quality_check(df_standardized),
                'file_size': len(df_standardized) * len(df_standardized.columns) * 8
            }
            st.success("âœ… æ ‡å‡†åŒ–åçš„æ•°æ®å·²ä¿å­˜!")

def variable_management_section():
    """å˜é‡ç®¡ç†éƒ¨åˆ†"""
    st.markdown("### ğŸ“‹ å˜é‡ç®¡ç†")
    st.markdown("*ç®¡ç†å’Œç¼–è¾‘æ•°æ®é›†ä¸­çš„å˜é‡ä¿¡æ¯*")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    datasets = get_available_datasets()
    if not datasets:
        st.warning("âš ï¸ è¯·å…ˆå¯¼å…¥æ•°æ®")
        return
    
    # é€‰æ‹©æ•°æ®é›†
    selected_dataset = st.selectbox("é€‰æ‹©æ•°æ®é›†", list(datasets.keys()))
    df = datasets[selected_dataset]['data']
    
    # å˜é‡ç®¡ç†é€‰é¡¹
    management_type = st.radio(
        "ç®¡ç†ç±»å‹",
        ["ğŸ“ å˜é‡é‡å‘½å", "ğŸ—‚ï¸ å˜é‡åˆ†ç±»", "ğŸ“Š å˜é‡ç¼–ç ", "ğŸ”„ å˜é‡åˆ›å»º", "ğŸ—‘ï¸ å˜é‡åˆ é™¤"],
        horizontal=True
    )
    
    if management_type == "ğŸ“ å˜é‡é‡å‘½å":
        variable_renaming(df, selected_dataset)
    elif management_type == "ğŸ—‚ï¸ å˜é‡åˆ†ç±»":
        variable_categorization(df, selected_dataset)
    elif management_type == "ğŸ“Š å˜é‡ç¼–ç ":
        variable_encoding(df, selected_dataset)
    elif management_type == "ğŸ”„ å˜é‡åˆ›å»º":
        variable_creation(df, selected_dataset)
    elif management_type == "ğŸ—‘ï¸ å˜é‡åˆ é™¤":
        variable_deletion(df, selected_dataset)

def variable_renaming(df, dataset_name):
    """å˜é‡é‡å‘½å"""
    st.markdown("#### ğŸ“ å˜é‡é‡å‘½å")
    
    # æ˜¾ç¤ºå½“å‰å˜é‡å
    st.markdown("**å½“å‰å˜é‡åˆ—è¡¨:**")
    current_names = pd.DataFrame({
        'åºå·': range(1, len(df.columns) + 1),
        'å½“å‰åç§°': df.columns.tolist(),
        'æ•°æ®ç±»å‹': [str(dtype) for dtype in df.dtypes],
        'éç©ºå€¼æ•°': [df[col].count() for col in df.columns]
    })
    st.dataframe(current_names, use_container_width=True)
    
    # é‡å‘½åé€‰é¡¹
    rename_method = st.radio(
        "é‡å‘½åæ–¹å¼",
        ["å•ä¸ªé‡å‘½å", "æ‰¹é‡é‡å‘½å", "ä½¿ç”¨æ˜ å°„æ–‡ä»¶"],
        horizontal=True
    )
    
    if rename_method == "å•ä¸ªé‡å‘½å":
        col1, col2 = st.columns(2)
        with col1:
            old_name = st.selectbox("é€‰æ‹©è¦é‡å‘½åçš„å˜é‡", df.columns.tolist())
        with col2:
            new_name = st.text_input("æ–°å˜é‡å", value=old_name)
        
        if old_name != new_name and new_name and st.button("ğŸ”„ é‡å‘½å"):
            df_renamed = df.copy()
            df_renamed = df_renamed.rename(columns={old_name: new_name})
            
            st.success(f"âœ… å˜é‡ '{old_name}' å·²é‡å‘½åä¸º '{new_name}'")
            
            # ä¿å­˜é‡å‘½ååçš„æ•°æ®
            if st.button("ğŸ’¾ ä¿å­˜é‡å‘½ååçš„æ•°æ®"):
                new_dataset_key = f'dataset_renamed_{dataset_name}'
                st.session_state[new_dataset_key] = {
                    'data': df_renamed,
                    'name': f'å·²é‡å‘½å_{dataset_name}',
                    'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'quality_score': perform_data_quality_check(df_renamed),
                    'file_size': len(df_renamed) * len(df_renamed.columns) * 8
                }
                st.success("âœ… é‡å‘½ååçš„æ•°æ®å·²ä¿å­˜!")
    
    elif rename_method == "æ‰¹é‡é‡å‘½å":
        st.markdown("**æ‰¹é‡é‡å‘½åè§„åˆ™:**")
        
        rule_type = st.selectbox(
            "è§„åˆ™ç±»å‹",
            ["æ·»åŠ å‰ç¼€", "æ·»åŠ åç¼€", "æ›¿æ¢æ–‡æœ¬", "è½¬æ¢å¤§å°å†™"]
        )
        
        if rule_type == "æ·»åŠ å‰ç¼€":
            prefix = st.text_input("å‰ç¼€")
            if prefix and st.button("ğŸ”„ åº”ç”¨å‰ç¼€"):
                new_columns = [f"{prefix}{col}" for col in df.columns]
                df_renamed = df.copy()
                df_renamed.columns = new_columns
                st.success(f"âœ… å·²ä¸ºæ‰€æœ‰å˜é‡æ·»åŠ å‰ç¼€ '{prefix}'")
                
        elif rule_type == "æ·»åŠ åç¼€":
            suffix = st.text_input("åç¼€")
            if suffix and st.button("ğŸ”„ åº”ç”¨åç¼€"):
                new_columns = [f"{col}{suffix}" for col in df.columns]
                df_renamed = df.copy()
                df_renamed.columns = new_columns
                st.success(f"âœ… å·²ä¸ºæ‰€æœ‰å˜é‡æ·»åŠ åç¼€ '{suffix}'")
                
        elif rule_type == "æ›¿æ¢æ–‡æœ¬":
            col1, col2 = st.columns(2)
            with col1:
                old_text = st.text_input("è¦æ›¿æ¢çš„æ–‡æœ¬")
            with col2:
                new_text = st.text_input("æ›¿æ¢ä¸º")
            
            if old_text and st.button("ğŸ”„ æ‰§è¡Œæ›¿æ¢"):
                new_columns = [col.replace(old_text, new_text) for col in df.columns]
                df_renamed = df.copy()
                df_renamed.columns = new_columns
                st.success(f"âœ… å·²å°† '{old_text}' æ›¿æ¢ä¸º '{new_text}'")
                
        elif rule_type == "è½¬æ¢å¤§å°å†™":
            case_type = st.selectbox("è½¬æ¢ç±»å‹", ["å…¨éƒ¨å¤§å†™", "å…¨éƒ¨å°å†™", "é¦–å­—æ¯å¤§å†™"])
            
            if st.button("ğŸ”„ è½¬æ¢å¤§å°å†™"):
                if case_type == "å…¨éƒ¨å¤§å†™":
                    new_columns = [col.upper() for col in df.columns]
                elif case_type == "å…¨éƒ¨å°å†™":
                    new_columns = [col.lower() for col in df.columns]
                elif case_type == "é¦–å­—æ¯å¤§å†™":
                    new_columns = [col.title() for col in df.columns]
                
                df_renamed = df.copy()
                df_renamed.columns = new_columns
                st.success(f"âœ… å·²è½¬æ¢ä¸º{case_type}")

def variable_categorization(df, dataset_name):
    """å˜é‡åˆ†ç±»"""
    st.markdown("#### ğŸ—‚ï¸ å˜é‡åˆ†ç±»")
    
    # è‡ªåŠ¨è¯†åˆ«å˜é‡ç±»å‹
    numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_vars = df.select_dtypes(include=['object']).columns.tolist()
    datetime_vars = df.select_dtypes(include=['datetime64']).columns.tolist()
    
    # æ˜¾ç¤ºè‡ªåŠ¨åˆ†ç±»ç»“æœ
    st.markdown("**è‡ªåŠ¨å˜é‡åˆ†ç±»:**")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**ğŸ”¢ æ•°å€¼å˜é‡:**")
        for var in numeric_vars:
            st.write(f"â€¢ {var}")
    
    with col2:
        st.markdown("**ğŸ”¤ åˆ†ç±»å˜é‡:**")
        for var in categorical_vars:
            st.write(f"â€¢ {var}")
    
    with col3:
        st.markdown("**ğŸ“… æ—¥æœŸå˜é‡:**")
        for var in datetime_vars:
            st.write(f"â€¢ {var}")
    
    # æ‰‹åŠ¨åˆ†ç±»è°ƒæ•´
    st.markdown("**æ‰‹åŠ¨åˆ†ç±»è°ƒæ•´:**")
    
    selected_var = st.selectbox("é€‰æ‹©å˜é‡", df.columns.tolist())
    
        if selected_var:
        current_type = "æ•°å€¼å‹" if selected_var in numeric_vars else "åˆ†ç±»å‹" if selected_var in categorical_vars else "æ—¥æœŸå‹"
        st.info(f"å½“å‰ç±»å‹: {current_type}")
        
        new_type = st.selectbox(
            "é‡æ–°åˆ†ç±»ä¸º",
            ["æ•°å€¼å‹", "åˆ†ç±»å‹", "æ—¥æœŸå‹", "äºŒå…ƒå‹", "æœ‰åºåˆ†ç±»å‹"]
        )
        
        if st.button("ğŸ”„ åº”ç”¨åˆ†ç±»"):
            df_categorized = df.copy()
            
            try:
                if new_type == "æ•°å€¼å‹":
                    df_categorized[selected_var] = pd.to_numeric(df_categorized[selected_var], errors='coerce')
                elif new_type == "åˆ†ç±»å‹":
                    df_categorized[selected_var] = df_categorized[selected_var].astype('category')
                elif new_type == "æ—¥æœŸå‹":
                    df_categorized[selected_var] = pd.to_datetime(df_categorized[selected_var], errors='coerce')
                elif new_type == "äºŒå…ƒå‹":
                    unique_vals = df[selected_var].unique()
                    if len(unique_vals) <= 2:
                        df_categorized[selected_var] = df_categorized[selected_var].astype('category')
                    else:
                        st.warning("âš ï¸ è¯¥å˜é‡æœ‰è¶…è¿‡2ä¸ªå”¯ä¸€å€¼ï¼Œä¸é€‚åˆä½œä¸ºäºŒå…ƒå˜é‡")
                elif new_type == "æœ‰åºåˆ†ç±»å‹":
                    order = st.text_input("è¾“å…¥é¡ºåº (ç”¨é€—å·åˆ†éš”)", placeholder="ä½,ä¸­,é«˜")
                    if order:
                        order_list = [x.strip() for x in order.split(',')]
                        df_categorized[selected_var] = pd.Categorical(df_categorized[selected_var], categories=order_list, ordered=True)
                
                st.success(f"âœ… å˜é‡ '{selected_var}' å·²é‡æ–°åˆ†ç±»ä¸º {new_type}")
                
            except Exception as e:
                st.error(f"âŒ åˆ†ç±»å¤±è´¥: {str(e)}")

def variable_encoding(df, dataset_name):
    """å˜é‡ç¼–ç """
    st.markdown("#### ğŸ“Š å˜é‡ç¼–ç ")
    
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    if not categorical_cols:
        st.warning("âš ï¸ æ²¡æœ‰åˆ†ç±»å˜é‡éœ€è¦ç¼–ç ")
        return
    
    # ç¼–ç æ–¹æ³•é€‰æ‹©
    encoding_method = st.selectbox(
        "ç¼–ç æ–¹æ³•",
        ["æ ‡ç­¾ç¼–ç ", "ç‹¬çƒ­ç¼–ç ", "ç›®æ ‡ç¼–ç ", "äºŒè¿›åˆ¶ç¼–ç ", "å“ˆå¸Œç¼–ç "]
    )
    
    selected_col = st.selectbox("é€‰æ‹©è¦ç¼–ç çš„å˜é‡", categorical_cols)
    
    if selected_col:
        # æ˜¾ç¤ºå˜é‡ä¿¡æ¯
        unique_values = df[selected_col].unique()
        st.info(f"å”¯ä¸€å€¼æ•°é‡: {len(unique_values)}")
        st.write("å”¯ä¸€å€¼:", unique_values[:10].tolist() + (['...'] if len(unique_values) > 10 else []))
        
        if st.button("ğŸ”¢ æ‰§è¡Œç¼–ç "):
            df_encoded = df.copy()
            
            if encoding_method == "æ ‡ç­¾ç¼–ç ":
                from sklearn.preprocessing import LabelEncoder
                le = LabelEncoder()
                df_encoded[f'{selected_col}_encoded'] = le.fit_transform(df_encoded[selected_col].astype(str))
                st.success("âœ… æ ‡ç­¾ç¼–ç å®Œæˆ")
                
                # æ˜¾ç¤ºç¼–ç æ˜ å°„
                mapping = dict(zip(le.classes_, le.transform(le.classes_)))
                st.write("ç¼–ç æ˜ å°„:", mapping)
                
            elif encoding_method == "ç‹¬çƒ­ç¼–ç ":
                encoded_df = pd.get_dummies(df_encoded[selected_col], prefix=selected_col)
                df_encoded = pd.concat([df_encoded, encoded_df], axis=1)
                st.success("âœ… ç‹¬çƒ­ç¼–ç å®Œæˆ")
                st.info(f"ç”Ÿæˆäº† {len(encoded_df.columns)} ä¸ªæ–°å˜é‡")
                
            elif encoding_method == "ç›®æ ‡ç¼–ç ":
                target_col = st.selectbox("é€‰æ‹©ç›®æ ‡å˜é‡", df.select_dtypes(include=[np.number]).columns.tolist())
                if target_col:
                    target_mean = df.groupby(selected_col)[target_col].mean()
                    df_encoded[f'{selected_col}_target_encoded'] = df_encoded[selected_col].map(target_mean)
                    st.success("âœ… ç›®æ ‡ç¼–ç å®Œæˆ")
                
            elif encoding_method == "äºŒè¿›åˆ¶ç¼–ç ":
                try:
                    import category_encoders as ce
                    encoder = ce.BinaryEncoder(cols=[selected_col])
                    encoded_df = encoder.fit_transform(df_encoded[selected_col])
                    df_encoded = pd.concat([df_encoded, encoded_df], axis=1)
                    st.success("âœ… äºŒè¿›åˆ¶ç¼–ç å®Œæˆ")
                except ImportError:
                    st.error("âŒ éœ€è¦å®‰è£… category_encoders åº“")
                
            elif encoding_method == "å“ˆå¸Œç¼–ç ":
                try:
                    import category_encoders as ce
                    n_components = st.number_input("å“ˆå¸Œç»´åº¦", min_value=2, max_value=20, value=8)
                    encoder = ce.HashingEncoder(cols=[selected_col], n_components=n_components)
                    encoded_df = encoder.fit_transform(df_encoded[selected_col])
                    df_encoded = pd.concat([df_encoded, encoded_df], axis=1)
                    st.success("âœ… å“ˆå¸Œç¼–ç å®Œæˆ")
                except ImportError:
                    st.error("âŒ éœ€è¦å®‰è£… category_encoders åº“")
            
            # ä¿å­˜ç¼–ç åçš„æ•°æ®
            if st.button("ğŸ’¾ ä¿å­˜ç¼–ç åçš„æ•°æ®"):
                new_dataset_key = f'dataset_encoded_{dataset_name}'
                st.session_state[new_dataset_key] = {
                    'data': df_encoded,
                    'name': f'å·²ç¼–ç _{dataset_name}',
                    'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'quality_score': perform_data_quality_check(df_encoded),
                    'file_size': len(df_encoded) * len(df_encoded.columns) * 8
                }
                st.success("âœ… ç¼–ç åçš„æ•°æ®å·²ä¿å­˜!")

def variable_creation(df, dataset_name):
    """å˜é‡åˆ›å»º"""
    st.markdown("#### ğŸ”„ å˜é‡åˆ›å»º")
    
    creation_type = st.selectbox(
        "åˆ›å»ºç±»å‹",
        ["æ•°å­¦è¿ç®—", "æ¡ä»¶åˆ›å»º", "åˆ†ç»„ç»Ÿè®¡", "æ—¶é—´ç‰¹å¾", "æ–‡æœ¬å¤„ç†"]
    )
    
    if creation_type == "æ•°å­¦è¿ç®—":
        st.markdown("**æ•°å­¦è¿ç®—åˆ›å»ºæ–°å˜é‡:**")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) < 2:
            st.warning("âš ï¸ éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼å˜é‡è¿›è¡Œæ•°å­¦è¿ç®—")
            return
        
        col1, col2, col3 = st.columns(3)
        with col1:
            var1 = st.selectbox("å˜é‡1", numeric_cols)
        with col2:
            operation = st.selectbox("è¿ç®—", ["+", "-", "*", "/", "**", "log", "sqrt"])
        with col3:
            if operation in ["+", "-", "*", "/", "**"]:
                var2 = st.selectbox("å˜é‡2", numeric_cols)
            else:
                var2 = None
        
        new_var_name = st.text_input("æ–°å˜é‡å", value=f"{var1}_{operation}_{var2}" if var2 else f"{operation}_{var1}")
        
        if st.button("â• åˆ›å»ºå˜é‡"):
            df_new = df.copy()
            
            try:
                if operation == "+":
                    df_new[new_var_name] = df_new[var1] + df_new[var2]
                elif operation == "-":
                    df_new[new_var_name] = df_new[var1] - df_new[var2]
                elif operation == "*":
                    df_new[new_var_name] = df_new[var1] * df_new[var2]
                elif operation == "/":
                    df_new[new_var_name] = df_new[var1] / df_new[var2]
                elif operation == "**":
                    df_new[new_var_name] = df_new[var1] ** df_new[var2]
                elif operation == "log":
                    df_new[new_var_name] = np.log(df_new[var1])
                elif operation == "sqrt":
                    df_new[new_var_name] = np.sqrt(df_new[var1])
                
                st.success(f"âœ… æ–°å˜é‡ '{new_var_name}' åˆ›å»ºæˆåŠŸ")
                
                # æ˜¾ç¤ºæ–°å˜é‡çš„ç»Ÿè®¡ä¿¡æ¯
                st.write("æ–°å˜é‡ç»Ÿè®¡ä¿¡æ¯:")
                st.write(df_new[new_var_name].describe())
                
            except Exception as e:
                st.error(f"âŒ åˆ›å»ºå¤±è´¥: {str(e)}")
    
    elif creation_type == "æ¡ä»¶åˆ›å»º":
        st.markdown("**æ¡ä»¶åˆ›å»ºæ–°å˜é‡:**")
        
        condition_col = st.selectbox("æ¡ä»¶å˜é‡", df.columns.tolist())
        condition_type = st.selectbox("æ¡ä»¶ç±»å‹", ["æ•°å€¼æ¡ä»¶", "æ–‡æœ¬æ¡ä»¶", "å¤šæ¡ä»¶"])
        
        new_var_name = st.text_input("æ–°å˜é‡å", value=f"{condition_col}_category")
        
        if condition_type == "æ•°å€¼æ¡ä»¶":
            threshold = st.number_input("é˜ˆå€¼")
            operator = st.selectbox("æ“ä½œç¬¦", [">", ">=", "<", "<=", "==", "!="])
            
            true_value = st.text_input("æ»¡è¶³æ¡ä»¶æ—¶çš„å€¼", value="é«˜")
            false_value = st.text_input("ä¸æ»¡è¶³æ¡ä»¶æ—¶çš„å€¼", value="ä½")
            
            if st.button("â• åˆ›å»ºæ¡ä»¶å˜é‡"):
                df_new = df.copy()
                
                if operator == ">":
                    condition = df_new[condition_col] > threshold
                elif operator == ">=":
                    condition = df_new[condition_col] >= threshold
                elif operator == "<":
                    condition = df_new[condition_col] < threshold
                elif operator == "<=":
                    condition = df_new[condition_col] <= threshold
                elif operator == "==":
                    condition = df_new[condition_col] == threshold
                elif operator == "!=":
                    condition = df_new[condition_col] != threshold
                
                df_new[new_var_name] = np.where(condition, true_value, false_value)
                st.success(f"âœ… æ¡ä»¶å˜é‡ '{new_var_name}' åˆ›å»ºæˆåŠŸ")
        
        elif condition_type == "æ–‡æœ¬æ¡ä»¶":
            text_condition = st.text_input("åŒ…å«æ–‡æœ¬")
            true_value = st.text_input("åŒ…å«æ—¶çš„å€¼", value="æ˜¯")
            false_value = st.text_input("ä¸åŒ…å«æ—¶çš„å€¼", value="å¦")
            
            if st.button("â• åˆ›å»ºæ–‡æœ¬æ¡ä»¶å˜é‡"):
                df_new = df.copy()
                condition = df_new[condition_col].astype(str).str.contains(text_condition, na=False)
                df_new[new_var_name] = np.where(condition, true_value, false_value)
                st.success(f"âœ… æ–‡æœ¬æ¡ä»¶å˜é‡ '{new_var_name}' åˆ›å»ºæˆåŠŸ")

def variable_deletion(df, dataset_name):
    """å˜é‡åˆ é™¤"""
    st.markdown("#### ğŸ—‘ï¸ å˜é‡åˆ é™¤")
    
    # æ˜¾ç¤ºå˜é‡åˆ—è¡¨
    st.markdown("**å½“å‰å˜é‡åˆ—è¡¨:**")
    
    var_info = pd.DataFrame({
        'å˜é‡å': df.columns,
        'æ•°æ®ç±»å‹': [str(dtype) for dtype in df.dtypes],
        'éç©ºå€¼æ•°': [df[col].count() for col in df.columns],
        'ç¼ºå¤±å€¼æ•°': [df[col].isnull().sum() for col in df.columns],
        'å”¯ä¸€å€¼æ•°': [df[col].nunique() for col in df.columns]
    })
    
    st.dataframe(var_info, use_container_width=True)
    
    # åˆ é™¤é€‰é¡¹
    deletion_method = st.radio(
        "åˆ é™¤æ–¹å¼",
        ["æ‰‹åŠ¨é€‰æ‹©", "æŒ‰æ¡ä»¶åˆ é™¤", "åˆ é™¤é‡å¤åˆ—"],
        horizontal=True
    )
    
    if deletion_method == "æ‰‹åŠ¨é€‰æ‹©":
        selected_vars = st.multiselect(
            "é€‰æ‹©è¦åˆ é™¤çš„å˜é‡",
            df.columns.tolist(),
            help="å¯ä»¥é€‰æ‹©å¤šä¸ªå˜é‡è¿›è¡Œåˆ é™¤"
        )
        
        if selected_vars and st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­å˜é‡"):
            df_deleted = df.drop(columns=selected_vars)
            st.success(f"âœ… å·²åˆ é™¤ {len(selected_vars)} ä¸ªå˜é‡")
            
            # ä¿å­˜åˆ é™¤åçš„æ•°æ®
            if st.button("ğŸ’¾ ä¿å­˜åˆ é™¤åçš„æ•°æ®"):
                new_dataset_key = f'dataset_deleted_{dataset_name}'
                st.session_state[new_dataset_key] = {
                    'data': df_deleted,
                    'name': f'å·²åˆ é™¤å˜é‡_{dataset_name}',
                    'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'quality_score': perform_data_quality_check(df_deleted),
                    'file_size': len(df_deleted) * len(df_deleted.columns) * 8
                }
                st.success("âœ… åˆ é™¤åçš„æ•°æ®å·²ä¿å­˜!")
    
    elif deletion_method == "æŒ‰æ¡ä»¶åˆ é™¤":
        condition_type = st.selectbox(
            "åˆ é™¤æ¡ä»¶",
            ["ç¼ºå¤±å€¼æ¯”ä¾‹è¿‡é«˜", "å”¯ä¸€å€¼è¿‡å°‘", "æ–¹å·®è¿‡å°", "ç›¸å…³æ€§è¿‡é«˜"]
        )
        
        if condition_type == "ç¼ºå¤±å€¼æ¯”ä¾‹è¿‡é«˜":
            threshold = st.slider("ç¼ºå¤±å€¼æ¯”ä¾‹é˜ˆå€¼", 0.0, 1.0, 0.5, 0.1)
            missing_ratios = df.isnull().sum() / len(df)
            to_delete = missing_ratios[missing_ratios > threshold].index.tolist()
            
            if to_delete:
                st.warning(f"å°†åˆ é™¤ {len(to_delete)} ä¸ªå˜é‡: {to_delete}")
                if st.button("ğŸ—‘ï¸ æ‰§è¡Œåˆ é™¤"):
                    df_deleted = df.drop(columns=to_delete)
                    st.success(f"âœ… å·²åˆ é™¤ç¼ºå¤±å€¼æ¯”ä¾‹è¿‡é«˜çš„ {len(to_delete)} ä¸ªå˜é‡")
            else:
                st.info("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å˜é‡éœ€è¦åˆ é™¤")
        
        elif condition_type == "å”¯ä¸€å€¼è¿‡å°‘":
            threshold = st.number_input("æœ€å°‘å”¯ä¸€å€¼æ•°", min_value=1, value=2)
            unique_counts = df.nunique()
            to_delete = unique_counts[unique_counts < threshold].index.tolist()
            
            if to_delete:
                st.warning(f"å°†åˆ é™¤ {len(to_delete)} ä¸ªå˜é‡: {to_delete}")
                if st.button("ğŸ—‘ï¸ æ‰§è¡Œåˆ é™¤"):
                    df_deleted = df.drop(columns=to_delete)
                    st.success(f"âœ… å·²åˆ é™¤å”¯ä¸€å€¼è¿‡å°‘çš„ {len(to_delete)} ä¸ªå˜é‡")
            else:
                st.info("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å˜é‡éœ€è¦åˆ é™¤")
    
    elif deletion_method == "åˆ é™¤é‡å¤åˆ—":
        # æ£€æµ‹é‡å¤åˆ—
        duplicate_cols = []
        for i in range(len(df.columns)):
            for j in range(i+1, len(df.columns)):
                if df.iloc[:, i].equals(df.iloc[:, j]):
                    duplicate_cols.append(df.columns[j])
        
        if duplicate_cols:
            st.warning(f"å‘ç° {len(duplicate_cols)} ä¸ªé‡å¤åˆ—: {duplicate_cols}")
            if st.button("ğŸ—‘ï¸ åˆ é™¤é‡å¤åˆ—"):
                df_deleted = df.drop(columns=duplicate_cols)
                st.success(f"âœ… å·²åˆ é™¤ {len(duplicate_cols)} ä¸ªé‡å¤åˆ—")
        else:
            st.info("æ²¡æœ‰å‘ç°é‡å¤åˆ—")

def data_export_section():
    """æ•°æ®å¯¼å‡ºéƒ¨åˆ†"""
    st.markdown("### ğŸ’¾ æ•°æ®å¯¼å‡º")
    st.markdown("*å°†å¤„ç†åçš„æ•°æ®å¯¼å‡ºä¸ºå„ç§æ ¼å¼*")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    datasets = get_available_datasets()
    if not datasets:
        st.warning("âš ï¸ æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")
        return
    
    # é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®é›†
    selected_dataset = st.selectbox("é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®é›†", list(datasets.keys()))
    df = datasets[selected_dataset]['data']
    
    # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ•°æ®å½¢çŠ¶", f"{df.shape[0]} Ã— {df.shape[1]}")
    with col2:
        st.metric("å†…å­˜å¤§å°", f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB")
    with col3:
        st.metric("æ•°å€¼åˆ—", f"{df.select_dtypes(include=[np.number]).shape[1]}")
    with col4:
        st.metric("æ–‡æœ¬åˆ—", f"{df.select_dtypes(include=['object']).shape[1]}")
    
    # å¯¼å‡ºé€‰é¡¹
    export_format = st.selectbox(
        "é€‰æ‹©å¯¼å‡ºæ ¼å¼",
        ["Excel (.xlsx)", "CSV (.csv)", "JSON (.json)", "Parquet (.parquet)", "ç»Ÿè®¡æŠ¥å‘Š (HTML)"]
    )
    
    # å¯¼å‡ºè®¾ç½®
    with st.expander("ğŸ”§ å¯¼å‡ºè®¾ç½®", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            include_index = st.checkbox("åŒ…å«è¡Œç´¢å¼•", value=False)
            selected_columns = st.multiselect(
                "é€‰æ‹©è¦å¯¼å‡ºçš„åˆ— (ç•™ç©ºè¡¨ç¤ºå…¨éƒ¨)",
                df.columns.tolist()
            )
        
        with col2:
            if export_format == "CSV (.csv)":
                encoding = st.selectbox("ç¼–ç æ ¼å¼", ["utf-8", "gbk", "gb2312"])
                separator = st.selectbox("åˆ†éš”ç¬¦", [",", ";", "\t", "|"])
            elif export_format == "Excel (.xlsx)":
                sheet_name = st.text_input("å·¥ä½œè¡¨åç§°", value="Sheet1")
    
    # æ•°æ®é¢„è§ˆ
    if st.checkbox("é¢„è§ˆå¯¼å‡ºæ•°æ®"):
        export_df = df[selected_columns] if selected_columns else df
        st.dataframe(export_df.head(10), use_container_width=True)
    
    # æ‰§è¡Œå¯¼å‡º
    if st.button("ğŸ“¥ ç”Ÿæˆä¸‹è½½æ–‡ä»¶"):
        export_df = df[selected_columns] if selected_columns else df
        
        try:
            if export_format == "Excel (.xlsx)":
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    export_df.to_excel(writer, sheet_name=sheet_name, index=include_index)
                output.seek(0)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ Excel æ–‡ä»¶",
                    data=output.getvalue(),
                    file_name=f"{selected_dataset}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            
            elif export_format == "CSV (.csv)":
                csv_data = export_df.to_csv(index=include_index, encoding=encoding, sep=separator)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ CSV æ–‡ä»¶",
                    data=csv_data,
                    file_name=f"{selected_dataset}.csv",
                    mime="text/csv"
                )
            
            elif export_format == "JSON (.json)":
                json_data = export_df.to_json(orient='records', force_ascii=False, indent=2)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ JSON æ–‡ä»¶",
                    data=json_data,
                    file_name=f"{selected_dataset}.json",
                    mime="application/json"
                )
            
            elif export_format == "Parquet (.parquet)":
                output = io.BytesIO()
                export_df.to_parquet(output, index=include_index)
                output.seek(0)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ Parquet æ–‡ä»¶",
                    data=output.getvalue(),
                    file_name=f"{selected_dataset}.parquet",
                    mime="application/octet-stream"
                )
            
            elif export_format == "ç»Ÿè®¡æŠ¥å‘Š (HTML)":
                # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
                report_html = generate_statistical_report(export_df, selected_dataset)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»Ÿè®¡æŠ¥å‘Š",
                    data=report_html,
                    file_name=f"{selected_dataset}_report.html",
                    mime="text/html"
                )
            
            st.success("âœ… æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼Œè¯·ç‚¹å‡»ä¸‹è½½æŒ‰é’®!")
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

def generate_statistical_report(df, dataset_name):
    """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘ŠHTML"""
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>æ•°æ®ç»Ÿè®¡æŠ¥å‘Š - {dataset_name}</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; }}
            .header {{ background-color: #f8f9fa; padding: 20px; border-radius: 5px; }}
            .section {{ margin: 20px 0; }}
            table {{ border-collapse: collapse; width: 100%; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            .metric {{ display: inline-block; margin: 10px; padding: 10px; background-color: #e9ecef; border-radius: 5px; }}
        </style>
    </head>
    <body>
        <div class="header">
            <h1>æ•°æ®ç»Ÿè®¡æŠ¥å‘Š</h1>
            <h2>æ•°æ®é›†: {dataset_name}</h2>
            <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="section">
            <h3>æ•°æ®æ¦‚è§ˆ</h3>
            <div class="metric">æ€»è¡Œæ•°: {df.shape[0]:,}</div>
            <div class="metric">æ€»åˆ—æ•°: {df.shape[1]:,}</div>
            <div class="metric">æ•°å€¼åˆ—: {df.select_dtypes(include=[np.number]).shape[1]}</div>
            <div class="metric">æ–‡æœ¬åˆ—: {df.select_dtypes(include=['object']).shape[1]}</div>
        </div>
        
        <div class="section">
            <h3>æè¿°æ€§ç»Ÿè®¡</h3>
            {df.describe().to_html()}
        </div>
        
        <div class="section">
            <h3>ç¼ºå¤±å€¼ç»Ÿè®¡</h3>
            {pd.DataFrame({'ç¼ºå¤±å€¼æ•°': df.isnull().sum(), 'ç¼ºå¤±ç‡(%)': (df.isnull().sum() / len(df) * 100).round(2)}).to_html()}
        </div>
        
        <div class="section">
            <h3>æ•°æ®ç±»å‹</h3>
            {pd.DataFrame({'æ•°æ®ç±»å‹': df.dtypes}).to_html()}
        </div>
    </body>
    </html>
    """
    
    return html_content



