"""
æ ·æœ¬é‡è®¡ç®—æ¨¡å— (sample_size.py)
æä¾›å„ç§ç»Ÿè®¡åˆ†æçš„æ ·æœ¬é‡è®¡ç®—åŠŸèƒ½
"""

import streamlit as st
import numpy as np
import pandas as pd
import scipy.stats as stats
import plotly.graph_objects as go
import plotly.express as px
from scipy.optimize import fsolve
import math

def sample_size_calculator():
    """æ ·æœ¬é‡è®¡ç®—ä¸»å‡½æ•°"""
    st.markdown("# ğŸ§® æ ·æœ¬é‡è®¡ç®—å™¨")
    st.markdown("*ä¸ºå„ç§ç»Ÿè®¡åˆ†æè®¾è®¡æä¾›ç§‘å­¦çš„æ ·æœ¬é‡è®¡ç®—*")
    
    # ä¾§è¾¹æ  - è®¡ç®—ç±»å‹é€‰æ‹©
    with st.sidebar:
        st.markdown("### ğŸ“Š è®¡ç®—ç±»å‹")
        calc_type = st.selectbox(
            "é€‰æ‹©åˆ†æç±»å‹",
            [
                "ğŸ”¢ å‡æ•°æ¯”è¾ƒ",
                "ğŸ“Š æ¯”ä¾‹æ¯”è¾ƒ", 
                "ğŸ“ˆ ç›¸å…³æ€§åˆ†æ",
                "ğŸ§ª æ–¹å·®åˆ†æ(ANOVA)",
                "ğŸ”„ å¡æ–¹æ£€éªŒ",
                "âš–ï¸ ç”Ÿå­˜åˆ†æ",
                "ğŸ“‰ å›å½’åˆ†æ",
                "ğŸ¯ éåŠ£æ•ˆæ€§æ£€éªŒ",
                "âš¡ åŠŸæ•ˆåˆ†æ",
                "ğŸ“‹ å¤šé‡æ¯”è¾ƒ"
            ]
        )
        
        st.markdown("### âš™ï¸ é€šç”¨å‚æ•°")
        alpha = st.slider("æ˜¾è‘—æ€§æ°´å¹³ (Î±)", 0.01, 0.10, 0.05, 0.01)
        power = st.slider("ç»Ÿè®¡åŠŸæ•ˆ (1-Î²)", 0.70, 0.99, 0.80, 0.01)
        
        st.markdown("### ğŸ“ˆ å¯è§†åŒ–é€‰é¡¹")
        show_power_curve = st.checkbox("æ˜¾ç¤ºåŠŸæ•ˆæ›²çº¿", value=True)
        show_sample_curve = st.checkbox("æ˜¾ç¤ºæ ·æœ¬é‡æ›²çº¿", value=True)
    
    # æ ¹æ®é€‰æ‹©çš„ç±»å‹è°ƒç”¨ç›¸åº”å‡½æ•°
    if calc_type == "ğŸ”¢ å‡æ•°æ¯”è¾ƒ":
        mean_comparison_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "ğŸ“Š æ¯”ä¾‹æ¯”è¾ƒ":
        proportion_comparison_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "ğŸ“ˆ ç›¸å…³æ€§åˆ†æ":
        correlation_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "ğŸ§ª æ–¹å·®åˆ†æ(ANOVA)":
        anova_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "ğŸ”„ å¡æ–¹æ£€éªŒ":
        chi_square_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "âš–ï¸ ç”Ÿå­˜åˆ†æ":
        survival_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "ğŸ“‰ å›å½’åˆ†æ":
        regression_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "ğŸ¯ éåŠ£æ•ˆæ€§æ£€éªŒ":
        non_inferiority_sample_size(alpha, power, show_power_curve, show_sample_curve)
    elif calc_type == "âš¡ åŠŸæ•ˆåˆ†æ":
        power_analysis(alpha, show_power_curve, show_sample_curve)
    elif calc_type == "ğŸ“‹ å¤šé‡æ¯”è¾ƒ":
        multiple_comparison_sample_size(alpha, power, show_power_curve, show_sample_curve)

def mean_comparison_sample_size(alpha, power, show_power_curve, show_sample_curve):
    """å‡æ•°æ¯”è¾ƒçš„æ ·æœ¬é‡è®¡ç®—"""
    st.markdown("## ğŸ”¢ å‡æ•°æ¯”è¾ƒæ ·æœ¬é‡è®¡ç®—")
    st.markdown("*é€‚ç”¨äºtæ£€éªŒã€é…å¯¹tæ£€éªŒç­‰å‡æ•°æ¯”è¾ƒç ”ç©¶*")
    
    # å‚æ•°è¾“å…¥
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“‹ ç ”ç©¶è®¾è®¡å‚æ•°")
        
        study_design = st.selectbox(
            "ç ”ç©¶è®¾è®¡ç±»å‹",
            ["ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ", "é…å¯¹tæ£€éªŒ", "å•æ ·æœ¬tæ£€éªŒ"]
        )
        
        test_type = st.selectbox(
            "æ£€éªŒç±»å‹",
            ["åŒä¾§æ£€éªŒ", "å•ä¾§æ£€éªŒ"]
        )
        
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
            allocation_ratio = st.number_input(
                "åˆ†ç»„æ¯”ä¾‹ (è¯•éªŒç»„:å¯¹ç…§ç»„)",
                min_value=0.1, max_value=5.0, value=1.0, step=0.1
            )
        else:
            allocation_ratio = 1.0
    
    with col2:
        st.markdown("### ğŸ“Š æ•ˆåº”é‡å‚æ•°")
        
        effect_input_method = st.selectbox(
            "æ•ˆåº”é‡è¾“å…¥æ–¹å¼",
            ["ç›´æ¥è¾“å…¥æ•ˆåº”é‡", "è¾“å…¥å‡æ•°å’Œæ ‡å‡†å·®"]
        )
        
        if effect_input_method == "ç›´æ¥è¾“å…¥æ•ˆåº”é‡":
            effect_size = st.number_input(
                "æ•ˆåº”é‡ (Cohen's d)",
                min_value=0.1, max_value=2.0, value=0.5, step=0.1,
                help="å°æ•ˆåº”: 0.2, ä¸­ç­‰æ•ˆåº”: 0.5, å¤§æ•ˆåº”: 0.8"
            )
        else:
            if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
                mu1 = st.number_input("è¯•éªŒç»„å‡æ•°", value=10.0)
                mu2 = st.number_input("å¯¹ç…§ç»„å‡æ•°", value=8.0)
                sigma = st.number_input("æ€»ä½“æ ‡å‡†å·®", min_value=0.1, value=2.0)
                effect_size = abs(mu1 - mu2) / sigma
            elif study_design == "é…å¯¹tæ£€éªŒ":
                mean_diff = st.number_input("é…å¯¹å·®å€¼çš„å‡æ•°", value=2.0)
                sd_diff = st.number_input("é…å¯¹å·®å€¼çš„æ ‡å‡†å·®", min_value=0.1, value=3.0)
                effect_size = abs(mean_diff) / sd_diff
            else:  # å•æ ·æœ¬tæ£€éªŒ
                sample_mean = st.number_input("æ ·æœ¬å‡æ•°", value=10.0)
                pop_mean = st.number_input("æ€»ä½“å‡æ•°", value=8.0)
                sigma = st.number_input("æ€»ä½“æ ‡å‡†å·®", min_value=0.1, value=2.0)
                effect_size = abs(sample_mean - pop_mean) / sigma
        
        st.info(f"ğŸ’¡ è®¡ç®—å¾—åˆ°çš„æ•ˆåº”é‡: {effect_size:.3f}")
    
    # æ ·æœ¬é‡è®¡ç®—
    try:
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
            sample_size = calculate_two_sample_t_test_size(
                effect_size, alpha, power, allocation_ratio, test_type
            )
            
            n1 = int(np.ceil(sample_size))
            n2 = int(np.ceil(sample_size * allocation_ratio))
            total_n = n1 + n2
            
        elif study_design == "é…å¯¹tæ£€éªŒ":
            sample_size = calculate_paired_t_test_size(
                effect_size, alpha, power, test_type
            )
            
            n1 = int(np.ceil(sample_size))
            n2 = n1  # é…å¯¹è®¾è®¡
            total_n = n1
            
        else:  # å•æ ·æœ¬tæ£€éªŒ
            sample_size = calculate_one_sample_t_test_size(
                effect_size, alpha, power, test_type
            )
            
            n1 = int(np.ceil(sample_size))
            n2 = 0
            total_n = n1
        
        # ç»“æœæ˜¾ç¤º
        display_sample_size_results(
            study_design, n1, n2, total_n, effect_size, alpha, power, test_type
        )
        
        # æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis_means(
            study_design, effect_size, alpha, power, test_type, allocation_ratio,
            show_power_curve, show_sample_curve
        )
        
        # æ ·æœ¬é‡è¡¨æ ¼
        generate_sample_size_table_means(
            study_design, effect_size, alpha, test_type, allocation_ratio
        )
    
    except Exception as e:
        st.error(f"âŒ æ ·æœ¬é‡è®¡ç®—å¤±è´¥: {str(e)}")

def calculate_two_sample_t_test_size(effect_size, alpha, power, ratio, test_type):
    """è®¡ç®—ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒçš„æ ·æœ¬é‡"""
    
    # è·å–ä¸´ç•Œå€¼
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # æ ·æœ¬é‡å…¬å¼
    k = ratio  # åˆ†ç»„æ¯”ä¾‹
    n1 = ((z_alpha + z_beta)**2 * (1 + 1/k)) / (effect_size**2)
    
    return n1

def calculate_paired_t_test_size(effect_size, alpha, power, test_type):
    """è®¡ç®—é…å¯¹tæ£€éªŒçš„æ ·æœ¬é‡"""
    
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # é…å¯¹tæ£€éªŒæ ·æœ¬é‡å…¬å¼
    n = ((z_alpha + z_beta) / effect_size)**2
    
    return n

def calculate_one_sample_t_test_size(effect_size, alpha, power, test_type):
    """è®¡ç®—å•æ ·æœ¬tæ£€éªŒçš„æ ·æœ¬é‡"""
    
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # å•æ ·æœ¬tæ£€éªŒæ ·æœ¬é‡å…¬å¼
    n = ((z_alpha + z_beta) / effect_size)**2
    
    return n

def display_sample_size_results(study_design, n1, n2, total_n, effect_size, alpha, power, test_type):
    """æ˜¾ç¤ºæ ·æœ¬é‡è®¡ç®—ç»“æœ"""
    st.markdown("### ğŸ¯ æ ·æœ¬é‡è®¡ç®—ç»“æœ")
    
    # åˆ›å»ºç»“æœå±•ç¤º
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
            st.metric("è¯•éªŒç»„æ ·æœ¬é‡", n1)
        elif study_design == "é…å¯¹tæ£€éªŒ":
            st.metric("é…å¯¹æ•°", n1)
        else:
            st.metric("æ ·æœ¬é‡", n1)
    
    with col2:
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
            st.metric("å¯¹ç…§ç»„æ ·æœ¬é‡", n2)
        elif study_design == "é…å¯¹tæ£€éªŒ":
            st.metric("æ€»è§‚æµ‹æ•°", n1 * 2)
        else:
            st.metric("", "")
    
    with col3:
        st.metric("æ€»æ ·æœ¬é‡", total_n)
    
    # è¯¦ç»†å‚æ•°è¡¨
    st.markdown("### ğŸ“‹ è®¡ç®—å‚æ•°æ‘˜è¦")
    
    params_df = pd.DataFrame({
        'å‚æ•°': [
            'ç ”ç©¶è®¾è®¡',
            'æ£€éªŒç±»å‹', 
            'æ•ˆåº”é‡',
            'æ˜¾è‘—æ€§æ°´å¹³(Î±)',
            'ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)',
            'é¢„æœŸæ£€å‡ºç‡'
        ],
        'æ•°å€¼': [
            study_design,
            test_type,
            f"{effect_size:.3f}",
            f"{alpha:.3f}",
            f"{power:.3f}",
            f"{power*100:.1f}%"
        ]
    })
    
    st.dataframe(params_df, hide_index=True)
    
    # è§£é‡Šè¯´æ˜
    st.markdown("### ğŸ“ ç»“æœè§£é‡Š")
    
    if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
        st.markdown(f"""
        **æ ·æœ¬é‡è®¡ç®—ç»“æœè§£é‡Š:**
        - è¯•éªŒç»„éœ€è¦ **{n1}** åå—è¯•è€…
        - å¯¹ç…§ç»„éœ€è¦ **{n2}** åå—è¯•è€…  
        - æ€»è®¡éœ€è¦ **{total_n}** åå—è¯•è€…
        - åœ¨Î±={alpha}ï¼ŒåŠŸæ•ˆ={power}çš„æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿæ£€å‡ºæ•ˆåº”é‡ä¸º{effect_size:.3f}çš„å·®å¼‚
        """)
    elif study_design == "é…å¯¹tæ£€éªŒ":
        st.markdown(f"""
        **æ ·æœ¬é‡è®¡ç®—ç»“æœè§£é‡Š:**
        - éœ€è¦ **{n1}** å¯¹é…å¯¹è§‚æµ‹
        - æ€»è®¡éœ€è¦ **{n1*2}** æ¬¡è§‚æµ‹
        - åœ¨Î±={alpha}ï¼ŒåŠŸæ•ˆ={power}çš„æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿæ£€å‡ºæ•ˆåº”é‡ä¸º{effect_size:.3f}çš„é…å¯¹å·®å¼‚
        """)
    else:
        st.markdown(f"""
        **æ ·æœ¬é‡è®¡ç®—ç»“æœè§£é‡Š:**
        - éœ€è¦ **{n1}** åå—è¯•è€…
        - åœ¨Î±={alpha}ï¼ŒåŠŸæ•ˆ={power}çš„æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿæ£€å‡ºæ•ˆåº”é‡ä¸º{effect_size:.3f}çš„å·®å¼‚
        """)

def sensitivity_analysis_means(study_design, effect_size, alpha, power, test_type, ratio, show_power_curve, show_sample_curve):
    """å‡æ•°æ¯”è¾ƒçš„æ•æ„Ÿæ€§åˆ†æ"""
    st.markdown("### ğŸ“ˆ æ•æ„Ÿæ€§åˆ†æ")
    
    tab1, tab2 = st.tabs(["åŠŸæ•ˆæ›²çº¿", "æ ·æœ¬é‡æ›²çº¿"])
    
    with tab1:
        if show_power_curve:
            st.markdown("#### ğŸ”‹ ç»Ÿè®¡åŠŸæ•ˆæ›²çº¿")
            
            # æ•ˆåº”é‡èŒƒå›´
            effect_range = np.linspace(0.1, 1.5, 50)
            powers = []
            
            for es in effect_range:
                if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
                    n = calculate_two_sample_t_test_size(es, alpha, 0.8, ratio, test_type)
                elif study_design == "é…å¯¹tæ£€éªŒ":
                    n = calculate_paired_t_test_size(es, alpha, 0.8, test_type)
                else:
                    n = calculate_one_sample_t_test_size(es, alpha, 0.8, test_type)
                
                # è®¡ç®—å®é™…åŠŸæ•ˆ
                actual_power = calculate_actual_power_t_test(n, es, alpha, test_type, study_design, ratio)
                powers.append(actual_power)
            
            fig_power = go.Figure()
            
            fig_power.add_trace(go.Scatter(
                x=effect_range,
                y=powers,
                mode='lines',
                name='ç»Ÿè®¡åŠŸæ•ˆ',
                line=dict(color='blue', width=3)
            ))
            
            # æ·»åŠ å‚è€ƒçº¿
            fig_power.add_hline(y=0.8, line_dash="dash", line_color="red", 
                               annotation_text="ç›®æ ‡åŠŸæ•ˆ (80%)")
            fig_power.add_vline(x=effect_size, line_dash="dash", line_color="green",
                               annotation_text=f"å½“å‰æ•ˆåº”é‡ ({effect_size:.3f})")
            
            fig_power.update_layout(
                title="ç»Ÿè®¡åŠŸæ•ˆéšæ•ˆåº”é‡å˜åŒ–æ›²çº¿",
                xaxis_title="æ•ˆåº”é‡ (Cohen's d)",
                yaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis=dict(range=[0, 1]),
                height=400
            )
            
            st.plotly_chart(fig_power, use_container_width=True)
    
    with tab2:
        if show_sample_curve:
            st.markdown("#### ğŸ“Š æ ·æœ¬é‡éœ€æ±‚æ›²çº¿")
            
            # åŠŸæ•ˆèŒƒå›´
            power_range = np.linspace(0.5, 0.99, 50)
            sample_sizes = []
            
            for p in power_range:
                if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
                    n = calculate_two_sample_t_test_size(effect_size, alpha, p, ratio, test_type)
                    total_n = n * (1 + ratio)
                elif study_design == "é…å¯¹tæ£€éªŒ":
                    n = calculate_paired_t_test_size(effect_size, alpha, p, test_type)
                    total_n = n
                else:
                    n = calculate_one_sample_t_test_size(effect_size, alpha, p, test_type)
                    total_n = n
                
                sample_sizes.append(total_n)
            
            fig_sample = go.Figure()
            
            fig_sample.add_trace(go.Scatter(
                x=power_range,
                y=sample_sizes,
                mode='lines',
                name='æ€»æ ·æœ¬é‡',
                line=dict(color='orange', width=3)
            ))
            
            # æ·»åŠ å‚è€ƒçº¿
            fig_sample.add_vline(x=power, line_dash="dash", line_color="red",
                                annotation_text=f"ç›®æ ‡åŠŸæ•ˆ ({power:.0%})")
            
            fig_sample.update_layout(
                title="æ ·æœ¬é‡éœ€æ±‚éšç»Ÿè®¡åŠŸæ•ˆå˜åŒ–æ›²çº¿",
                xaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis_title="æ€»æ ·æœ¬é‡",
                height=400
            )
            
            st.plotly_chart(fig_sample, use_container_width=True)

def calculate_actual_power_t_test(n, effect_size, alpha, test_type, study_design, ratio=1.0):
    """è®¡ç®—tæ£€éªŒçš„å®é™…ç»Ÿè®¡åŠŸæ•ˆ"""
    try:
        if test_type == "åŒä¾§æ£€éªŒ":
            z_alpha = stats.norm.ppf(1 - alpha/2)
        else:
            z_alpha = stats.norm.ppf(1 - alpha)
        
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
            se = np.sqrt((1 + 1/ratio) / n)
        else:
            se = 1 / np.sqrt(n)
        
        z_beta = effect_size / se - z_alpha
        power = stats.norm.cdf(z_beta)
        
        return min(max(power, 0), 1)
    
    except:
        return 0.5

def generate_sample_size_table_means(study_design, effect_size, alpha, test_type, ratio):
    """ç”Ÿæˆæ ·æœ¬é‡å¯¹ç…§è¡¨"""
    st.markdown("### ğŸ“Š æ ·æœ¬é‡å¯¹ç…§è¡¨")
    
    # åˆ›å»ºä¸åŒå‚æ•°ç»„åˆçš„æ ·æœ¬é‡è¡¨
    power_levels = [0.70, 0.75, 0.80, 0.85, 0.90, 0.95]
    alpha_levels = [0.01, 0.05, 0.10]
    
    table_data = []
    
    for a in alpha_levels:
        for p in power_levels:
            if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
                n = calculate_two_sample_t_test_size(effect_size, a, p, ratio, test_type)
                total_n = int(np.ceil(n * (1 + ratio)))
            elif study_design == "é…å¯¹tæ£€éªŒ":
                n = calculate_paired_t_test_size(effect_size, a, p, test_type)
                total_n = int(np.ceil(n))
            else:
                n = calculate_one_sample_t_test_size(effect_size, a, p, test_type)
                total_n = int(np.ceil(n))
            
            table_data.append({
                'æ˜¾è‘—æ€§æ°´å¹³(Î±)': f"{a:.2f}",
                'ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)': f"{p:.2f}",
                'æ€»æ ·æœ¬é‡': total_n
            })
    
    table_df = pd.DataFrame(table_data)
    
    # é€è§†è¡¨æ ¼å¼
    pivot_table = table_df.pivot(index='æ˜¾è‘—æ€§æ°´å¹³(Î±)', 
                                columns='ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)', 
                                values='æ€»æ ·æœ¬é‡')
    
    st.dataframe(pivot_table)
    
    st.markdown(f"""
    **è¡¨æ ¼è¯´æ˜:**
    - åŸºäºæ•ˆåº”é‡ = {effect_size:.3f}
    - æ£€éªŒç±»å‹: {test_type}
    - ç ”ç©¶è®¾è®¡: {study_design}
    """)

def proportion_comparison_sample_size(alpha, power, show_power_curve, show_sample_curve):
    """æ¯”ä¾‹æ¯”è¾ƒçš„æ ·æœ¬é‡è®¡ç®—"""
    st.markdown("## ğŸ“Š æ¯”ä¾‹æ¯”è¾ƒæ ·æœ¬é‡è®¡ç®—")
    st.markdown("*é€‚ç”¨äºä¸¤ç»„ç‡çš„æ¯”è¾ƒã€å¡æ–¹æ£€éªŒç­‰*")
    
    # å‚æ•°è¾“å…¥
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“‹ ç ”ç©¶è®¾è®¡å‚æ•°")
        
        study_design = st.selectbox(
            "ç ”ç©¶è®¾è®¡ç±»å‹",
            ["ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ", "é…å¯¹æ¯”ä¾‹æ¯”è¾ƒ", "å•æ ·æœ¬æ¯”ä¾‹æ£€éªŒ"]
        )
        
        test_type = st.selectbox(
            "æ£€éªŒç±»å‹",
            ["åŒä¾§æ£€éªŒ", "å•ä¾§æ£€éªŒ"]
        )
        
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
            allocation_ratio = st.number_input(
                "åˆ†ç»„æ¯”ä¾‹ (è¯•éªŒç»„:å¯¹ç…§ç»„)",
                min_value=0.1, max_value=5.0, value=1.0, step=0.1
            )
        else:
            allocation_ratio = 1.0
    
    with col2:
        st.markdown("### ğŸ“Š æ¯”ä¾‹å‚æ•°")
        
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
            p1 = st.number_input(
                "è¯•éªŒç»„é¢„æœŸæ¯”ä¾‹ (p1)",
                min_value=0.01, max_value=0.99, value=0.6, step=0.01
            )
            p2 = st.number_input(
                "å¯¹ç…§ç»„é¢„æœŸæ¯”ä¾‹ (p2)", 
                min_value=0.01, max_value=0.99, value=0.4, step=0.01
            )
            
            # è®¡ç®—æ•ˆåº”é‡
            effect_size = abs(p1 - p2)
            
        elif study_design == "é…å¯¹æ¯”ä¾‹æ¯”è¾ƒ":
            p_discordant = st.number_input(
                "ä¸ä¸€è‡´å¯¹çš„æ¯”ä¾‹",
                min_value=0.01, max_value=0.50, value=0.2, step=0.01
            )
            p_diff = st.number_input(
                "é…å¯¹å·®å¼‚æ¯”ä¾‹",
                min_value=0.01, max_value=1.0, value=0.1, step=0.01
            )
            p1, p2 = p_discordant, p_diff
            effect_size = p_diff
            
        else:  # å•æ ·æœ¬æ¯”ä¾‹æ£€éªŒ
            p_sample = st.number_input(
                "æ ·æœ¬é¢„æœŸæ¯”ä¾‹",
                min_value=0.01, max_value=0.99, value=0.6, step=0.01
            )
            p_null = st.number_input(
                "åŸå‡è®¾æ¯”ä¾‹",
                min_value=0.01, max_value=0.99, value=0.5, step=0.01
            )
            p1, p2 = p_sample, p_null
            effect_size = abs(p_sample - p_null)
        
        st.info(f"ğŸ’¡ æ•ˆåº”é‡: {effect_size:.3f}")
    
    # æ ·æœ¬é‡è®¡ç®—
    try:
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
            sample_size = calculate_two_proportion_test_size(
                p1, p2, alpha, power, allocation_ratio, test_type
            )
            
            n1 = int(np.ceil(sample_size))
            n2 = int(np.ceil(sample_size * allocation_ratio))
            total_n = n1 + n2
            
        elif study_design == "é…å¯¹æ¯”ä¾‹æ¯”è¾ƒ":
            sample_size = calculate_paired_proportion_test_size(
                p_discordant, p_diff, alpha, power, test_type
            )
            
            n1 = int(np.ceil(sample_size))
            n2 = n1
            total_n = n1
            
        else:  # å•æ ·æœ¬æ¯”ä¾‹æ£€éªŒ
            sample_size = calculate_one_proportion_test_size(
                p_sample, p_null, alpha, power, test_type
            )
            
            n1 = int(np.ceil(sample_size))
            n2 = 0
            total_n = n1
        
        # ç»“æœæ˜¾ç¤º
        display_proportion_results(
            study_design, n1, n2, total_n, p1, p2, alpha, power, test_type
        )
        
        # æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis_proportions(
            study_design, p1, p2, alpha, power, test_type, allocation_ratio,
            show_power_curve, show_sample_curve
        )
    
    except Exception as e:
        st.error(f"âŒ æ ·æœ¬é‡è®¡ç®—å¤±è´¥: {str(e)}")

def calculate_two_proportion_test_size(p1, p2, alpha, power, ratio, test_type):
    """è®¡ç®—ä¸¤æ¯”ä¾‹æ¯”è¾ƒçš„æ ·æœ¬é‡"""
    
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # åˆå¹¶æ¯”ä¾‹
    p_pooled = (p1 + ratio * p2) / (1 + ratio)
    
    # æ ·æœ¬é‡å…¬å¼
    numerator = (z_alpha * np.sqrt(p_pooled * (1 - p_pooled) * (1 + 1/ratio)) + 
                z_beta * np.sqrt(p1 * (1 - p1) + p2 * (1 - p2) / ratio))**2
    
    denominator = (p1 - p2)**2
    
    n1 = numerator / denominator
    
    return n1

def calculate_paired_proportion_test_size(p_discordant, p_diff, alpha, power, test_type):
    """è®¡ç®—é…å¯¹æ¯”ä¾‹æ¯”è¾ƒçš„æ ·æœ¬é‡"""
    
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # McNemaræ£€éªŒæ ·æœ¬é‡å…¬å¼
    n = ((z_alpha + z_beta)**2 * p_discordant) / (p_diff**2)
    
    return n

def calculate_one_proportion_test_size(p_sample, p_null, alpha, power, test_type):
    """è®¡ç®—å•æ ·æœ¬æ¯”ä¾‹æ£€éªŒçš„æ ·æœ¬é‡"""
    
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # å•æ ·æœ¬æ¯”ä¾‹æ£€éªŒæ ·æœ¬é‡å…¬å¼
    numerator = (z_alpha * np.sqrt(p_null * (1 - p_null)) + 
                z_beta * np.sqrt(p_sample * (1 - p_sample)))**2
    
    denominator = (p_sample - p_null)**2
    
    n = numerator / denominator
    
    return n

def display_proportion_results(study_design, n1, n2, total_n, p1, p2, alpha, power, test_type):
    """æ˜¾ç¤ºæ¯”ä¾‹æ¯”è¾ƒæ ·æœ¬é‡ç»“æœ"""
    st.markdown("### ğŸ¯ æ ·æœ¬é‡è®¡ç®—ç»“æœ")
    
    # ç»“æœå±•ç¤º
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
            st.metric("è¯•éªŒç»„æ ·æœ¬é‡", n1)
        elif study_design == "é…å¯¹æ¯”ä¾‹æ¯”è¾ƒ":
            st.metric("é…å¯¹æ•°", n1)
        else:
            st.metric("æ ·æœ¬é‡", n1)
    
    with col2:
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
            st.metric("å¯¹ç…§ç»„æ ·æœ¬é‡", n2)
        elif study_design == "é…å¯¹æ¯”ä¾‹æ¯”è¾ƒ":
            st.metric("æ€»è§‚æµ‹æ•°", n1 * 2)
        else:
            st.metric("", "")
    
    with col3:
        st.metric("æ€»æ ·æœ¬é‡", total_n)
    
        # è¯¦ç»†å‚æ•°è¡¨
    st.markdown("### ğŸ“‹ è®¡ç®—å‚æ•°æ‘˜è¦")
    
    if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
        params_df = pd.DataFrame({
            'å‚æ•°': [
                'ç ”ç©¶è®¾è®¡',
                'æ£€éªŒç±»å‹',
                'è¯•éªŒç»„æ¯”ä¾‹(p1)',
                'å¯¹ç…§ç»„æ¯”ä¾‹(p2)',
                'æ•ˆåº”é‡(|p1-p2|)',
                'æ˜¾è‘—æ€§æ°´å¹³(Î±)',
                'ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)'
            ],
            'æ•°å€¼': [
                study_design,
                test_type,
                f"{p1:.3f}",
                f"{p2:.3f}",
                f"{abs(p1-p2):.3f}",
                f"{alpha:.3f}",
                f"{power:.3f}"
            ]
        })
    elif study_design == "é…å¯¹æ¯”ä¾‹æ¯”è¾ƒ":
        params_df = pd.DataFrame({
            'å‚æ•°': [
                'ç ”ç©¶è®¾è®¡',
                'æ£€éªŒç±»å‹',
                'ä¸ä¸€è‡´å¯¹æ¯”ä¾‹',
                'é…å¯¹å·®å¼‚æ¯”ä¾‹',
                'æ˜¾è‘—æ€§æ°´å¹³(Î±)',
                'ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)'
            ],
            'æ•°å€¼': [
                study_design,
                test_type,
                f"{p1:.3f}",
                f"{p2:.3f}",
                f"{alpha:.3f}",
                f"{power:.3f}"
            ]
        })
    else:
        params_df = pd.DataFrame({
            'å‚æ•°': [
                'ç ”ç©¶è®¾è®¡',
                'æ£€éªŒç±»å‹',
                'æ ·æœ¬æ¯”ä¾‹',
                'åŸå‡è®¾æ¯”ä¾‹',
                'æ•ˆåº”é‡',
                'æ˜¾è‘—æ€§æ°´å¹³(Î±)',
                'ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)'
            ],
            'æ•°å€¼': [
                study_design,
                test_type,
                f"{p1:.3f}",
                f"{p2:.3f}",
                f"{abs(p1-p2):.3f}",
                f"{alpha:.3f}",
                f"{power:.3f}"
            ]
        })
    
    st.dataframe(params_df, hide_index=True)

def sensitivity_analysis_proportions(study_design, p1, p2, alpha, power, test_type, ratio, show_power_curve, show_sample_curve):
    """æ¯”ä¾‹æ¯”è¾ƒçš„æ•æ„Ÿæ€§åˆ†æ"""
    st.markdown("### ğŸ“ˆ æ•æ„Ÿæ€§åˆ†æ")
    
    tab1, tab2 = st.tabs(["åŠŸæ•ˆæ›²çº¿", "æ ·æœ¬é‡æ›²çº¿"])
    
    with tab1:
        if show_power_curve:
            st.markdown("#### ğŸ”‹ ç»Ÿè®¡åŠŸæ•ˆæ›²çº¿")
            
            if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
                # å›ºå®šp2ï¼Œå˜åŒ–p1
                p1_range = np.linspace(max(0.01, p2-0.4), min(0.99, p2+0.4), 50)
                powers = []
                
                for p1_var in p1_range:
                    if abs(p1_var - p2) > 0.001:  # é¿å…é™¤é›¶
                        n = calculate_two_proportion_test_size(p1_var, p2, alpha, 0.8, ratio, test_type)
                        actual_power = calculate_actual_power_proportion(n, p1_var, p2, alpha, test_type, study_design, ratio)
                        powers.append(actual_power)
                    else:
                        powers.append(0.05)  # æ¥è¿‘åŸå‡è®¾æ—¶åŠŸæ•ˆæ¥è¿‘Î±
                
                fig_power = go.Figure()
                
                fig_power.add_trace(go.Scatter(
                    x=p1_range,
                    y=powers,
                    mode='lines',
                    name='ç»Ÿè®¡åŠŸæ•ˆ',
                    line=dict(color='blue', width=3)
                ))
                
                fig_power.add_hline(y=0.8, line_dash="dash", line_color="red", 
                                   annotation_text="ç›®æ ‡åŠŸæ•ˆ (80%)")
                fig_power.add_vline(x=p1, line_dash="dash", line_color="green",
                                   annotation_text=f"å½“å‰p1 ({p1:.3f})")
                
                fig_power.update_layout(
                    title="ç»Ÿè®¡åŠŸæ•ˆéšè¯•éªŒç»„æ¯”ä¾‹å˜åŒ–æ›²çº¿",
                    xaxis_title="è¯•éªŒç»„æ¯”ä¾‹ (p1)",
                    yaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                    yaxis=dict(range=[0, 1]),
                    height=400
                )
            
            st.plotly_chart(fig_power, use_container_width=True)
    
    with tab2:
        if show_sample_curve:
            st.markdown("#### ğŸ“Š æ ·æœ¬é‡éœ€æ±‚æ›²çº¿")
            
            power_range = np.linspace(0.5, 0.99, 50)
            sample_sizes = []
            
            for p in power_range:
                if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
                    n = calculate_two_proportion_test_size(p1, p2, alpha, p, ratio, test_type)
                    total_n = n * (1 + ratio)
                elif study_design == "é…å¯¹æ¯”ä¾‹æ¯”è¾ƒ":
                    n = calculate_paired_proportion_test_size(p1, p2, alpha, p, test_type)
                    total_n = n
                else:
                    n = calculate_one_proportion_test_size(p1, p2, alpha, p, test_type)
                    total_n = n
                
                sample_sizes.append(total_n)
            
            fig_sample = go.Figure()
            
            fig_sample.add_trace(go.Scatter(
                x=power_range,
                y=sample_sizes,
                mode='lines',
                name='æ€»æ ·æœ¬é‡',
                line=dict(color='orange', width=3)
            ))
            
            fig_sample.add_vline(x=power, line_dash="dash", line_color="red",
                                annotation_text=f"ç›®æ ‡åŠŸæ•ˆ ({power:.0%})")
            
            fig_sample.update_layout(
                title="æ ·æœ¬é‡éœ€æ±‚éšç»Ÿè®¡åŠŸæ•ˆå˜åŒ–æ›²çº¿",
                xaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis_title="æ€»æ ·æœ¬é‡",
                height=400
            )
            
            st.plotly_chart(fig_sample, use_container_width=True)

def calculate_actual_power_proportion(n, p1, p2, alpha, test_type, study_design, ratio=1.0):
    """è®¡ç®—æ¯”ä¾‹æ£€éªŒçš„å®é™…ç»Ÿè®¡åŠŸæ•ˆ"""
    try:
        if test_type == "åŒä¾§æ£€éªŒ":
            z_alpha = stats.norm.ppf(1 - alpha/2)
        else:
            z_alpha = stats.norm.ppf(1 - alpha)
        
        if study_design == "ä¸¤ç‹¬ç«‹æ ·æœ¬æ¯”ä¾‹æ¯”è¾ƒ":
            p_pooled = (p1 + ratio * p2) / (1 + ratio)
            se_null = np.sqrt(p_pooled * (1 - p_pooled) * (1 + 1/ratio) / n)
            se_alt = np.sqrt(p1 * (1 - p1) / n + p2 * (1 - p2) / (n * ratio))
        else:
            se_null = np.sqrt(p2 * (1 - p2) / n)
            se_alt = np.sqrt(p1 * (1 - p1) / n)
        
        z_beta = (abs(p1 - p2) / se_alt) - z_alpha
        power = stats.norm.cdf(z_beta)
        
        return min(max(power, 0), 1)
    
    except:
        return 0.5

def correlation_sample_size(alpha, power, show_power_curve, show_sample_curve):
    """ç›¸å…³æ€§åˆ†ææ ·æœ¬é‡è®¡ç®—"""
    st.markdown("## ğŸ“ˆ ç›¸å…³æ€§åˆ†ææ ·æœ¬é‡è®¡ç®—")
    st.markdown("*é€‚ç”¨äºPearsonç›¸å…³ã€Spearmanç›¸å…³ç­‰*")
    
    # å‚æ•°è¾“å…¥
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“‹ ç ”ç©¶è®¾è®¡å‚æ•°")
        
        correlation_type = st.selectbox(
            "ç›¸å…³åˆ†æç±»å‹",
            ["Pearsonç›¸å…³", "Spearmanç›¸å…³", "åç›¸å…³"]
        )
        
        test_type = st.selectbox(
            "æ£€éªŒç±»å‹",
            ["åŒä¾§æ£€éªŒ", "å•ä¾§æ£€éªŒ"]
        )
        
        if correlation_type == "åç›¸å…³":
            control_vars = st.number_input(
                "æ§åˆ¶å˜é‡ä¸ªæ•°",
                min_value=1, max_value=10, value=2, step=1
            )
        else:
            control_vars = 0
    
    with col2:
        st.markdown("### ğŸ“Š æ•ˆåº”é‡å‚æ•°")
        
        effect_input_method = st.selectbox(
            "æ•ˆåº”é‡è¾“å…¥æ–¹å¼",
            ["ç›´æ¥è¾“å…¥ç›¸å…³ç³»æ•°", "æ ¹æ®æ•ˆåº”å¤§å°é€‰æ‹©"]
        )
        
        if effect_input_method == "ç›´æ¥è¾“å…¥ç›¸å…³ç³»æ•°":
            expected_r = st.number_input(
                "é¢„æœŸç›¸å…³ç³»æ•° (r)",
                min_value=0.01, max_value=0.99, value=0.3, step=0.01
            )
        else:
            effect_size_level = st.selectbox(
                "æ•ˆåº”å¤§å°",
                ["å°æ•ˆåº” (r=0.1)", "ä¸­ç­‰æ•ˆåº” (r=0.3)", "å¤§æ•ˆåº” (r=0.5)"]
            )
            
            effect_mapping = {
                "å°æ•ˆåº” (r=0.1)": 0.1,
                "ä¸­ç­‰æ•ˆåº” (r=0.3)": 0.3,
                "å¤§æ•ˆåº” (r=0.5)": 0.5
            }
            expected_r = effect_mapping[effect_size_level]
        
        null_r = st.number_input(
            "åŸå‡è®¾ç›¸å…³ç³»æ•°",
            min_value=0.0, max_value=0.99, value=0.0, step=0.01
        )
        
        st.info(f"ğŸ’¡ æ•ˆåº”é‡ (r): {expected_r:.3f}")
    
    # æ ·æœ¬é‡è®¡ç®—
    try:
        sample_size = calculate_correlation_sample_size(
            expected_r, null_r, alpha, power, test_type, control_vars
        )
        
        n = int(np.ceil(sample_size))
        
        # ç»“æœæ˜¾ç¤º
        display_correlation_results(
            n, expected_r, null_r, alpha, power, test_type, correlation_type, control_vars
        )
        
        # æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis_correlation(
            expected_r, null_r, alpha, power, test_type, control_vars,
            show_power_curve, show_sample_curve
        )
    
    except Exception as e:
        st.error(f"âŒ æ ·æœ¬é‡è®¡ç®—å¤±è´¥: {str(e)}")

def calculate_correlation_sample_size(r1, r0, alpha, power, test_type, control_vars=0):
    """è®¡ç®—ç›¸å…³åˆ†æçš„æ ·æœ¬é‡"""
    
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # Fisher's zå˜æ¢
    z1 = 0.5 * np.log((1 + r1) / (1 - r1))
    z0 = 0.5 * np.log((1 + r0) / (1 - r0))
    
    # æ ·æœ¬é‡å…¬å¼ï¼ˆè€ƒè™‘æ§åˆ¶å˜é‡ï¼‰
    n = ((z_alpha + z_beta) / (z1 - z0))**2 + 3 + control_vars
    
    return n

def display_correlation_results(n, r1, r0, alpha, power, test_type, correlation_type, control_vars):
    """æ˜¾ç¤ºç›¸å…³åˆ†ææ ·æœ¬é‡ç»“æœ"""
    st.markdown("### ğŸ¯ æ ·æœ¬é‡è®¡ç®—ç»“æœ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("æ‰€éœ€æ ·æœ¬é‡", n)
    
    with col2:
        st.metric("é¢„æœŸç›¸å…³ç³»æ•°", f"{r1:.3f}")
    
    with col3:
        st.metric("æ•ˆåº”é‡", f"{abs(r1-r0):.3f}")
    
    # è¯¦ç»†å‚æ•°è¡¨
    st.markdown("### ğŸ“‹ è®¡ç®—å‚æ•°æ‘˜è¦")
    
    params_data = [
        ['ç›¸å…³åˆ†æç±»å‹', correlation_type],
        ['æ£€éªŒç±»å‹', test_type],
        ['é¢„æœŸç›¸å…³ç³»æ•°(r1)', f"{r1:.3f}"],
        ['åŸå‡è®¾ç›¸å…³ç³»æ•°(r0)', f"{r0:.3f}"],
        ['æ˜¾è‘—æ€§æ°´å¹³(Î±)', f"{alpha:.3f}"],
        ['ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)', f"{power:.3f}"]
    ]
    
    if control_vars > 0:
        params_data.append(['æ§åˆ¶å˜é‡ä¸ªæ•°', str(control_vars)])
    
    params_df = pd.DataFrame(params_data, columns=['å‚æ•°', 'æ•°å€¼'])
    st.dataframe(params_df, hide_index=True)
    
    # ç»“æœè§£é‡Š
    st.markdown("### ğŸ“ ç»“æœè§£é‡Š")
    st.markdown(f"""
    **æ ·æœ¬é‡è®¡ç®—ç»“æœè§£é‡Š:**
    - éœ€è¦ **{n}** åå—è¯•è€…è¿›è¡Œç›¸å…³æ€§åˆ†æ
    - åœ¨Î±={alpha}ï¼ŒåŠŸæ•ˆ={power}çš„æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿæ£€å‡ºç›¸å…³ç³»æ•°ä¸º{r1:.3f}çš„å…³è”
    - ä½¿ç”¨{correlation_type}è¿›è¡Œåˆ†æ
    """)

def sensitivity_analysis_correlation(r1, r0, alpha, power, test_type, control_vars, show_power_curve, show_sample_curve):
    """ç›¸å…³åˆ†æçš„æ•æ„Ÿæ€§åˆ†æ"""
    st.markdown("### ğŸ“ˆ æ•æ„Ÿæ€§åˆ†æ")
    
    tab1, tab2 = st.tabs(["åŠŸæ•ˆæ›²çº¿", "æ ·æœ¬é‡æ›²çº¿"])
    
    with tab1:
        if show_power_curve:
            st.markdown("#### ğŸ”‹ ç»Ÿè®¡åŠŸæ•ˆæ›²çº¿")
            
            r_range = np.linspace(0.05, 0.8, 50)
            powers = []
            
            for r in r_range:
                n = calculate_correlation_sample_size(r, r0, alpha, 0.8, test_type, control_vars)
                actual_power = calculate_actual_power_correlation(n, r, r0, alpha, test_type, control_vars)
                powers.append(actual_power)
            
            fig_power = go.Figure()
            
            fig_power.add_trace(go.Scatter(
                x=r_range,
                y=powers,
                mode='lines',
                name='ç»Ÿè®¡åŠŸæ•ˆ',
                line=dict(color='blue', width=3)
            ))
            
            fig_power.add_hline(y=0.8, line_dash="dash", line_color="red", 
                               annotation_text="ç›®æ ‡åŠŸæ•ˆ (80%)")
            fig_power.add_vline(x=r1, line_dash="dash", line_color="green",
                               annotation_text=f"å½“å‰ç›¸å…³ç³»æ•° ({r1:.3f})")
            
            fig_power.update_layout(
                title="ç»Ÿè®¡åŠŸæ•ˆéšç›¸å…³ç³»æ•°å˜åŒ–æ›²çº¿",
                xaxis_title="ç›¸å…³ç³»æ•° (r)",
                yaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis=dict(range=[0, 1]),
                height=400
            )
            
            st.plotly_chart(fig_power, use_container_width=True)
    
    with tab2:
        if show_sample_curve:
            st.markdown("#### ğŸ“Š æ ·æœ¬é‡éœ€æ±‚æ›²çº¿")
            
            power_range = np.linspace(0.5, 0.99, 50)
            sample_sizes = []
            
            for p in power_range:
                n = calculate_correlation_sample_size(r1, r0, alpha, p, test_type, control_vars)
                sample_sizes.append(n)
            
            fig_sample = go.Figure()
            
            fig_sample.add_trace(go.Scatter(
                x=power_range,
                y=sample_sizes,
                mode='lines',
                name='æ ·æœ¬é‡',
                line=dict(color='orange', width=3)
            ))
            
            fig_sample.add_vline(x=power, line_dash="dash", line_color="red",
                                annotation_text=f"ç›®æ ‡åŠŸæ•ˆ ({power:.0%})")
            
            fig_sample.update_layout(
                title="æ ·æœ¬é‡éœ€æ±‚éšç»Ÿè®¡åŠŸæ•ˆå˜åŒ–æ›²çº¿",
                xaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis_title="æ ·æœ¬é‡",
                height=400
            )
            
            st.plotly_chart(fig_sample, use_container_width=True)

def calculate_actual_power_correlation(n, r1, r0, alpha, test_type, control_vars=0):
    """è®¡ç®—ç›¸å…³åˆ†æçš„å®é™…ç»Ÿè®¡åŠŸæ•ˆ"""
    try:
        if test_type == "åŒä¾§æ£€éªŒ":
            z_alpha = stats.norm.ppf(1 - alpha/2)
        else:
            z_alpha = stats.norm.ppf(1 - alpha)
        
        # Fisher's zå˜æ¢
        z1 = 0.5 * np.log((1 + r1) / (1 - r1))
        z0 = 0.5 * np.log((1 + r0) / (1 - r0))
        
        # æ ‡å‡†è¯¯
        se = 1 / np.sqrt(n - 3 - control_vars)
        
        z_beta = (z1 - z0) / se - z_alpha
        power = stats.norm.cdf(z_beta)
        
        return min(max(power, 0), 1)
    
    except:
        return 0.5

def anova_sample_size(alpha, power, show_power_curve, show_sample_curve):
    """æ–¹å·®åˆ†ææ ·æœ¬é‡è®¡ç®—"""
    st.markdown("## ğŸ§ª æ–¹å·®åˆ†æ(ANOVA)æ ·æœ¬é‡è®¡ç®—")
    st.markdown("*é€‚ç”¨äºå•å› ç´ æ–¹å·®åˆ†æã€å¤šå› ç´ æ–¹å·®åˆ†æ*")
    
    # å‚æ•°è¾“å…¥
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“‹ ç ”ç©¶è®¾è®¡å‚æ•°")
        
        anova_type = st.selectbox(
            "æ–¹å·®åˆ†æç±»å‹",
            ["å•å› ç´ æ–¹å·®åˆ†æ", "åŒå› ç´ æ–¹å·®åˆ†æ", "é‡å¤æµ‹é‡æ–¹å·®åˆ†æ"]
        )
        
        num_groups = st.number_input(
            "ç»„åˆ«æ•°é‡",
            min_value=2, max_value=10, value=3, step=1
        )
        
        if anova_type == "åŒå› ç´ æ–¹å·®åˆ†æ":
            factor_a_levels = st.number_input(
                "å› å­Aæ°´å¹³æ•°",
                min_value=2, max_value=5, value=2, step=1
            )
            factor_b_levels = st.number_input(
                "å› å­Bæ°´å¹³æ•°", 
                min_value=2, max_value=5, value=2, step=1
            )
            num_groups = factor_a_levels * factor_b_levels
        
        elif anova_type == "é‡å¤æµ‹é‡æ–¹å·®åˆ†æ":
            num_timepoints = st.number_input(
                "æµ‹é‡æ—¶é—´ç‚¹æ•°",
                min_value=2, max_value=8, value=3, step=1
            )
            correlation = st.slider(
                "é‡å¤æµ‹é‡ç›¸å…³ç³»æ•°",
                0.0, 0.9, 0.5, 0.1
            )
    
    with col2:
        st.markdown("### ğŸ“Š æ•ˆåº”é‡å‚æ•°")
        
        effect_input_method = st.selectbox(
            "æ•ˆåº”é‡è¾“å…¥æ–¹å¼",
            ["ç›´æ¥è¾“å…¥æ•ˆåº”é‡f", "è¾“å…¥å‡æ•°å’Œæ ‡å‡†å·®", "æ ¹æ®æ•ˆåº”å¤§å°é€‰æ‹©"]
        )
        
        if effect_input_method == "ç›´æ¥è¾“å…¥æ•ˆåº”é‡f":
            effect_size_f = st.number_input(
                "æ•ˆåº”é‡ f",
                min_value=0.1, max_value=1.0, value=0.25, step=0.05,
                help="å°æ•ˆåº”: 0.1, ä¸­ç­‰æ•ˆåº”: 0.25, å¤§æ•ˆåº”: 0.4"
            )
        
        elif effect_input_method == "æ ¹æ®æ•ˆåº”å¤§å°é€‰æ‹©":
            effect_level = st.selectbox(
                "æ•ˆåº”å¤§å°",
                ["å°æ•ˆåº” (f=0.1)", "ä¸­ç­‰æ•ˆåº” (f=0.25)", "å¤§æ•ˆåº” (f=0.4)"]
            )
            
            effect_mapping = {
                "å°æ•ˆåº” (f=0.1)": 0.1,
                "ä¸­ç­‰æ•ˆåº” (f=0.25)": 0.25,
                "å¤§æ•ˆåº” (f=0.4)": 0.4
            }
            effect_size_f = effect_mapping[effect_level]
        
        else:  # è¾“å…¥å‡æ•°å’Œæ ‡å‡†å·®
            st.markdown("**å„ç»„å‡æ•°:**")
            group_means = []
            for i in range(num_groups):
                mean = st.number_input(
                    f"ç¬¬{i+1}ç»„å‡æ•°",
                    value=10.0 + i * 2.0,
                    key=f"mean_{i}"
                )
                group_means.append(mean)
            
            pooled_sd = st.number_input(
                "ç»„å†…æ ‡å‡†å·®",
                min_value=0.1, value=3.0, step=0.1
            )
            
            # è®¡ç®—æ•ˆåº”é‡f
            grand_mean = np.mean(group_means)
            sum_squares_between = sum([(m - grand_mean)**2 for m in group_means])
            effect_size_f = np.sqrt(sum_squares_between / (num_groups * pooled_sd**2))
        
        st.info(f"ğŸ’¡ æ•ˆåº”é‡ f: {effect_size_f:.3f}")
    
    # æ ·æœ¬é‡è®¡ç®—
    try:
        if anova_type == "å•å› ç´ æ–¹å·®åˆ†æ":
            sample_size_per_group = calculate_one_way_anova_sample_size(
                effect_size_f, alpha, power, num_groups
            )
            total_n = sample_size_per_group * num_groups
            
        elif anova_type == "åŒå› ç´ æ–¹å·®åˆ†æ":
            sample_size_per_cell = calculate_two_way_anova_sample_size(
                effect_size_f, alpha, power, factor_a_levels, factor_b_levels
            )
            total_n = sample_size_per_cell * num_groups
            
        else:  # é‡å¤æµ‹é‡æ–¹å·®åˆ†æ
            sample_size = calculate_repeated_measures_anova_sample_size(
                effect_size_f, alpha, power, num_timepoints, correlation
            )
            sample_size_per_group = sample_size
            total_n = sample_size
        
        # ç»“æœæ˜¾ç¤º
        display_anova_results(
            anova_type, sample_size_per_group, total_n, num_groups, 
            effect_size_f, alpha, power
        )
        
        # æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis_anova(
            anova_type, effect_size_f, alpha, power, num_groups,
            show_power_curve, show_sample_curve
        )
    
    except Exception as e:
        st.error(f"âŒ æ ·æœ¬é‡è®¡ç®—å¤±è´¥: {str(e)}")

def calculate_one_way_anova_sample_size(effect_size_f, alpha, power, num_groups):
    """è®¡ç®—å•å› ç´ æ–¹å·®åˆ†ææ ·æœ¬é‡"""
    
    # è‡ªç”±åº¦
    df_between = num_groups - 1
    
    # éä¸­å¿ƒå‚æ•°
    lambda_param = effect_size_f**2
    
    # ä½¿ç”¨è¿­ä»£æ–¹æ³•æ±‚è§£æ ·æœ¬é‡
    def power_function(n_per_group):
        df_within = num_groups * (n_per_group - 1)
        ncp = lambda_param * n_per_group * num_groups
        
        # Fåˆ†å¸ƒä¸´ç•Œå€¼
        f_crit = stats.f.ppf(1 - alpha, df_between, df_within)
        
        # è®¡ç®—åŠŸæ•ˆ
        power_calc = 1 - stats.ncf.cdf(f_crit, df_between, df_within, ncp)
        
        return power_calc - power
    
    # æ±‚è§£æ ·æœ¬é‡
    try:
        n_per_group = fsolve(power_function, 10)[0]
        return max(2, int(np.ceil(n_per_group)))
    except:
        # å¤‡ç”¨å…¬å¼
        n_per_group = ((stats.norm.ppf(1-alpha) + stats.norm.ppf(power))**2) / (effect_size_f**2)
        return max(2, int(np.ceil(n_per_group)))

def calculate_two_way_anova_sample_size(effect_size_f, alpha, power, factor_a, factor_b):
    """è®¡ç®—åŒå› ç´ æ–¹å·®åˆ†ææ ·æœ¬é‡"""
    
    # ç®€åŒ–è®¡ç®—ï¼Œä½¿ç”¨å•å› ç´ å…¬å¼çš„è°ƒæ•´ç‰ˆæœ¬
    total_groups = factor_a * factor_b
    n_per_cell = calculate_one_way_anova_sample_size(effect_size_f, alpha, power, total_groups)
    
    return n_per_cell

def calculate_repeated_measures_anova_sample_size(effect_size_f, alpha, power, num_timepoints, correlation):
    """è®¡ç®—é‡å¤æµ‹é‡æ–¹å·®åˆ†ææ ·æœ¬é‡"""
    
    # è€ƒè™‘ç›¸å…³æ€§çš„è°ƒæ•´
    epsilon = 1 - correlation  # çƒå½¢åº¦å‡è®¾è°ƒæ•´
    adjusted_effect = effect_size_f / np.sqrt(epsilon)
    
    # ä½¿ç”¨è°ƒæ•´åçš„æ•ˆåº”é‡è®¡ç®—æ ·æœ¬é‡
    n = calculate_one_way_anova_sample_size(adjusted_effect, alpha, power, num_timepoints)
    
    return n

def display_anova_results(anova_type, n_per_group, total_n, num_groups, effect_size_f, alpha, power):
    """æ˜¾ç¤ºæ–¹å·®åˆ†ææ ·æœ¬é‡ç»“æœ"""
    st.markdown("### ğŸ¯ æ ·æœ¬é‡è®¡ç®—ç»“æœ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if anova_type == "é‡å¤æµ‹é‡æ–¹å·®åˆ†æ":
            st.metric("æ‰€éœ€å—è¯•è€…æ•°", n_per_group)
        else:
            st.metric("æ¯ç»„æ ·æœ¬é‡", n_per_group)
    
    with col2:
        st.metric("ç»„åˆ«æ•°é‡", num_groups)
    
    with col3:
        st.metric("æ€»æ ·æœ¬é‡", total_n)
    
    # è¯¦ç»†å‚æ•°è¡¨
    st.markdown("### ğŸ“‹ è®¡ç®—å‚æ•°æ‘˜è¦")
    
    params_df = pd.DataFrame({
        'å‚æ•°': [
            'æ–¹å·®åˆ†æç±»å‹',
            'æ•ˆåº”é‡(f)',
            'æ˜¾è‘—æ€§æ°´å¹³(Î±)',
            'ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)',
            'ç»„åˆ«æ•°é‡'
        ],
        'æ•°å€¼': [
            anova_type,
            f"{effect_size_f:.3f}",
            f"{alpha:.3f}",
            f"{power:.3f}",
            str(num_groups)
        ]
    })
    
    st.dataframe(params_df, hide_index=True)

def sensitivity_analysis_anova(anova_type, effect_size_f, alpha, power, num_groups, show_power_curve, show_sample_curve):
    """æ–¹å·®åˆ†æçš„æ•æ„Ÿæ€§åˆ†æ"""
    st.markdown("### ğŸ“ˆ æ•æ„Ÿæ€§åˆ†æ")
    
    tab1, tab2 = st.tabs(["åŠŸæ•ˆæ›²çº¿", "æ ·æœ¬é‡æ›²çº¿"])
    
    with tab1:
        if show_power_curve:
            st.markdown("#### ğŸ”‹ ç»Ÿè®¡åŠŸæ•ˆæ›²çº¿")
            
            effect_range = np.linspace(0.05, 0.8, 50)
            powers = []
            
            for f in effect_range:
                n = calculate_one_way_anova_sample_size(f, alpha, 0.8, num_groups)
                actual_power = calculate_actual_power_anova(n, f, alpha, num_groups)
                powers.append(actual_power)
            
            fig_power = go.Figure()
            
            fig_power.add_trace(go.Scatter(
                x=effect_range,
                y=powers,
                mode='lines',
                name='ç»Ÿè®¡åŠŸæ•ˆ',
                line=dict(color='blue', width=3)
            ))
            
            fig_power.add_hline(y=0.8, line_dash="dash", line_color="red", 
                               annotation_text="ç›®æ ‡åŠŸæ•ˆ (80%)")
            fig_power.add_vline(x=effect_size_f, line_dash="dash", line_color="green",
                               annotation_text=f"å½“å‰æ•ˆåº”é‡ ({effect_size_f:.3f})")
            
            fig_power.update_layout(
                title="ç»Ÿè®¡åŠŸæ•ˆéšæ•ˆåº”é‡å˜åŒ–æ›²çº¿",
                xaxis_title="æ•ˆåº”é‡ (f)",
                yaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis=dict(range=[0, 1]),
                height=400
            )
                        st.plotly_chart(fig_power, use_container_width=True)
    
    with tab2:
        if show_sample_curve:
            st.markdown("#### ğŸ“Š æ ·æœ¬é‡éœ€æ±‚æ›²çº¿")
            
            power_range = np.linspace(0.5, 0.99, 50)
            sample_sizes = []
            
            for p in power_range:
                n = calculate_one_way_anova_sample_size(effect_size_f, alpha, p, num_groups)
                total_n = n * num_groups
                sample_sizes.append(total_n)
            
            fig_sample = go.Figure()
            
            fig_sample.add_trace(go.Scatter(
                x=power_range,
                y=sample_sizes,
                mode='lines',
                name='æ€»æ ·æœ¬é‡',
                line=dict(color='orange', width=3)
            ))
            
            fig_sample.add_vline(x=power, line_dash="dash", line_color="red",
                                annotation_text=f"ç›®æ ‡åŠŸæ•ˆ ({power:.0%})")
            
            fig_sample.update_layout(
                title="æ ·æœ¬é‡éœ€æ±‚éšç»Ÿè®¡åŠŸæ•ˆå˜åŒ–æ›²çº¿",
                xaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis_title="æ€»æ ·æœ¬é‡",
                height=400
            )
            
            st.plotly_chart(fig_sample, use_container_width=True)

def calculate_actual_power_anova(n_per_group, effect_size_f, alpha, num_groups):
    """è®¡ç®—æ–¹å·®åˆ†æçš„å®é™…ç»Ÿè®¡åŠŸæ•ˆ"""
    try:
        df_between = num_groups - 1
        df_within = num_groups * (n_per_group - 1)
        ncp = effect_size_f**2 * n_per_group * num_groups
        
        f_crit = stats.f.ppf(1 - alpha, df_between, df_within)
        power = 1 - stats.ncf.cdf(f_crit, df_between, df_within, ncp)
        
        return min(max(power, 0), 1)
    except:
        return 0.5

def survival_sample_size(alpha, power, show_power_curve, show_sample_curve):
    """ç”Ÿå­˜åˆ†ææ ·æœ¬é‡è®¡ç®—"""
    st.markdown("## âš–ï¸ ç”Ÿå­˜åˆ†ææ ·æœ¬é‡è®¡ç®—")
    st.markdown("*é€‚ç”¨äºLog-rankæ£€éªŒã€Coxå›å½’ç­‰ç”Ÿå­˜åˆ†æ*")
    
    # å‚æ•°è¾“å…¥
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“‹ ç ”ç©¶è®¾è®¡å‚æ•°")
        
        survival_design = st.selectbox(
            "ç”Ÿå­˜åˆ†æç±»å‹",
            ["Log-rankæ£€éªŒ", "Coxå›å½’åˆ†æ", "æŒ‡æ•°ç”Ÿå­˜æ¨¡å‹"]
        )
        
        test_type = st.selectbox(
            "æ£€éªŒç±»å‹",
            ["åŒä¾§æ£€éªŒ", "å•ä¾§æ£€éªŒ"]
        )
        
        allocation_ratio = st.number_input(
            "åˆ†ç»„æ¯”ä¾‹ (è¯•éªŒç»„:å¯¹ç…§ç»„)",
            min_value=0.1, max_value=5.0, value=1.0, step=0.1
        )
        
        study_duration = st.number_input(
            "ç ”ç©¶æŒç»­æ—¶é—´ (å¹´)",
            min_value=0.5, max_value=10.0, value=3.0, step=0.5
        )
        
        accrual_period = st.number_input(
            "å…¥ç»„æœŸ (å¹´)",
            min_value=0.5, max_value=5.0, value=2.0, step=0.5
        )
    
    with col2:
        st.markdown("### ğŸ“Š ç”Ÿå­˜å‚æ•°")
        
        param_input_method = st.selectbox(
            "å‚æ•°è¾“å…¥æ–¹å¼",
            ["è¾“å…¥é£é™©æ¯”", "è¾“å…¥ä¸­ä½ç”Ÿå­˜æ—¶é—´", "è¾“å…¥ç”Ÿå­˜ç‡"]
        )
        
        if param_input_method == "è¾“å…¥é£é™©æ¯”":
            hazard_ratio = st.number_input(
                "é£é™©æ¯” (HR)",
                min_value=0.1, max_value=5.0, value=0.7, step=0.1,
                help="HR<1è¡¨ç¤ºè¯•éªŒç»„ä¼˜äºå¯¹ç…§ç»„"
            )
            
            # ä¼°ç®—å¯¹ç…§ç»„äº‹ä»¶ç‡
            control_event_rate = st.slider(
                "å¯¹ç…§ç»„é¢„æœŸäº‹ä»¶ç‡",
                0.1, 0.9, 0.6, 0.05
            )
            
        elif param_input_method == "è¾“å…¥ä¸­ä½ç”Ÿå­˜æ—¶é—´":
            median_control = st.number_input(
                "å¯¹ç…§ç»„ä¸­ä½ç”Ÿå­˜æ—¶é—´ (å¹´)",
                min_value=0.1, max_value=10.0, value=2.0, step=0.1
            )
            
            median_treatment = st.number_input(
                "è¯•éªŒç»„ä¸­ä½ç”Ÿå­˜æ—¶é—´ (å¹´)",
                min_value=0.1, max_value=10.0, value=3.0, step=0.1
            )
            
            # è®¡ç®—é£é™©æ¯”
            hazard_ratio = median_control / median_treatment
            
            # ä¼°ç®—äº‹ä»¶ç‡
            control_event_rate = 1 - np.exp(-np.log(2) * study_duration / median_control)
            
        else:  # è¾“å…¥ç”Ÿå­˜ç‡
            survival_rate_control = st.number_input(
                "å¯¹ç…§ç»„ç”Ÿå­˜ç‡",
                min_value=0.01, max_value=0.99, value=0.4, step=0.01
            )
            
            survival_rate_treatment = st.number_input(
                "è¯•éªŒç»„ç”Ÿå­˜ç‡",
                min_value=0.01, max_value=0.99, value=0.6, step=0.01
            )
            
            # è®¡ç®—é£é™©æ¯”
            hazard_control = -np.log(survival_rate_control) / study_duration
            hazard_treatment = -np.log(survival_rate_treatment) / study_duration
            hazard_ratio = hazard_treatment / hazard_control
            
            control_event_rate = 1 - survival_rate_control
        
        st.info(f"ğŸ’¡ è®¡ç®—å¾—åˆ°çš„é£é™©æ¯”: {hazard_ratio:.3f}")
        st.info(f"ğŸ’¡ å¯¹ç…§ç»„äº‹ä»¶ç‡: {control_event_rate:.3f}")
    
    # æ ·æœ¬é‡è®¡ç®—
    try:
        if survival_design == "Log-rankæ£€éªŒ":
            total_events, total_sample = calculate_logrank_sample_size(
                hazard_ratio, alpha, power, allocation_ratio, 
                control_event_rate, test_type
            )
            
        elif survival_design == "Coxå›å½’åˆ†æ":
            total_events, total_sample = calculate_cox_regression_sample_size(
                hazard_ratio, alpha, power, allocation_ratio,
                control_event_rate, test_type
            )
            
        else:  # æŒ‡æ•°ç”Ÿå­˜æ¨¡å‹
            total_events, total_sample = calculate_exponential_survival_sample_size(
                hazard_ratio, alpha, power, allocation_ratio,
                control_event_rate, study_duration, accrual_period
            )
        
        # ç»“æœæ˜¾ç¤º
        display_survival_results(
            survival_design, total_sample, total_events, hazard_ratio,
            alpha, power, allocation_ratio, control_event_rate
        )
        
        # æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis_survival(
            hazard_ratio, alpha, power, allocation_ratio, control_event_rate,
            show_power_curve, show_sample_curve
        )
    
    except Exception as e:
        st.error(f"âŒ æ ·æœ¬é‡è®¡ç®—å¤±è´¥: {str(e)}")

def calculate_logrank_sample_size(hr, alpha, power, ratio, event_rate, test_type):
    """è®¡ç®—Log-rankæ£€éªŒæ ·æœ¬é‡"""
    
    if test_type == "åŒä¾§æ£€éªŒ":
        z_alpha = stats.norm.ppf(1 - alpha/2)
    else:
        z_alpha = stats.norm.ppf(1 - alpha)
    
    z_beta = stats.norm.ppf(power)
    
    # Log-rankæ£€éªŒæ‰€éœ€äº‹ä»¶æ•°
    p1 = 1 / (1 + ratio)  # è¯•éªŒç»„æ¯”ä¾‹
    p2 = ratio / (1 + ratio)  # å¯¹ç…§ç»„æ¯”ä¾‹
    
    # æ‰€éœ€äº‹ä»¶æ•°
    events_needed = ((z_alpha + z_beta) / np.log(hr))**2 / (p1 * p2)
    
    # æ€»æ ·æœ¬é‡
    total_sample = events_needed / event_rate
    
    return int(np.ceil(events_needed)), int(np.ceil(total_sample))

def calculate_cox_regression_sample_size(hr, alpha, power, ratio, event_rate, test_type):
    """è®¡ç®—Coxå›å½’åˆ†ææ ·æœ¬é‡"""
    
    # Coxå›å½’ä¸Log-rankæ£€éªŒç±»ä¼¼ï¼Œä½†éœ€è¦è€ƒè™‘åå˜é‡
    events_needed, total_sample = calculate_logrank_sample_size(
        hr, alpha, power, ratio, event_rate, test_type
    )
    
    # Coxå›å½’é€šå¸¸éœ€è¦æ›´å¤šæ ·æœ¬ï¼ˆè€ƒè™‘åå˜é‡è°ƒæ•´ï¼‰
    inflation_factor = 1.1  # 10%çš„æ ·æœ¬é‡å¢åŠ 
    
    return int(np.ceil(events_needed * inflation_factor)), int(np.ceil(total_sample * inflation_factor))

def calculate_exponential_survival_sample_size(hr, alpha, power, ratio, event_rate, 
                                             study_duration, accrual_period):
    """è®¡ç®—æŒ‡æ•°ç”Ÿå­˜æ¨¡å‹æ ·æœ¬é‡"""
    
    # åŸºç¡€Log-rankæ ·æœ¬é‡
    events_needed, base_sample = calculate_logrank_sample_size(
        hr, alpha, power, ratio, event_rate, "åŒä¾§æ£€éªŒ"
    )
    
    # è€ƒè™‘å…¥ç»„æ—¶é—´å’Œéšè®¿æ—¶é—´çš„è°ƒæ•´
    follow_up_time = study_duration - accrual_period
    
    if follow_up_time > 0:
        # è°ƒæ•´å› å­åŸºäºå…¥ç»„æ¨¡å¼å’Œéšè®¿æ—¶é—´
        adjustment_factor = 1 + (accrual_period / (2 * follow_up_time))
        total_sample = base_sample * adjustment_factor
    else:
        total_sample = base_sample * 1.5  # ä¿å®ˆä¼°è®¡
    
    return events_needed, int(np.ceil(total_sample))

def display_survival_results(survival_design, total_sample, total_events, hr, 
                           alpha, power, ratio, event_rate):
    """æ˜¾ç¤ºç”Ÿå­˜åˆ†ææ ·æœ¬é‡ç»“æœ"""
    st.markdown("### ğŸ¯ æ ·æœ¬é‡è®¡ç®—ç»“æœ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ€»æ ·æœ¬é‡", total_sample)
    
    with col2:
        st.metric("æ‰€éœ€äº‹ä»¶æ•°", total_events)
    
    with col3:
        treatment_n = int(total_sample / (1 + ratio))
        st.metric("è¯•éªŒç»„æ ·æœ¬é‡", treatment_n)
    
    with col4:
        control_n = total_sample - treatment_n
        st.metric("å¯¹ç…§ç»„æ ·æœ¬é‡", control_n)
    
    # è¯¦ç»†å‚æ•°è¡¨
    st.markdown("### ğŸ“‹ è®¡ç®—å‚æ•°æ‘˜è¦")
    
    params_df = pd.DataFrame({
        'å‚æ•°': [
            'ç”Ÿå­˜åˆ†æç±»å‹',
            'é£é™©æ¯”(HR)',
            'å¯¹ç…§ç»„äº‹ä»¶ç‡',
            'åˆ†ç»„æ¯”ä¾‹',
            'æ˜¾è‘—æ€§æ°´å¹³(Î±)',
            'ç»Ÿè®¡åŠŸæ•ˆ(1-Î²)'
        ],
        'æ•°å€¼': [
            survival_design,
            f"{hr:.3f}",
            f"{event_rate:.3f}",
            f"1:{ratio:.1f}",
            f"{alpha:.3f}",
            f"{power:.3f}"
        ]
    })
    
    st.dataframe(params_df, hide_index=True)
    
    # ç»“æœè§£é‡Š
    st.markdown("### ğŸ“ ç»“æœè§£é‡Š")
    st.markdown(f"""
    **ç”Ÿå­˜åˆ†ææ ·æœ¬é‡ç»“æœè§£é‡Š:**
    - æ€»è®¡éœ€è¦ **{total_sample}** åå—è¯•è€…
    - éœ€è¦è§‚å¯Ÿåˆ° **{total_events}** ä¸ªäº‹ä»¶
    - è¯•éªŒç»„: **{int(total_sample / (1 + ratio))}** äºº
    - å¯¹ç…§ç»„: **{total_sample - int(total_sample / (1 + ratio))}** äºº
    - åœ¨Î±={alpha}ï¼ŒåŠŸæ•ˆ={power}çš„æ¡ä»¶ä¸‹ï¼Œèƒ½å¤Ÿæ£€å‡ºé£é™©æ¯”ä¸º{hr:.3f}çš„å·®å¼‚
    """)

def sensitivity_analysis_survival(hr, alpha, power, ratio, event_rate, show_power_curve, show_sample_curve):
    """ç”Ÿå­˜åˆ†æçš„æ•æ„Ÿæ€§åˆ†æ"""
    st.markdown("### ğŸ“ˆ æ•æ„Ÿæ€§åˆ†æ")
    
    tab1, tab2 = st.tabs(["åŠŸæ•ˆæ›²çº¿", "æ ·æœ¬é‡æ›²çº¿"])
    
    with tab1:
        if show_power_curve:
            st.markdown("#### ğŸ”‹ ç»Ÿè®¡åŠŸæ•ˆæ›²çº¿")
            
            hr_range = np.linspace(0.3, 1.5, 50)
            powers = []
            
            for hr_val in hr_range:
                if abs(hr_val - 1.0) > 0.01:  # é¿å…HR=1çš„æƒ…å†µ
                    events, total_n = calculate_logrank_sample_size(
                        hr_val, alpha, 0.8, ratio, event_rate, "åŒä¾§æ£€éªŒ"
                    )
                    actual_power = calculate_actual_power_survival(
                        total_n, hr_val, alpha, ratio, event_rate
                    )
                    powers.append(actual_power)
                else:
                    powers.append(0.05)  # HR=1æ—¶åŠŸæ•ˆæ¥è¿‘Î±
            
            fig_power = go.Figure()
            
            fig_power.add_trace(go.Scatter(
                x=hr_range,
                y=powers,
                mode='lines',
                name='ç»Ÿè®¡åŠŸæ•ˆ',
                line=dict(color='blue', width=3)
            ))
            
            fig_power.add_hline(y=0.8, line_dash="dash", line_color="red", 
                               annotation_text="ç›®æ ‡åŠŸæ•ˆ (80%)")
            fig_power.add_vline(x=hr, line_dash="dash", line_color="green",
                               annotation_text=f"å½“å‰HR ({hr:.3f})")
            fig_power.add_vline(x=1.0, line_dash="dot", line_color="gray",
                               annotation_text="æ— æ•ˆåº” (HR=1)")
            
            fig_power.update_layout(
                title="ç»Ÿè®¡åŠŸæ•ˆéšé£é™©æ¯”å˜åŒ–æ›²çº¿",
                xaxis_title="é£é™©æ¯” (HR)",
                yaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis=dict(range=[0, 1]),
                height=400
            )
            
            st.plotly_chart(fig_power, use_container_width=True)
    
    with tab2:
        if show_sample_curve:
            st.markdown("#### ğŸ“Š æ ·æœ¬é‡éœ€æ±‚æ›²çº¿")
            
            power_range = np.linspace(0.5, 0.99, 50)
            sample_sizes = []
            
            for p in power_range:
                events, total_n = calculate_logrank_sample_size(
                    hr, alpha, p, ratio, event_rate, "åŒä¾§æ£€éªŒ"
                )
                sample_sizes.append(total_n)
            
            fig_sample = go.Figure()
            
            fig_sample.add_trace(go.Scatter(
                x=power_range,
                y=sample_sizes,
                mode='lines',
                name='æ€»æ ·æœ¬é‡',
                line=dict(color='orange', width=3)
            ))
            
            fig_sample.add_vline(x=power, line_dash="dash", line_color="red",
                                annotation_text=f"ç›®æ ‡åŠŸæ•ˆ ({power:.0%})")
            
            fig_sample.update_layout(
                title="æ ·æœ¬é‡éœ€æ±‚éšç»Ÿè®¡åŠŸæ•ˆå˜åŒ–æ›²çº¿",
                xaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
                yaxis_title="æ€»æ ·æœ¬é‡",
                height=400
            )
            
            st.plotly_chart(fig_sample, use_container_width=True)

def calculate_actual_power_survival(n, hr, alpha, ratio, event_rate):
    """è®¡ç®—ç”Ÿå­˜åˆ†æçš„å®é™…ç»Ÿè®¡åŠŸæ•ˆ"""
    try:
        z_alpha = stats.norm.ppf(1 - alpha/2)
        
        p1 = 1 / (1 + ratio)
        p2 = ratio / (1 + ratio)
        
        events = n * event_rate
        z_beta = np.log(hr) * np.sqrt(events * p1 * p2) - z_alpha
        power = stats.norm.cdf(z_beta)
        
        return min(max(power, 0), 1)
    except:
        return 0.5

def power_analysis(alpha, show_power_curve, show_sample_curve):
    """åŠŸæ•ˆåˆ†æ"""
    st.markdown("## âš¡ åŠŸæ•ˆåˆ†æ")
    st.markdown("*å·²çŸ¥æ ·æœ¬é‡ï¼Œè®¡ç®—ç»Ÿè®¡åŠŸæ•ˆ*")
    
    # å‚æ•°è¾“å…¥
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ“‹ ç ”ç©¶è®¾è®¡å‚æ•°")
        
        analysis_type = st.selectbox(
            "åˆ†æç±»å‹",
            ["tæ£€éªŒåŠŸæ•ˆåˆ†æ", "æ¯”ä¾‹æ£€éªŒåŠŸæ•ˆåˆ†æ", "ç›¸å…³åˆ†æåŠŸæ•ˆåˆ†æ", "æ–¹å·®åˆ†æåŠŸæ•ˆåˆ†æ"]
        )
        
        sample_size = st.number_input(
            "å·²çŸ¥æ ·æœ¬é‡",
            min_value=5, max_value=10000, value=100, step=5
        )
        
        if analysis_type in ["tæ£€éªŒåŠŸæ•ˆåˆ†æ", "æ¯”ä¾‹æ£€éªŒåŠŸæ•ˆåˆ†æ"]:
            allocation_ratio = st.number_input(
                "åˆ†ç»„æ¯”ä¾‹ (å¦‚é€‚ç”¨)",
                min_value=0.1, max_value=5.0, value=1.0, step=0.1
            )
    
    with col2:
        st.markdown("### ğŸ“Š æ•ˆåº”é‡å‚æ•°")
        
        if analysis_type == "tæ£€éªŒåŠŸæ•ˆåˆ†æ":
            effect_size = st.number_input(
                "æ•ˆåº”é‡ (Cohen's d)",
                min_value=0.1, max_value=2.0, value=0.5, step=0.1
            )
            
        elif analysis_type == "æ¯”ä¾‹æ£€éªŒåŠŸæ•ˆåˆ†æ":
            p1 = st.number_input("ç»„1æ¯”ä¾‹", min_value=0.01, max_value=0.99, value=0.6, step=0.01)
            p2 = st.number_input("ç»„2æ¯”ä¾‹", min_value=0.01, max_value=0.99, value=0.4, step=0.01)
            effect_size = abs(p1 - p2)
            
        elif analysis_type == "ç›¸å…³åˆ†æåŠŸæ•ˆåˆ†æ":
            effect_size = st.number_input(
                "ç›¸å…³ç³»æ•° (r)",
                min_value=0.01, max_value=0.99, value=0.3, step=0.01
            )
            
        else:  # æ–¹å·®åˆ†æåŠŸæ•ˆåˆ†æ
            effect_size = st.number_input(
                "æ•ˆåº”é‡ (f)",
                min_value=0.1, max_value=1.0, value=0.25, step=0.05
            )
            num_groups = st.number_input(
                "ç»„åˆ«æ•°é‡",
                min_value=2, max_value=10, value=3, step=1
            )
    
    # åŠŸæ•ˆè®¡ç®—
    try:
        if analysis_type == "tæ£€éªŒåŠŸæ•ˆåˆ†æ":
            calculated_power = calculate_power_t_test(sample_size, effect_size, alpha, allocation_ratio)
            
        elif analysis_type == "æ¯”ä¾‹æ£€éªŒåŠŸæ•ˆåˆ†æ":
            calculated_power = calculate_power_proportion_test(sample_size, p1, p2, alpha, allocation_ratio)
            
        elif analysis_type == "ç›¸å…³åˆ†æåŠŸæ•ˆåˆ†æ":
            calculated_power = calculate_power_correlation(sample_size, effect_size, alpha)
            
        else:  # æ–¹å·®åˆ†æåŠŸæ•ˆåˆ†æ
            calculated_power = calculate_power_anova(sample_size, effect_size, alpha, num_groups)
        
        # ç»“æœæ˜¾ç¤º
        display_power_analysis_results(
            analysis_type, sample_size, effect_size, alpha, calculated_power
        )
        
        # åŠŸæ•ˆæ›²çº¿
        if show_power_curve:
            display_power_curves(analysis_type, sample_size, effect_size, alpha)
    
    except Exception as e:
        st.error(f"âŒ åŠŸæ•ˆè®¡ç®—å¤±è´¥: {str(e)}")

def calculate_power_t_test(n, effect_size, alpha, ratio=1.0):
    """è®¡ç®—tæ£€éªŒçš„ç»Ÿè®¡åŠŸæ•ˆ"""
    z_alpha = stats.norm.ppf(1 - alpha/2)
    se = np.sqrt((1 + 1/ratio) / n)
    z_beta = effect_size / se - z_alpha
    power = stats.norm.cdf(z_beta)
    return min(max(power, 0), 1)

def calculate_power_proportion_test(n, p1, p2, alpha, ratio=1.0):
    """è®¡ç®—æ¯”ä¾‹æ£€éªŒçš„ç»Ÿè®¡åŠŸæ•ˆ"""
    z_alpha = stats.norm.ppf(1 - alpha/2)
    p_pooled = (p1 + ratio * p2) / (1 + ratio)
    
    se_null = np.sqrt(p_pooled * (1 - p_pooled) * (1 + 1/ratio) / n)
    se_alt = np.sqrt(p1 * (1 - p1) / n + p2 * (1 - p2) / (n * ratio))
    
    z_beta = abs(p1 - p2) / se_alt - z_alpha
    power = stats.norm.cdf(z_beta)
    return min(max(power, 0), 1)

def calculate_power_correlation(n, r, alpha):
    """è®¡ç®—ç›¸å…³åˆ†æçš„ç»Ÿè®¡åŠŸæ•ˆ"""
    z_alpha = stats.norm.ppf(1 - alpha/2)
    z_r = 0.5 * np.log((1 + r) / (1 - r))
    se = 1 / np.sqrt(n - 3)
    
    z_beta = z_r / se - z_alpha
    power = stats.norm.cdf(z_beta)
    return min(max(power, 0), 1)

def calculate_power_anova(n_per_group, effect_size_f, alpha, num_groups):
    """è®¡ç®—æ–¹å·®åˆ†æçš„ç»Ÿè®¡åŠŸæ•ˆ"""
    df_between = num_groups - 1
    df_within = num_groups * (n_per_group - 1)
    ncp = effect_size_f**2 * n_per_group * num_groups
    
    f_crit = stats.f.ppf(1 - alpha, df_between, df_within)
    power = 1 - stats.ncf.cdf(f_crit, df_between, df_within, ncp)
    return min(max(power, 0), 1)

def display_power_analysis_results(analysis_type, sample_size, effect_size, alpha, power):
    """æ˜¾ç¤ºåŠŸæ•ˆåˆ†æç»“æœ"""
    st.markdown("### âš¡ åŠŸæ•ˆåˆ†æç»“æœ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ ·æœ¬é‡", sample_size)
    
    with col2:
        st.metric("æ•ˆåº”é‡", f"{effect_size:.3f}")
    
    with col3:
        st.metric("æ˜¾è‘—æ€§æ°´å¹³", f"{alpha:.3f}")
    
    with col4:
        st.metric("ç»Ÿè®¡åŠŸæ•ˆ", f"{power:.3f}", f"{power*100:.1f}%")
    
    # åŠŸæ•ˆè§£é‡Š
    st.markdown("### ğŸ“ åŠŸæ•ˆè§£é‡Š")
    
    if power >= 0.8:
        st.success(f"âœ… ç»Ÿè®¡åŠŸæ•ˆå……è¶³ ({power:.1%})ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹åˆ°é¢„æœŸæ•ˆåº”")
    elif power >= 0.6:
        st.warning(f"âš ï¸ ç»Ÿè®¡åŠŸæ•ˆä¸­ç­‰ ({power:.1%})ï¼Œå¯èƒ½æ— æ³•å……åˆ†æ£€æµ‹åˆ°é¢„æœŸæ•ˆåº”")
    else:
        st.error(f"âŒ ç»Ÿè®¡åŠŸæ•ˆä¸è¶³ ({power:.1%})ï¼Œå»ºè®®å¢åŠ æ ·æœ¬é‡")
    
    # å»ºè®®
    st.markdown("### ğŸ’¡ å»ºè®®")
    
    if power < 0.8:
        # è®¡ç®—è¾¾åˆ°80%åŠŸæ•ˆæ‰€éœ€çš„æ ·æœ¬é‡
        if analysis_type == "tæ£€éªŒåŠŸæ•ˆåˆ†æ":
            recommended_n = calculate_two_sample_t_test_size(effect_size, alpha, 0.8, 1.0, "åŒä¾§æ£€éªŒ")
        elif analysis_type == "ç›¸å…³åˆ†æåŠŸæ•ˆåˆ†æ":
            recommended_n = calculate_correlation_sample_size(effect_size, 0, alpha, 0.8, "åŒä¾§æ£€éªŒ")
        else:
            recommended_n = sample_size * 1.5  # ç®€å•ä¼°è®¡
        
        st.info(f"ğŸ’¡ å»ºè®®æ ·æœ¬é‡: {int(np.ceil(recommended_n))} (è¾¾åˆ°80%åŠŸæ•ˆ)")

def display_power_curves(analysis_type, sample_size, effect_size, alpha):
    """æ˜¾ç¤ºåŠŸæ•ˆæ›²çº¿"""
    st.markdown("### ğŸ“ˆ åŠŸæ•ˆæ›²çº¿åˆ†æ")
    
    if analysis_type == "tæ£€éªŒåŠŸæ•ˆåˆ†æ":
        effect_range = np.linspace(0.1, 1.5, 50)
        powers = [calculate_power_t_test(sample_size, es, alpha) for es in effect_range]
        x_label = "æ•ˆåº”é‡ (Cohen's d)"
        
    elif analysis_type == "ç›¸å…³åˆ†æåŠŸæ•ˆåˆ†æ":
        effect_range = np.linspace(0.05, 0.8, 50)
        powers = [calculate_power_correlation(sample_size, r, alpha) for r in effect_range]
        x_label = "ç›¸å…³ç³»æ•° (r)"
        
    else:
        return  # å…¶ä»–ç±»å‹æš‚ä¸æ˜¾ç¤º
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=effect_range,
        y=powers,
        mode='lines',
        name='ç»Ÿè®¡åŠŸæ•ˆ',
        line=dict(color='blue', width=3)
    ))
    
    fig.add_hline(y=0.8, line_dash="dash", line_color="red", 
                  annotation_text="ç›®æ ‡åŠŸæ•ˆ (80%)")
    fig.add_vline(x=effect_size, line_dash="dash", line_color="green",
                  annotation_text=f"å½“å‰æ•ˆåº”é‡ ({effect_size:.3f})")
    
    fig.update_layout(
        title=f"ç»Ÿè®¡åŠŸæ•ˆæ›²çº¿ (n={sample_size})",
        xaxis_title=x_label,
        yaxis_title="ç»Ÿè®¡åŠŸæ•ˆ",
        yaxis=dict(range=[0, 1]),
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)

# ä¸»å‡½æ•°è°ƒç”¨
if __name__ == "__main__":
    sample_size_calculator()

