# reporting.py - æŠ¥å‘Šç”Ÿæˆæ¨¡å—
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import io
import base64
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image
from reportlab.lib import colors
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
import docx
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import json
import zipfile
import tempfile
import os

def reporting_module():
    """æŠ¥å‘Šç”Ÿæˆæ¨¡å—ä¸»ç•Œé¢"""
    st.title("ğŸ“„ æŠ¥å‘Šç”Ÿæˆæ¨¡å—")
    st.markdown("---")
    
    # ä¾§è¾¹æ  - æŠ¥å‘Šç±»å‹é€‰æ‹©
    st.sidebar.markdown("### ğŸ“‹ æŠ¥å‘Šç±»å‹")
    
    report_types = {
        "ğŸ“Š ç»Ÿè®¡åˆ†ææŠ¥å‘Š": "statistical_report",
        "ğŸ“ˆ æ•°æ®å¯è§†åŒ–æŠ¥å‘Š": "visualization_report", 
        "ğŸ” æ•°æ®è´¨é‡æŠ¥å‘Š": "quality_report",
        "ğŸ“‹ ç ”ç©¶æ€»ç»“æŠ¥å‘Š": "summary_report",
        "âš ï¸ å®‰å…¨æ€§æŠ¥å‘Š": "safety_report",
        "ğŸ“Š ä¸­æœŸåˆ†ææŠ¥å‘Š": "interim_report",
        "ğŸ“‘ æœ€ç»ˆç ”ç©¶æŠ¥å‘Š": "final_report",
        "ğŸ“Š è‡ªå®šä¹‰æŠ¥å‘Š": "custom_report"
    }
    
    selected_report = st.sidebar.selectbox(
        "é€‰æ‹©æŠ¥å‘Šç±»å‹",
        options=list(report_types.keys())
    )
    
    report_type = report_types[selected_report]
    
    # ä¸»ç•Œé¢
    st.markdown(f"## {selected_report}")
    
    # æ•°æ®æºé€‰æ‹©
    st.markdown("### ğŸ“ æ•°æ®æºé€‰æ‹©")
    
    data_source = st.selectbox(
        "é€‰æ‹©æ•°æ®æº",
        ["ä¸Šä¼ æ–‡ä»¶", "ä½¿ç”¨ç¤ºä¾‹æ•°æ®", "è¿æ¥æ•°æ®åº“"]
    )
    
    df = None
    
    if data_source == "ä¸Šä¼ æ–‡ä»¶":
        uploaded_file = st.file_uploader(
            "é€‰æ‹©æ•°æ®æ–‡ä»¶",
            type=['csv', 'xlsx', 'json'],
            help="æ”¯æŒCSVã€Excelå’ŒJSONæ ¼å¼"
        )
        
        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith('.xlsx'):
                    df = pd.read_excel(uploaded_file)
                elif uploaded_file.name.endswith('.json'):
                    df = pd.read_json(uploaded_file)
                
                st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼å…± {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")
                
            except Exception as e:
                st.error(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")
    
    elif data_source == "ä½¿ç”¨ç¤ºä¾‹æ•°æ®":
        df = generate_sample_data()
        st.success("ç¤ºä¾‹æ•°æ®åŠ è½½æˆåŠŸï¼")
    
    elif data_source == "è¿æ¥æ•°æ®åº“":
        st.info("æ•°æ®åº“è¿æ¥åŠŸèƒ½å¼€å‘ä¸­...")
    
    # å¦‚æœæœ‰æ•°æ®ï¼Œæ˜¾ç¤ºæ•°æ®é¢„è§ˆ
    if df is not None:
        with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ"):
            st.dataframe(df.head(10))
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»è¡Œæ•°", len(df))
            with col2:
                st.metric("æ€»åˆ—æ•°", len(df.columns))
            with col3:
                st.metric("ç¼ºå¤±å€¼", df.isnull().sum().sum())
    
    # æ ¹æ®é€‰æ‹©çš„æŠ¥å‘Šç±»å‹è°ƒç”¨ç›¸åº”å‡½æ•°
    if df is not None:
        if report_type == "statistical_report":
            generate_statistical_report(df)
        elif report_type == "visualization_report":
            generate_visualization_report(df)
        elif report_type == "quality_report":
            generate_quality_report(df)
        elif report_type == "summary_report":
            generate_summary_report(df)
        elif report_type == "safety_report":
            generate_safety_report(df)
        elif report_type == "interim_report":
            generate_interim_report(df)
        elif report_type == "final_report":
            generate_final_report(df)
        elif report_type == "custom_report":
            generate_custom_report(df)

def generate_sample_data():
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
    np.random.seed(42)
    
    n_subjects = 200
    
    # åŸºç¡€ä¿¡æ¯
    subject_ids = [f"S{i:04d}" for i in range(1, n_subjects + 1)]
    ages = np.random.normal(45, 12, n_subjects).astype(int)
    ages = np.clip(ages, 18, 80)
    
    genders = np.random.choice(['ç”·', 'å¥³'], n_subjects, p=[0.6, 0.4])
    
    # åˆ†ç»„ä¿¡æ¯
    groups = np.random.choice(['è¯•éªŒç»„', 'å¯¹ç…§ç»„'], n_subjects, p=[0.5, 0.5])
    
    # åŸºçº¿æŒ‡æ ‡
    baseline_sbp = np.random.normal(140, 15, n_subjects)
    baseline_dbp = np.random.normal(90, 10, n_subjects)
    baseline_weight = np.random.normal(70, 12, n_subjects)
    
    # ç»ˆç‚¹æŒ‡æ ‡ï¼ˆæ¨¡æ‹Ÿæ²»ç–—æ•ˆæœï¼‰
    treatment_effect = np.where(groups == 'è¯•éªŒç»„', -10, -2)
    endpoint_sbp = baseline_sbp + treatment_effect + np.random.normal(0, 8, n_subjects)
    endpoint_dbp = baseline_dbp + treatment_effect * 0.6 + np.random.normal(0, 6, n_subjects)
    
    # ä¸è‰¯äº‹ä»¶
    ae_prob = np.where(groups == 'è¯•éªŒç»„', 0.15, 0.12)
    adverse_events = np.random.binomial(1, ae_prob)
    
    # ä¾ä»æ€§
    compliance = np.random.normal(0.85, 0.15, n_subjects)
    compliance = np.clip(compliance, 0, 1)
    
    df = pd.DataFrame({
        'subject_id': subject_ids,
        'age': ages,
        'gender': genders,
        'group': groups,
        'baseline_sbp': baseline_sbp,
        'baseline_dbp': baseline_dbp,
        'baseline_weight': baseline_weight,
        'endpoint_sbp': endpoint_sbp,
        'endpoint_dbp': endpoint_dbp,
        'sbp_change': endpoint_sbp - baseline_sbp,
        'dbp_change': endpoint_dbp - baseline_dbp,
        'adverse_event': adverse_events,
        'compliance': compliance,
        'visit_date': pd.date_range('2024-01-01', periods=n_subjects, freq='D')
    })
    
    return df

def generate_statistical_report(df):
    """ç”Ÿæˆç»Ÿè®¡åˆ†ææŠ¥å‘Š"""
    st.markdown("### ğŸ“Š ç»Ÿè®¡åˆ†ææŠ¥å‘Š")
    
    # æŠ¥å‘Šé…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### âš™ï¸ åˆ†æé…ç½®")
        
        # é€‰æ‹©åˆ†ç»„å˜é‡
        group_var = st.selectbox(
            "åˆ†ç»„å˜é‡",
            options=[col for col in df.columns if df[col].dtype == 'object'],
            help="ç”¨äºåˆ†ç»„æ¯”è¾ƒçš„å˜é‡"
        )
        
        # é€‰æ‹©åˆ†æå˜é‡
        analysis_vars = st.multiselect(
            "åˆ†æå˜é‡",
            options=[col for col in df.columns if df[col].dtype in ['int64', 'float64']],
            help="éœ€è¦è¿›è¡Œç»Ÿè®¡åˆ†æçš„æ•°å€¼å˜é‡"
        )
        
        # ç»Ÿè®¡æ–¹æ³•é€‰æ‹©
        stat_methods = st.multiselect(
            "ç»Ÿè®¡æ–¹æ³•",
            ["æè¿°æ€§ç»Ÿè®¡", "tæ£€éªŒ", "å¡æ–¹æ£€éªŒ", "æ–¹å·®åˆ†æ", "éå‚æ•°æ£€éªŒ", "ç›¸å…³åˆ†æ"],
            default=["æè¿°æ€§ç»Ÿè®¡", "tæ£€éªŒ"]
        )
    
    with col2:
        st.markdown("#### ğŸ“‹ æŠ¥å‘Šé€‰é¡¹")
        
        include_plots = st.checkbox("åŒ…å«å›¾è¡¨", value=True)
        include_tables = st.checkbox("åŒ…å«ç»Ÿè®¡è¡¨æ ¼", value=True)
        confidence_level = st.slider("ç½®ä¿¡æ°´å¹³", 0.90, 0.99, 0.95, 0.01)
        
        report_format = st.selectbox(
            "æŠ¥å‘Šæ ¼å¼",
            ["HTML", "PDF", "Word", "PowerPoint"]
        )
        
        report_title = st.text_input(
            "æŠ¥å‘Šæ ‡é¢˜",
            value="ç»Ÿè®¡åˆ†ææŠ¥å‘Š"
        )
    
    if st.button("ğŸ“Š ç”Ÿæˆç»Ÿè®¡åˆ†ææŠ¥å‘Š", type="primary"):
        
        if not analysis_vars:
            st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªåˆ†æå˜é‡")
            return
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = create_statistical_analysis(
            df, group_var, analysis_vars, stat_methods, confidence_level
        )
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        display_statistical_report(
            report_content, include_plots, include_tables,
            report_title, report_format
        )

def create_statistical_analysis(df, group_var, analysis_vars, stat_methods, confidence_level):
    """åˆ›å»ºç»Ÿè®¡åˆ†æå†…å®¹"""
    
    results = {
        'basic_info': {
            'total_subjects': len(df),
            'analysis_date': datetime.now().strftime('%Y-%m-%d'),
            'confidence_level': confidence_level
        },
        'descriptive_stats': {},
        'group_comparison': {},
        'plots': {}
    }
    
    # æè¿°æ€§ç»Ÿè®¡
    if "æè¿°æ€§ç»Ÿè®¡" in stat_methods:
        results['descriptive_stats'] = perform_descriptive_analysis(df, group_var, analysis_vars)
    
    # ç»„é—´æ¯”è¾ƒ
    if any(method in stat_methods for method in ["tæ£€éªŒ", "å¡æ–¹æ£€éªŒ", "æ–¹å·®åˆ†æ", "éå‚æ•°æ£€éªŒ"]):
        results['group_comparison'] = perform_group_comparison(
            df, group_var, analysis_vars, stat_methods, confidence_level
        )
    
    # ç›¸å…³åˆ†æ
    if "ç›¸å…³åˆ†æ" in stat_methods:
        results['correlation_analysis'] = perform_correlation_analysis(df, analysis_vars)
    
    return results

def perform_descriptive_analysis(df, group_var, analysis_vars):
    """æ‰§è¡Œæè¿°æ€§ç»Ÿè®¡åˆ†æ"""
    
    descriptive_results = {}
    
    # æ€»ä½“æè¿°æ€§ç»Ÿè®¡
    overall_stats = []
    
    for var in analysis_vars:
        if var in df.columns:
            stats = {
                'variable': var,
                'n': df[var].count(),
                'mean': df[var].mean(),
                'std': df[var].std(),
                'min': df[var].min(),
                'q25': df[var].quantile(0.25),
                'median': df[var].median(),
                'q75': df[var].quantile(0.75),
                'max': df[var].max(),
                'missing': df[var].isnull().sum()
            }
            overall_stats.append(stats)
    
    descriptive_results['overall'] = pd.DataFrame(overall_stats)
    
    # åˆ†ç»„æè¿°æ€§ç»Ÿè®¡
    if group_var and group_var in df.columns:
        group_stats = {}
        
        for group in df[group_var].unique():
            group_data = df[df[group_var] == group]
            group_analysis = []
            
            for var in analysis_vars:
                if var in group_data.columns:
                    stats = {
                        'variable': var,
                        'group': group,
                        'n': group_data[var].count(),
                        'mean': group_data[var].mean(),
                        'std': group_data[var].std(),
                        'median': group_data[var].median(),
                        'missing': group_data[var].isnull().sum()
                    }
                    group_analysis.append(stats)
            
            group_stats[group] = pd.DataFrame(group_analysis)
        
        descriptive_results['by_group'] = group_stats
    
    return descriptive_results

def perform_group_comparison(df, group_var, analysis_vars, stat_methods, confidence_level):
    """æ‰§è¡Œç»„é—´æ¯”è¾ƒåˆ†æ"""
    
    from scipy import stats
    
    comparison_results = {}
    
    if not group_var or group_var not in df.columns:
        return comparison_results
    
    groups = df[group_var].unique()
    
    if len(groups) < 2:
        return comparison_results
    
    # ä¸¤ç»„æ¯”è¾ƒ
    if len(groups) == 2:
        group1_data = df[df[group_var] == groups[0]]
        group2_data = df[df[group_var] == groups[1]]
        
        for var in analysis_vars:
            if var in df.columns:
                var_results = {
                    'variable': var,
                    'group1': groups[0],
                    'group2': groups[1],
                    'group1_n': group1_data[var].count(),
                    'group2_n': group2_data[var].count(),
                    'group1_mean': group1_data[var].mean(),
                    'group2_mean': group2_data[var].mean(),
                    'mean_diff': group2_data[var].mean() - group1_data[var].mean()
                }
                
                # tæ£€éªŒ
                if "tæ£€éªŒ" in stat_methods:
                    try:
                        t_stat, p_value = stats.ttest_ind(
                            group1_data[var].dropna(),
                            group2_data[var].dropna()
                        )
                        var_results['t_statistic'] = t_stat
                        var_results['t_test_p_value'] = p_value
                        var_results['t_test_significant'] = p_value < (1 - confidence_level)
                    except:
                        var_results['t_test_error'] = "æ— æ³•æ‰§è¡Œtæ£€éªŒ"
                
                # éå‚æ•°æ£€éªŒ
                if "éå‚æ•°æ£€éªŒ" in stat_methods:
                    try:
                        u_stat, p_value = stats.mannwhitneyu(
                            group1_data[var].dropna(),
                            group2_data[var].dropna()
                        )
                        var_results['mannwhitney_u'] = u_stat
                        var_results['mannwhitney_p_value'] = p_value
                        var_results['mannwhitney_significant'] = p_value < (1 - confidence_level)
                    except:
                        var_results['mannwhitney_error'] = "æ— æ³•æ‰§è¡ŒMann-Whitneyæ£€éªŒ"
                
                comparison_results[var] = var_results
    
    # å¤šç»„æ¯”è¾ƒ
    elif len(groups) > 2 and "æ–¹å·®åˆ†æ" in stat_methods:
        for var in analysis_vars:
            if var in df.columns:
                group_data = [df[df[group_var] == group][var].dropna() for group in groups]
                
                try:
                    f_stat, p_value = stats.f_oneway(*group_data)
                    
                    var_results = {
                        'variable': var,
                        'f_statistic': f_stat,
                        'anova_p_value': p_value,
                        'anova_significant': p_value < (1 - confidence_level),
                        'groups': list(groups)
                    }
                    
                    comparison_results[var] = var_results
                    
                except:
                    comparison_results[var] = {'error': 'æ— æ³•æ‰§è¡Œæ–¹å·®åˆ†æ'}
    
    return comparison_results

def perform_correlation_analysis(df, analysis_vars):
    """æ‰§è¡Œç›¸å…³åˆ†æ"""
    
    correlation_results = {}
    
    # é€‰æ‹©æ•°å€¼å˜é‡
    numeric_vars = [var for var in analysis_vars if var in df.columns and df[var].dtype in ['int64', 'float64']]
    
    if len(numeric_vars) < 2:
        return correlation_results
    
    # è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µ
    correlation_matrix = df[numeric_vars].corr()
    
    correlation_results['correlation_matrix'] = correlation_matrix
    
    # æ˜¾è‘—æ€§æ£€éªŒ
    from scipy.stats import pearsonr
    
    correlation_tests = []
    
    for i, var1 in enumerate(numeric_vars):
        for j, var2 in enumerate(numeric_vars):
            if i < j:  # é¿å…é‡å¤
                try:
                    data1 = df[var1].dropna()
                    data2 = df[var2].dropna()
                    
                    # æ‰¾åˆ°ä¸¤ä¸ªå˜é‡éƒ½æœ‰å€¼çš„è§‚æµ‹
                    common_idx = data1.index.intersection(data2.index)
                    
                    if len(common_idx) > 2:
                        corr_coef, p_value = pearsonr(data1[common_idx], data2[common_idx])
                        
                        correlation_tests.append({
                            'variable1': var1,
                            'variable2': var2,
                            'correlation': corr_coef,
                            'p_value': p_value,
                            'n': len(common_idx),
                            'significant': p_value < 0.05
                        })
                except:
                    pass
    
    correlation_results['correlation_tests'] = pd.DataFrame(correlation_tests)
    
    return correlation_results

def display_statistical_report(report_content, include_plots, include_tables, 
                             report_title, report_format):
    """æ˜¾ç¤ºç»Ÿè®¡åˆ†ææŠ¥å‘Š"""
    
    st.markdown(f"### ğŸ“Š {report_title}")
    st.markdown(f"**ç”Ÿæˆæ—¶é—´**: {report_content['basic_info']['analysis_date']}")
    st.markdown(f"**æ ·æœ¬é‡**: {report_content['basic_info']['total_subjects']}")
    st.markdown(f"**ç½®ä¿¡æ°´å¹³**: {report_content['basic_info']['confidence_level']:.0%}")
    
    st.markdown("---")
    
    # æè¿°æ€§ç»Ÿè®¡
    if 'descriptive_stats' in report_content:
        st.markdown("#### ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡")
        
        if include_tables and 'overall' in report_content['descriptive_stats']:
            st.markdown("##### æ€»ä½“ç»Ÿè®¡")
            
            desc_df = report_content['descriptive_stats']['overall']
            
            # æ ¼å¼åŒ–æ•°å€¼
            formatted_desc = desc_df.copy()
            numeric_cols = ['mean', 'std', 'min', 'q25', 'median', 'q75', 'max']
            
            for col in numeric_cols:
                if col in formatted_desc.columns:
                    formatted_desc[col] = formatted_desc[col].round(2)
            
            st.dataframe(formatted_desc, hide_index=True)
        
        # åˆ†ç»„ç»Ÿè®¡
        if 'by_group' in report_content['descriptive_stats']:
            st.markdown("##### åˆ†ç»„ç»Ÿè®¡")
            
            for group, group_df in report_content['descriptive_stats']['by_group'].items():
                st.markdown(f"**{group}ç»„**")
                
                formatted_group = group_df.copy()
                numeric_cols = ['mean', 'std', 'median']
                
                for col in numeric_cols:
                    if col in formatted_group.columns:
                        formatted_group[col] = formatted_group[col].round(2)
                
                st.dataframe(formatted_group[['variable', 'n', 'mean', 'std', 'median']], hide_index=True)
    
    # ç»„é—´æ¯”è¾ƒ
    if 'group_comparison' in report_content and report_content['group_comparison']:
        st.markdown("#### ğŸ” ç»„é—´æ¯”è¾ƒåˆ†æ")
        
        comparison_results = []
        
        for var, results in report_content['group_comparison'].items():
            result_row = {
                'å˜é‡': var,
                'ç»„1': results.get('group1', ''),
                'ç»„2': results.get('group2', ''),
                'å‡å€¼å·®': f"{results.get('mean_diff', 0):.3f}",
            }
            
            if 't_test_p_value' in results:
                result_row['tæ£€éªŒPå€¼'] = f"{results['t_test_p_value']:.4f}"
                result_row['tæ£€éªŒæ˜¾è‘—æ€§'] = "æ˜¯" if results.get('t_test_significant', False) else "å¦"
            
            if 'mannwhitney_p_value' in results:
                result_row['Mann-Whitney På€¼'] = f"{results['mannwhitney_p_value']:.4f}"
            
            comparison_results.append(result_row)
        
        if comparison_results:
            st.dataframe(pd.DataFrame(comparison_results), hide_index=True)
    
    # ç›¸å…³åˆ†æ
    if 'correlation_analysis' in report_content:
        st.markdown("#### ğŸ”— ç›¸å…³åˆ†æ")
        
        if 'correlation_matrix' in report_content['correlation_analysis']:
            corr_matrix = report_content['correlation_analysis']['correlation_matrix']
            
            if include_plots:
                fig = px.imshow(
                    corr_matrix,
                    text_auto=True,
                    aspect="auto",
                    title="å˜é‡ç›¸å…³ç³»æ•°çŸ©é˜µ",
                    color_continuous_scale='RdBu_r'
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
            
            if include_tables and 'correlation_tests' in report_content['correlation_analysis']:
                st.markdown("##### ç›¸å…³æ€§æ£€éªŒç»“æœ")
                
                corr_tests = report_content['correlation_analysis']['correlation_tests']
                if not corr_tests.empty:
                    formatted_corr = corr_tests.copy()
                    formatted_corr['correlation'] = formatted_corr['correlation'].round(3)
                    formatted_corr['p_value'] = formatted_corr['p_value'].round(4)
                    formatted_corr['significant'] = formatted_corr['significant'].map({True: 'æ˜¯', False: 'å¦'})
                    
                    st.dataframe(formatted_corr, hide_index=True)
    
    # ç”Ÿæˆå¯ä¸‹è½½çš„æŠ¥å‘Š
    st.markdown("---")
    st.markdown("### ğŸ’¾ ä¸‹è½½æŠ¥å‘Š")
    
    if st.button("ğŸ“¥ ç”Ÿæˆä¸‹è½½æ–‡ä»¶"):
        
        if report_format == "HTML":
            html_report = generate_html_report(report_content, report_title)
            st.download_button(
                label="ä¸‹è½½HTMLæŠ¥å‘Š",
                data=html_report,
                file_name=f"{report_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                mime="text/html"
            )
        
        elif report_format == "PDF":
            pdf_report = generate_pdf_report(report_content, report_title)
            st.download_button(
                label="ä¸‹è½½PDFæŠ¥å‘Š",
                data=pdf_report,
                file_name=f"{report_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf"
            )
        
        elif report_format == "Word":
            word_report = generate_word_report(report_content, report_title)
            st.download_button(
                label="ä¸‹è½½WordæŠ¥å‘Š",
                data=word_report,
                file_name=f"{report_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )

def generate_visualization_report(df):
    """ç”Ÿæˆæ•°æ®å¯è§†åŒ–æŠ¥å‘Š"""
    st.markdown("### ğŸ“ˆ æ•°æ®å¯è§†åŒ–æŠ¥å‘Š")
    
    # å¯è§†åŒ–é…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ¨ å›¾è¡¨é…ç½®")
        
        # é€‰æ‹©å˜é‡
        numeric_vars = [col for col in df.columns if df[col].dtype in ['int64', 'float64']]
        categorical_vars = [col for col in df.columns if df[col].dtype == 'object']
        
        chart_types = st.multiselect(
            "é€‰æ‹©å›¾è¡¨ç±»å‹",
            ["ç›´æ–¹å›¾", "ç®±çº¿å›¾", "æ•£ç‚¹å›¾", "ç›¸å…³çƒ­åŠ›å›¾", "åˆ†ç»„æŸ±çŠ¶å›¾", "æ—¶é—´åºåˆ—å›¾"],
            default=["ç›´æ–¹å›¾", "ç®±çº¿å›¾"]
        )
        
        color_scheme = st.selectbox(
            "é…è‰²æ–¹æ¡ˆ",
            ["é»˜è®¤", "è“è‰²ç³»", "çº¢è‰²ç³»", "ç»¿è‰²ç³»", "å½©è™¹è‰²"]
        )
    
    with col2:
        st.markdown("#### ğŸ“Š å›¾è¡¨é€‰é¡¹")
        
        show_statistics = st.checkbox("æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯", value=True)
        interactive_plots = st.checkbox("äº¤äº’å¼å›¾è¡¨", value=True)
        
        plot_size = st.selectbox(
            "å›¾è¡¨å°ºå¯¸",
            ["å°", "ä¸­", "å¤§"],
            index=1
        )
        
        export_format = st.selectbox(
            "å¯¼å‡ºæ ¼å¼",
            ["PNG", "SVG", "PDF", "HTML"]
        )
    
    if st.button("ğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š", type="primary"):
        
        # åˆ›å»ºå¯è§†åŒ–å†…å®¹
        create_visualization_charts(
            df, chart_types, numeric_vars, categorical_vars,
            color_scheme, show_statistics, interactive_plots, plot_size
        )

def create_visualization_charts(df, chart_types, numeric_vars, categorical_vars,
                              color_scheme, show_statistics, interactive_plots, plot_size):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    
    # è®¾ç½®å›¾è¡¨å°ºå¯¸
    size_map = {"å°": 300, "ä¸­": 400, "å¤§": 500}
    height = size_map[plot_size]
    
    # è®¾ç½®é…è‰²
    color_map = {
        "é»˜è®¤": px.colors.qualitative.Plotly,
        "è“è‰²ç³»": px.colors.sequential.Blues,
        "çº¢è‰²ç³»": px.colors.sequential.Reds,
        "ç»¿è‰²ç³»": px.colors.sequential.Greens,
        "å½©è™¹è‰²": px.colors.qualitative.Set1
    }
    colors = color_map[color_scheme]
    
    # ç›´æ–¹å›¾
    if "ç›´æ–¹å›¾" in chart_types and numeric_vars:
        st.markdown("#### ğŸ“Š æ•°å€¼å˜é‡åˆ†å¸ƒ")
        
        selected_vars = st.multiselect(
            "é€‰æ‹©è¦å±•ç¤ºçš„æ•°å€¼å˜é‡",
            numeric_vars,
            default=numeric_vars[:3]
        )
        
        for var in selected_vars:
            fig = px.histogram(
                df, x=var,
                title=f"{var} åˆ†å¸ƒå›¾",
                nbins=30,
                color_discrete_sequence=colors
            )
            
            if show_statistics:
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                mean_val = df[var].mean()
                std_val = df[var].std()
                
                fig.add_vline(
                    x=mean_val, 
                    line_dash="dash", 
                    line_color="red",
                    annotation_text=f"å‡å€¼: {mean_val:.2f}"
                )
            
            fig.update_layout(height=height)
            st.plotly_chart(fig, use_container_width=True)
    
    # ç®±çº¿å›¾
    if "ç®±çº¿å›¾" in chart_types and numeric_vars:
        st.markdown("#### ğŸ“¦ ç®±çº¿å›¾åˆ†æ")
        
        if categorical_vars:
            group_var = st.selectbox(
                "é€‰æ‹©åˆ†ç»„å˜é‡ï¼ˆç®±çº¿å›¾ï¼‰",
                categorical_vars,
                key="boxplot_group"
            )
            
            selected_numeric = st.selectbox(
                "é€‰æ‹©æ•°å€¼å˜é‡ï¼ˆç®±çº¿å›¾ï¼‰",
                numeric_vars,
                key="boxplot_numeric"
            )
            
            fig = px.box(
                df, x=group_var, y=selected_numeric,
                title=f"{selected_numeric} æŒ‰ {group_var} åˆ†ç»„çš„ç®±çº¿å›¾",
                color_discrete_sequence=colors
            )
            
            fig.update_layout(height=height)
            st.plotly_chart(fig, use_container_width=True)
        else:
            # å•å˜é‡ç®±çº¿å›¾
            selected_var = st.selectbox(
                "é€‰æ‹©å˜é‡ï¼ˆå•å˜é‡ç®±çº¿å›¾ï¼‰",
                numeric_vars,
                key="single_boxplot"
            )
            
            fig = px.box(
                df, y=selected_var,
                title=f"{selected_var} ç®±çº¿å›¾"
            )
            
            fig.update_layout(height=height)
            st.plotly_chart(fig, use_container_width=True)
    
    # æ•£ç‚¹å›¾
    if "æ•£ç‚¹å›¾" in chart_types and len(numeric_vars) >= 2:
        st.markdown("#### ğŸ” æ•£ç‚¹å›¾åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            x_var = st.selectbox(
                "Xè½´å˜é‡",
                numeric_vars,
                key="scatter_x"
            )
        
        with col2:
            y_var = st.selectbox(
                "Yè½´å˜é‡",
                [var for var in numeric_vars if var != x_var],
                key="scatter_y"
            )
        
        # å¯é€‰çš„é¢œè‰²åˆ†ç»„
        color_var = None
        if categorical_vars:
            color_var = st.selectbox(
                "é¢œè‰²åˆ†ç»„å˜é‡ï¼ˆå¯é€‰ï¼‰",
                ["æ— "] + categorical_vars,
                key="scatter_color"
            )
            if color_var == "æ— ":
                color_var = None
        
        fig = px.scatter(
            df, x=x_var, y=y_var, color=color_var,
            title=f"{y_var} vs {x_var}",
            trendline="ols" if show_statistics else None,
            color_discrete_sequence=colors
        )
        
        fig.update_layout(height=height)
        st.plotly_chart(fig, use_container_width=True)
        
        # æ˜¾ç¤ºç›¸å…³ç³»æ•°
        if show_statistics:
            correlation = df[x_var].corr(df[y_var])
            st.info(f"**ç›¸å…³ç³»æ•°**: {correlation:.3f}")
    
    # ç›¸å…³çƒ­åŠ›å›¾
    if "ç›¸å…³çƒ­åŠ›å›¾" in chart_types and len(numeric_vars) >= 2:
        st.markdown("#### ğŸ”¥ ç›¸å…³æ€§çƒ­åŠ›å›¾")
        
        correlation_matrix = df[numeric_vars].corr()
        
        fig = px.imshow(
            correlation_matrix,
            text_auto=True,
            aspect="auto",
            title="å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾",
            color_continuous_scale='RdBu_r'
        )
        
        fig.update_layout(height=height)
        st.plotly_chart(fig, use_container_width=True)
    
    # åˆ†ç»„æŸ±çŠ¶å›¾
    if "åˆ†ç»„æŸ±çŠ¶å›¾" in chart_types and categorical_vars and numeric_vars:
        st.markdown("#### ğŸ“Š åˆ†ç»„æŸ±çŠ¶å›¾")
        
        col1, col2 = st.columns(2)
        
        with col1:
            cat_var = st.selectbox(
                "åˆ†ç±»å˜é‡",
                categorical_vars,
                key="bar_cat"
            )
        
        with col2:
            num_var = st.selectbox(
                "æ•°å€¼å˜é‡",
                numeric_vars,
                key="bar_num"
            )
        
        # è®¡ç®—åˆ†ç»„ç»Ÿè®¡
        group_stats = df.groupby(cat_var)[num_var].agg(['mean', 'std', 'count']).reset_index()
        
        fig = px.bar(
            group_stats, x=cat_var, y='mean',
            title=f"{num_var} æŒ‰ {cat_var} åˆ†ç»„çš„å‡å€¼",
            error_y='std' if show_statistics else None,
            color_discrete_sequence=colors
        )
        
        fig.update_layout(height=height)
        st.plotly_chart(fig, use_container_width=True)
        
        # æ˜¾ç¤ºç»Ÿè®¡è¡¨
        if show_statistics:
            st.dataframe(group_stats, hide_index=True)
    
    # æ—¶é—´åºåˆ—å›¾
    if "æ—¶é—´åºåˆ—å›¾" in chart_types:
        st.markdown("#### ğŸ“ˆ æ—¶é—´åºåˆ—åˆ†æ")
        
        # æŸ¥æ‰¾æ—¥æœŸåˆ—
        date_cols = [col for col in df.columns if df[col].dtype == 'datetime64[ns]' or 'date' in col.lower()]
        
        if date_cols:
            date_var = st.selectbox(
                "æ—¶é—´å˜é‡",
                date_cols,
                key="time_var"
            )
            
            num_var = st.selectbox(
                "æ•°å€¼å˜é‡",
                numeric_vars,
                key="time_num"
            )
            
            # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
            if df[date_var].dtype != 'datetime64[ns]':
                try:
                    df[date_var] = pd.to_datetime(df[date_var])
                except:
                    st.error("æ— æ³•è§£ææ—¥æœŸæ ¼å¼")
                    return
            
            fig = px.line(
                df.sort_values(date_var), 
                x=date_var, y=num_var,
                title=f"{num_var} æ—¶é—´è¶‹åŠ¿",
                color_discrete_sequence=colors
            )
            
            fig.update_layout(height=height)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æœªæ‰¾åˆ°æ—¥æœŸç±»å‹çš„åˆ—ï¼Œæ— æ³•ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾")

def generate_quality_report(df):
    """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""
    st.markdown("### ğŸ” æ•°æ®è´¨é‡æŠ¥å‘Š")
    
    # æ•°æ®è´¨é‡æ¦‚è§ˆ
    st.markdown("#### ğŸ“Š æ•°æ®è´¨é‡æ¦‚è§ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ€»è¡Œæ•°", len(df))
    
    with col2:
        st.metric("æ€»åˆ—æ•°", len(df.columns))
    
    with col3:
        missing_count = df.isnull().sum().sum()
        st.metric("ç¼ºå¤±å€¼æ€»æ•°", missing_count)
    
    with col4:
        duplicate_count = df.duplicated().sum()
        st.metric("é‡å¤è¡Œæ•°", duplicate_count)
    
    # ç¼ºå¤±å€¼åˆ†æ
    st.markdown("#### âŒ ç¼ºå¤±å€¼åˆ†æ")
    
    missing_analysis = []
    
    for col in df.columns:
        missing_count = df[col].isnull().sum()
        missing_percent = (missing_count / len(df)) * 100
        
        missing_analysis.append({
            'åˆ—å': col,
            'æ•°æ®ç±»å‹': str(df[col].dtype),
            'ç¼ºå¤±æ•°é‡': missing_count,
            'ç¼ºå¤±æ¯”ä¾‹': f"{missing_percent:.2f}%",
            'å®Œæ•´æ€§': f"{100-missing_percent:.2f}%"
        })
    
    missing_df = pd.DataFrame(missing_analysis)
    missing_df = missing_df.sort_values('ç¼ºå¤±æ•°é‡', ascending=False)
    
    st.dataframe(missing_df, hide_index=True)
    
    # ç¼ºå¤±å€¼å¯è§†åŒ–
    if missing_df['ç¼ºå¤±æ•°é‡'].sum() > 0:
        fig = px.bar(
            missing_df.head(10), 
            x='åˆ—å', y='ç¼ºå¤±æ•°é‡',
            title="å„åˆ—ç¼ºå¤±å€¼æ•°é‡ï¼ˆå‰10åˆ—ï¼‰",
            color='ç¼ºå¤±æ•°é‡',
            color_continuous_scale='Reds'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # æ•°æ®ç±»å‹åˆ†æ
    st.markdown("#### ğŸ·ï¸ æ•°æ®ç±»å‹åˆ†æ")
    
    dtype_analysis = df.dtypes.value_counts().reset_index()
    dtype_analysis.columns = ['æ•°æ®ç±»å‹', 'åˆ—æ•°']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.dataframe(dtype_analysis, hide_index=True)
    
    with col2:
        fig = px.pie(
            dtype_analysis, 
            values='åˆ—æ•°', names='æ•°æ®ç±»å‹',
            title="æ•°æ®ç±»å‹åˆ†å¸ƒ"
        )
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    # æ•°å€¼å˜é‡ç»Ÿè®¡
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    if len(numeric_cols) > 0:
        st.markdown("#### ğŸ“ˆ æ•°å€¼å˜é‡ç»Ÿè®¡")
        
        numeric_stats = []
        
        for col in numeric_cols:
            stats = {
                'å˜é‡å': col,
                'å‡å€¼': df[col].mean(),
                'æ ‡å‡†å·®': df[col].std(),
                'æœ€å°å€¼': df[col].min(),
                'æœ€å¤§å€¼': df[col].max(),
                'é›¶å€¼æ•°': (df[col] == 0).sum(),
                'è´Ÿå€¼æ•°': (df[col] < 0).sum(),
                'å¼‚å¸¸å€¼æ•°': detect_outliers(df[col])
            }
            numeric_stats.append(stats)
        
        numeric_df = pd.DataFrame(numeric_stats)
        
        # æ ¼å¼åŒ–æ•°å€¼
        for col in ['å‡å€¼', 'æ ‡å‡†å·®', 'æœ€å°å€¼', 'æœ€å¤§å€¼']:
            numeric_df[col] = numeric_df[col].round(3)
        
        st.dataframe(numeric_df, hide_index=True)
    
    # åˆ†ç±»å˜é‡åˆ†æ
    categorical_cols = df.select_dtypes(include=['object']).columns
    
    if len(categorical_cols) > 0:
        st.markdown("#### ğŸ·ï¸ åˆ†ç±»å˜é‡åˆ†æ")
        
        categorical_stats = []
        
        for col in categorical_cols:
            unique_count = df[col].nunique()
            most_frequent = df[col].mode().iloc[0] if not df[col].mode().empty else "N/A"
            most_frequent_count = df[col].value_counts().iloc[0] if not df[col].value_counts().empty else 0
            
            stats = {
                'å˜é‡å': col,
                'å”¯ä¸€å€¼æ•°': unique_count,
                'æœ€é¢‘ç¹å€¼': most_frequent,
                'æœ€é¢‘ç¹å€¼æ•°é‡': most_frequent_count,
                'æœ€é¢‘ç¹å€¼æ¯”ä¾‹': f"{(most_frequent_count/len(df))*100:.2f}%"
            }
            categorical_stats.append(stats)
        
        categorical_df = pd.DataFrame(categorical_stats)
        st.dataframe(categorical_df, hide_index=True)
    
    # æ•°æ®è´¨é‡è¯„åˆ†
    st.markdown("#### â­ æ•°æ®è´¨é‡è¯„åˆ†")
    
    quality_score = calculate_quality_score(df)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("å®Œæ•´æ€§è¯„åˆ†", f"{quality_score['completeness']:.1f}/100")
    
    with col2:
        st.metric("ä¸€è‡´æ€§è¯„åˆ†", f"{quality_score['consistency']:.1f}/100")
    
    with col3:
        st.metric("æ€»ä½“è´¨é‡è¯„åˆ†", f"{quality_score['overall']:.1f}/100")
    
    # è´¨é‡æ”¹è¿›å»ºè®®
    st.markdown("#### ğŸ’¡ è´¨é‡æ”¹è¿›å»ºè®®")
    
    suggestions = generate_quality_suggestions(df, missing_df, quality_score)
    
    for suggestion in suggestions:
        st.info(f"â€¢ {suggestion}")

def detect_outliers(series, method='iqr'):
    """æ£€æµ‹å¼‚å¸¸å€¼"""
    
    if method == 'iqr':
        Q1 = series.quantile(0.25)
        Q3 = series.quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = series[(series < lower_bound) | (series > upper_bound)]
        return len(outliers)
    
    return 0

def calculate_quality_score(df):
    """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
    
    # å®Œæ•´æ€§è¯„åˆ†ï¼ˆåŸºäºç¼ºå¤±å€¼æ¯”ä¾‹ï¼‰
    total_cells = len(df) * len(df.columns)
    missing_cells = df.isnull().sum().sum()
    completeness = ((total_cells - missing_cells) / total_cells) * 100
    
    # ä¸€è‡´æ€§è¯„åˆ†ï¼ˆåŸºäºæ•°æ®ç±»å‹ä¸€è‡´æ€§å’Œé‡å¤å€¼ï¼‰
    duplicate_ratio = df.duplicated().sum() / len(df)
    consistency = (1 - duplicate_ratio) * 100
    
    # æ€»ä½“è¯„åˆ†
    overall = (completeness + consistency) / 2
    
    return {
        'completeness': completeness,
        'consistency': consistency,
        'overall': overall
    }

def generate_quality_suggestions(df, missing_df, quality_score):
    """ç”Ÿæˆæ•°æ®è´¨é‡æ”¹è¿›å»ºè®®"""
    
    suggestions = []
    
    # ç¼ºå¤±å€¼å»ºè®®
    high_missing_cols = missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > len(df) * 0.1]['åˆ—å'].tolist()
    if high_missing_cols:
        suggestions.append(f"ä»¥ä¸‹åˆ—ç¼ºå¤±å€¼è¾ƒå¤šï¼ˆ>10%ï¼‰ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®æ”¶é›†è¿‡ç¨‹: {', '.join(high_missing_cols)}")
    
    # é‡å¤å€¼å»ºè®®
    if df.duplicated().sum() > 0:
        suggestions.append(f"å‘ç° {df.duplicated().sum()} è¡Œé‡å¤æ•°æ®ï¼Œå»ºè®®è¿›è¡Œå»é‡å¤„ç†")
    
    # æ•°æ®ç±»å‹å»ºè®®
    object_cols = df.select_dtypes(include=['object']).columns
    for col in object_cols:
        if df[col].str.isnumeric().all():
            suggestions.append(f"åˆ— '{col}' å¯èƒ½åº”è¯¥è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
    
    # å¼‚å¸¸å€¼å»ºè®®
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        outlier_count = detect_outliers(df[col])
        if outlier_count > len(df) * 0.05:  # è¶…è¿‡5%çš„å¼‚å¸¸å€¼
            suggestions.append(f"åˆ— '{col}' å­˜åœ¨è¾ƒå¤šå¼‚å¸¸å€¼ï¼ˆ{outlier_count}ä¸ªï¼‰ï¼Œå»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥")
    
    # æ€»ä½“è´¨é‡å»ºè®®
    if quality_score['overall'] < 80:
        suggestions.append("æ•°æ®æ•´ä½“è´¨é‡åä½ï¼Œå»ºè®®è¿›è¡Œå…¨é¢çš„æ•°æ®æ¸…æ´—å’ŒéªŒè¯")
    elif quality_score['overall'] < 90:
        suggestions.append("æ•°æ®è´¨é‡è‰¯å¥½ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
    else:
        suggestions.append("æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥è¿›è¡Œåç»­åˆ†æ")
    
    return suggestions

def generate_summary_report(df):
    """ç”Ÿæˆç ”ç©¶æ€»ç»“æŠ¥å‘Š"""
    st.markdown("### ğŸ“‹ ç ”ç©¶æ€»ç»“æŠ¥å‘Š")
    
    # æŠ¥å‘Šé…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### âš™ï¸ æŠ¥å‘Šé…ç½®")
        
        study_title = st.text_input(
            "ç ”ç©¶æ ‡é¢˜",
            value="ä¸´åºŠç ”ç©¶æ•°æ®åˆ†ææŠ¥å‘Š"
        )
        
        study_period = st.date_input(
            "ç ”ç©¶æœŸé—´",
            value=[datetime.now().date() - timedelta(days=365), datetime.now().date()]
        )
        
        primary_endpoint = st.text_input(
            "ä¸»è¦ç»ˆç‚¹",
            value="ä¸»è¦ç–—æ•ˆæŒ‡æ ‡"
        )
        
        secondary_endpoints = st.text_area(
            "æ¬¡è¦ç»ˆç‚¹",
            value="å®‰å…¨æ€§æŒ‡æ ‡\nç”Ÿæ´»è´¨é‡è¯„åˆ†\næ‚£è€…æ»¡æ„åº¦"
        )
    
    with col2:
        st.markdown("#### ğŸ“Š åˆ†æé€‰é¡¹")
        
        include_demographics = st.checkbox("åŒ…å«äººå£å­¦ç‰¹å¾", value=True)
        include_efficacy = st.checkbox("åŒ…å«ç–—æ•ˆåˆ†æ", value=True)
        include_safety = st.checkbox("åŒ…å«å®‰å…¨æ€§åˆ†æ", value=True)
        include_subgroup = st.checkbox("åŒ…å«äºšç»„åˆ†æ", value=False)
        
        report_language = st.selectbox(
            "æŠ¥å‘Šè¯­è¨€",
            ["ä¸­æ–‡", "è‹±æ–‡"]
        )
        
        report_template = st.selectbox(
            "æŠ¥å‘Šæ¨¡æ¿",
            ["æ ‡å‡†æ¨¡æ¿", "ç®€åŒ–æ¨¡æ¿", "è¯¦ç»†æ¨¡æ¿", "è‡ªå®šä¹‰æ¨¡æ¿"]
        )
    
    if st.button("ğŸ“‹ ç”Ÿæˆç ”ç©¶æ€»ç»“æŠ¥å‘Š", type="primary"):
        
        # åˆ›å»ºæŠ¥å‘Šå†…å®¹
        summary_content = create_summary_content(
            df, study_title, study_period, primary_endpoint, 
            secondary_endpoints, include_demographics, include_efficacy,
            include_safety, include_subgroup
        )
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        display_summary_report(summary_content, report_language, report_template)

def create_summary_content(df, study_title, study_period, primary_endpoint,
                         secondary_endpoints, include_demographics, include_efficacy,
                         include_safety, include_subgroup):
    """åˆ›å»ºç ”ç©¶æ€»ç»“å†…å®¹"""
    
    content = {
        'title': study_title,
        'period': study_period,
        'primary_endpoint': primary_endpoint,
        'secondary_endpoints': secondary_endpoints.split('\n'),
        'basic_info': {
            'total_subjects': len(df),
            'analysis_date': datetime.now().strftime('%Y-%m-%d')
        }
    }
    
    # äººå£å­¦ç‰¹å¾
    if include_demographics:
        content['demographics'] = analyze_demographics(df)
    
    # ç–—æ•ˆåˆ†æ
    if include_efficacy:
        content['efficacy'] = analyze_efficacy(df, primary_endpoint)
    
    # å®‰å…¨æ€§åˆ†æ
    if include_safety:
        content['safety'] = analyze_safety(df)
    
    # äºšç»„åˆ†æ
    if include_subgroup:
        content['subgroup'] = analyze_subgroups(df)
    
    return content

def analyze_demographics(df):
    """åˆ†æäººå£å­¦ç‰¹å¾"""
    
    demographics = {}
    
    # å¹´é¾„åˆ†æ
    if 'age' in df.columns:
        demographics['age'] = {
            'mean': df['age'].mean(),
            'std': df['age'].std(),
            'median': df['age'].median(),
            'range': [df['age'].min(), df['age'].max()]
        }
    
    # æ€§åˆ«åˆ†æ
    if 'gender' in df.columns:
        gender_counts = df['gender'].value_counts()
        demographics['gender'] = {
            'counts': gender_counts.to_dict(),
            'percentages': (gender_counts / len(df) * 100).to_dict()
        }
    
    # åˆ†ç»„åˆ†æ
    if 'group' in df.columns:
        group_counts = df['group'].value_counts()
        demographics['group'] = {
            'counts': group_counts.to_dict(),
            'percentages': (group_counts / len(df) * 100).to_dict()
        }
    
    return demographics

def analyze_efficacy(df, primary_endpoint):
    """åˆ†æç–—æ•ˆ"""
    
    efficacy = {}
    
    # æŸ¥æ‰¾å¯èƒ½çš„ç–—æ•ˆæŒ‡æ ‡
    efficacy_cols = [col for col in df.columns if any(keyword in col.lower() 
                    for keyword in ['change', 'improvement', 'response', 'endpoint'])]
    
    if efficacy_cols:
        for col in efficacy_cols:
            if df[col].dtype in ['int64', 'float64']:
                efficacy[col] = {
                    'mean': df[col].mean(),
                    'std': df[col].std(),
                    'median': df[col].median()
                }
                
                # åˆ†ç»„æ¯”è¾ƒ
                if 'group' in df.columns:
                    group_analysis = df.groupby('group')[col].agg(['mean', 'std', 'count'])
                    efficacy[col]['by_group'] = group_analysis.to_dict()
    
    return efficacy

def analyze_safety(df):
    """åˆ†æå®‰å…¨æ€§"""
    
    safety = {}
    
    # ä¸è‰¯äº‹ä»¶åˆ†æ
    if 'adverse_event' in df.columns:
        ae_rate = df['adverse_event'].mean()
        safety['adverse_event_rate'] = ae_rate
        
        if 'group' in df.columns:
            ae_by_group = df.groupby('group')['adverse_event'].mean()
            safety['ae_by_group'] = ae_by_group.to_dict()
    
    # å®éªŒå®¤æ£€æŸ¥å¼‚å¸¸
    lab_cols = [col for col in df.columns if any(keyword in col.lower() 
               for keyword in ['lab', 'test', 'level', 'count'])]
    
    if lab_cols:
        safety['lab_abnormalities'] = {}
        for col in lab_cols:
            if df[col].dtype in ['int64', 'float64']:
                # ç®€å•çš„å¼‚å¸¸æ£€æµ‹ï¼ˆè¶…å‡ºæ­£å¸¸èŒƒå›´ï¼‰
                outliers = detect_outliers(df[col])
                safety['lab_abnormalities'][col] = outliers
    
    return safety

def analyze_subgroups(df):
    """äºšç»„åˆ†æ"""
    
    subgroups = {}
    
    # åŸºäºå¹´é¾„çš„äºšç»„
    if 'age' in df.columns:
        df['age_group'] = pd.cut(df['age'], bins=[0, 40, 60, 100], labels=['é’å¹´', 'ä¸­å¹´', 'è€å¹´'])
        
        age_subgroup = {}
        for group in df['age_group'].unique():
            if pd.notna(group):
                subgroup_data = df[df['age_group'] == group]
                age_subgroup[group] = {
                    'count': len(subgroup_data),
                    'percentage': len(subgroup_data) / len(df) * 100
                }
        
        subgroups['age_groups'] = age_subgroup
    
    # åŸºäºæ€§åˆ«çš„äºšç»„
    if 'gender' in df.columns:
        gender_subgroup = {}
        for gender in df['gender'].unique():
            if pd.notna(gender):
                subgroup_data = df[df['gender'] == gender]
                gender_subgroup[gender] = {
                    'count': len(subgroup_data),
                    'percentage': len(subgroup_data) / len(df) * 100
                }
        
        subgroups['gender_groups'] = gender_subgroup
    
    return subgroups

def display_summary_report(content, language, template):
    """æ˜¾ç¤ºç ”ç©¶æ€»ç»“æŠ¥å‘Š"""
    
    st.markdown(f"# {content['title']}")
    st.markdown(f"**åˆ†ææ—¥æœŸ**: {content['basic_info']['analysis_date']}")
    st.markdown(f"**æ ·æœ¬é‡**: {content['basic_info']['total_subjects']}")
    
    if content['period']:
        st.markdown(f"**ç ”ç©¶æœŸé—´**: {content['period'][0]} è‡³ {content['period'][1]}")
    
    st.markdown("---")
    
    # ç ”ç©¶ç›®æ ‡
    st.markdown("## ğŸ¯ ç ”ç©¶ç›®æ ‡")
    st.markdown(f"**ä¸»è¦ç»ˆç‚¹**: {content['primary_endpoint']}")
    
    if content['secondary_endpoints']:
        st.markdown("**æ¬¡è¦ç»ˆç‚¹**:")
        for endpoint in content['secondary_endpoints']:
            if endpoint.strip():
                st.markdown(f"- {endpoint.strip()}")
    
    # äººå£å­¦ç‰¹å¾
    if 'demographics' in content:
        st.markdown("## ğŸ‘¥ å—è¯•è€…ç‰¹å¾")
        
        demo = content['demographics']
        
        if 'age' in demo:
            st.markdown("### å¹´é¾„åˆ†å¸ƒ")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("å¹³å‡å¹´é¾„", f"{demo['age']['mean']:.1f}å²")
            with col2:
                st.metric("å¹´é¾„ä¸­ä½æ•°", f"{demo['age']['median']:.1f}å²")
            with col3:
                st.metric("å¹´é¾„èŒƒå›´", f"{demo['age']['range'][0]:.0f}-{demo['age']['range'][1]:.0f}å²")
        
        if 'gender' in demo:
            st.markdown("### æ€§åˆ«åˆ†å¸ƒ")
            
            gender_data = []
            for gender, count in demo['gender']['counts'].items():
                percentage = demo['gender']['percentages'][gender]
                gender_data.append({
                    'æ€§åˆ«': gender,
                    'äººæ•°': count,
                    'æ¯”ä¾‹': f"{percentage:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(gender_data), hide_index=True)
        
        if 'group' in demo:
            st.markdown("### åˆ†ç»„åˆ†å¸ƒ")
            
            group_data = []
            for group, count in demo['group']['counts'].items():
                percentage = demo['group']['percentages'][group]
                group_data.append({
                    'åˆ†ç»„': group,
                    'äººæ•°': count,
                    'æ¯”ä¾‹': f"{percentage:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(group_data), hide_index=True)
    
    # ç–—æ•ˆåˆ†æ
    if 'efficacy' in content:
        st.markdown("## ğŸ“ˆ ç–—æ•ˆåˆ†æ")
        
        efficacy = content['efficacy']
        
        for endpoint, results in efficacy.items():
            st.markdown(f"### {endpoint}")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("å‡å€¼", f"{results['mean']:.3f}")
            with col2:
                st.metric("æ ‡å‡†å·®", f"{results['std']:.3f}")
            with col3:
                st.metric("ä¸­ä½æ•°", f"{results['median']:.3f}")
            
            # åˆ†ç»„æ¯”è¾ƒ
            if 'by_group' in results:
                st.markdown("#### åˆ†ç»„æ¯”è¾ƒ")
                
                group_data = []
                for group in results['by_group']['mean'].keys():
                    group_data.append({
                        'åˆ†ç»„': group,
                        'å‡å€¼': f"{results['by_group']['mean'][group]:.3f}",
                        'æ ‡å‡†å·®': f"{results['by_group']['std'][group]:.3f}",
                        'æ ·æœ¬é‡': results['by_group']['count'][group]
                    })
                
                st.dataframe(pd.DataFrame(group_data), hide_index=True)
    
    # å®‰å…¨æ€§åˆ†æ
    if 'safety' in content:
        st.markdown("## âš ï¸ å®‰å…¨æ€§åˆ†æ")
        
        safety = content['safety']
        
        if 'adverse_event_rate' in safety:
            st.markdown("### ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡")
            st.metric("æ€»ä½“ä¸è‰¯äº‹ä»¶ç‡", f"{safety['adverse_event_rate']:.1%}")
            
            if 'ae_by_group' in safety:
                ae_data = []
                for group, rate in safety['ae_by_group'].items():
                    ae_data.append({
                        'åˆ†ç»„': group,
                        'ä¸è‰¯äº‹ä»¶ç‡': f"{rate:.1%}"
                    })
                
                st.dataframe(pd.DataFrame(ae_data), hide_index=True)
        
        if 'lab_abnormalities' in safety:
            st.markdown("### å®éªŒå®¤æ£€æŸ¥å¼‚å¸¸")
            
            lab_data = []
            for lab, abnormal_count in safety['lab_abnormalities'].items():
                lab_data.append({
                    'æ£€æŸ¥é¡¹ç›®': lab,
                    'å¼‚å¸¸å€¼æ•°é‡': abnormal_count
                })
            
            if lab_data:
                st.dataframe(pd.DataFrame(lab_data), hide_index=True)
    
    # äºšç»„åˆ†æ
    if 'subgroup' in content:
        st.markdown("## ğŸ” äºšç»„åˆ†æ")
        
        subgroup = content['subgroup']
        
        if 'age_groups' in subgroup:
            st.markdown("### å¹´é¾„äºšç»„")
            
            age_data = []
            for group, stats in subgroup['age_groups'].items():
                age_data.append({
                    'å¹´é¾„ç»„': group,
                    'äººæ•°': stats['count'],
                    'æ¯”ä¾‹': f"{stats['percentage']:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(age_data), hide_index=True)
        
        if 'gender_groups' in subgroup:
            st.markdown("### æ€§åˆ«äºšç»„")
            
            gender_data = []
            for group, stats in subgroup['gender_groups'].items():
                gender_data.append({
                    'æ€§åˆ«': group,
                    'äººæ•°': stats['count'],
                    'æ¯”ä¾‹': f"{stats['percentage']:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(gender_data), hide_index=True)
    
    # ç»“è®º
    st.markdown("## ğŸ“ ç ”ç©¶ç»“è®º")
    
    conclusions = generate_conclusions(content)
    
    for conclusion in conclusions:
        st.success(f"âœ… {conclusion}")

def generate_conclusions(content):
    """ç”Ÿæˆç ”ç©¶ç»“è®º"""
    
    conclusions = []
    
    # åŸºæœ¬ä¿¡æ¯ç»“è®º
    conclusions.append(f"æœ¬ç ”ç©¶å…±çº³å…¥ {content['basic_info']['total_subjects']} åå—è¯•è€…")
    
    # äººå£å­¦ç»“è®º
    if 'demographics' in content:
        demo = content['demographics']
        
        if 'age' in demo:
            conclusions.append(f"å—è¯•è€…å¹³å‡å¹´é¾„ä¸º {demo['age']['mean']:.1f} å²")
        
        if 'gender' in demo:
            gender_dist = demo['gender']['percentages']
            main_gender = max(gender_dist.keys(), key=lambda x: gender_dist[x])
            conclusions.append(f"å—è¯•è€…ä»¥{main_gender}ä¸ºä¸»ï¼Œå  {gender_dist[main_gender]:.1f}%")
    
    # ç–—æ•ˆç»“è®º
    if 'efficacy' in content:
        efficacy = content['efficacy']
        
        for endpoint, results in efficacy.items():
            if 'by_group' in results:
                group_means = results['by_group']['mean']
                if len(group_means) >= 2:
                    groups = list(group_means.keys())
                    diff = abs(group_means[groups[0]] - group_means[groups[1]])
                    conclusions.append(f"{endpoint} åœ¨ä¸¤ç»„é—´å­˜åœ¨å·®å¼‚ï¼Œå·®å€¼ä¸º {diff:.3f}")
    
    # å®‰å…¨æ€§ç»“è®º
    if 'safety' in content:
        safety = content['safety']
        
        if 'adverse_event_rate' in safety:
            ae_rate = safety['adverse_event_rate']
            if ae_rate < 0.1:
                conclusions.append("ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡è¾ƒä½ï¼Œå®‰å…¨æ€§è‰¯å¥½")
            elif ae_rate < 0.2:
                conclusions.append("ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡åœ¨å¯æ¥å—èŒƒå›´å†…")
            else:
                conclusions.append("ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡è¾ƒé«˜ï¼Œéœ€è¦å…³æ³¨å®‰å…¨æ€§")
    
    return conclusions

def generate_safety_report(df):
    """ç”Ÿæˆå®‰å…¨æ€§æŠ¥å‘Š"""
    st.markdown("### âš ï¸ å®‰å…¨æ€§æŠ¥å‘Š")
    
    # å®‰å…¨æ€§æ•°æ®æ¦‚è§ˆ
    st.markdown("#### ğŸ“Š å®‰å…¨æ€§æ•°æ®æ¦‚è§ˆ")
    
    safety_cols = [col for col in df.columns if any(keyword in col.lower() 
                  for keyword in ['adverse', 'ae', 'safety', 'event', 'reaction'])]
    
    if not safety_cols:
        st.warning("æœªæ‰¾åˆ°å®‰å…¨æ€§ç›¸å…³æ•°æ®åˆ—ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º")
        # åˆ›å»ºæ¨¡æ‹Ÿå®‰å…¨æ€§æ•°æ®
        df = create_safety_demo_data(df)
        safety_cols = ['adverse_event', 'severity', 'causality']
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_subjects = len(df)
        st.metric("æ€»å—è¯•è€…æ•°", total_subjects)
    
    with col2:
        if 'adverse_event' in df.columns:
            ae_subjects = df['adverse_event'].sum() if df['adverse_event'].dtype in ['int64', 'bool'] else 0
            st.metric("å‘ç”ŸAEå—è¯•è€…æ•°", ae_subjects)
    
    with col3:
        if 'adverse_event' in df.columns:
            ae_rate = (ae_subjects / total_subjects) * 100 if total_subjects > 0 else 0
            st.metric("AEå‘ç”Ÿç‡", f"{ae_rate:.1f}%")
    
    with col4:
        if 'group' in df.columns and 'adverse_event' in df.columns:
            group_ae_rates = df.groupby('group')['adverse_event'].mean()
            max_diff = group_ae_rates.max() - group_ae_rates.min() if len(group_ae_rates) > 1 else 0
            st.metric("ç»„é—´AEç‡å·®å¼‚", f"{max_diff*100:.1f}%")
    
    # ä¸è‰¯äº‹ä»¶åˆ†ç±»åˆ†æ
    if 'adverse_event' in df.columns:
        st.markdown("#### ğŸ“‹ ä¸è‰¯äº‹ä»¶åˆ†æ")
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†æ
        if 'severity' in df.columns:
            st.markdown("##### æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»")
            
            severity_counts = df[df['adverse_event'] == 1]['severity'].value_counts()
            
            fig = px.pie(
                values=severity_counts.values,
                names=severity_counts.index,
                title="ä¸è‰¯äº‹ä»¶ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡è¡¨
            severity_data = []
            total_ae = severity_counts.sum()
            
            for severity, count in severity_counts.items():
                percentage = (count / total_ae) * 100 if total_ae > 0 else 0
                severity_data.append({
                    'ä¸¥é‡ç¨‹åº¦': severity,
                    'äº‹ä»¶æ•°': count,
                    'å æ¯”': f"{percentage:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(severity_data), hide_index=True)
        
        # æŒ‰å› æœå…³ç³»åˆ†æ
        if 'causality' in df.columns:
            st.markdown("##### æŒ‰å› æœå…³ç³»åˆ†ç±»")
            
            causality_counts = df[df['adverse_event'] == 1]['causality'].value_counts()
            
            fig = px.bar(
                x=causality_counts.index,
                y=causality_counts.values,
                title="ä¸è‰¯äº‹ä»¶å› æœå…³ç³»åˆ†å¸ƒ",
                labels={'x': 'å› æœå…³ç³»', 'y': 'äº‹ä»¶æ•°'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ
        if 'group' in df.columns:
            st.markdown("##### åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ")
            
            group_safety = df.groupby('group').agg({
                'adverse_event': ['sum', 'mean', 'count']
            }).round(3)
            
            group_safety.columns = ['AEæ€»æ•°', 'AEå‘ç”Ÿç‡', 'å—è¯•è€…æ•°']
            group_safety = group_safety.reset_index()
            
            st.dataframe(group_safety, hide_index=True)
            
            # å¯è§†åŒ–ç»„é—´æ¯”è¾ƒ
            fig = px.bar(
                group_safety,
                x='group',
                y='AEå‘ç”Ÿç‡',
                title="å„ç»„ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡æ¯”è¾ƒ",
                labels={'group': 'åˆ†ç»„', 'AEå‘ç”Ÿç‡': 'AEå‘ç”Ÿç‡'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # å®éªŒå®¤å®‰å…¨æ€§æŒ‡æ ‡
    lab_safety_cols = [col for col in df.columns if any(keyword in col.lower() 
                      for keyword in ['lab', 'test', 'level', 'count', 'alt', 'ast', 'creatinine'])]
    
    if lab_safety_cols:
        st.markdown("#### ğŸ§ª å®éªŒå®¤å®‰å…¨æ€§æŒ‡æ ‡")
        
        selected_lab_cols = st.multiselect(
            "é€‰æ‹©å®éªŒå®¤æŒ‡æ ‡",
            lab_safety_cols,
            default=lab_safety_cols[:3]
        )
        
        if selected_lab_cols:
            # å®éªŒå®¤æŒ‡æ ‡å¼‚å¸¸åˆ†æ
            lab_abnormal_data = []
            
            for col in selected_lab_cols:
                if df[col].dtype in ['int64', 'float64']:
                    # è®¡ç®—å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    
                    abnormal_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
                    abnormal_rate = (abnormal_count / len(df)) * 100
                    
                    lab_abnormal_data.append({
                        'æŒ‡æ ‡': col,
                        'å¼‚å¸¸ä¾‹æ•°': abnormal_count,
                        'å¼‚å¸¸ç‡': f"{abnormal_rate:.1f}%",
                        'å‡å€¼': f"{df[col].mean():.2f}",
                        'æ ‡å‡†å·®': f"{df[col].std():.2f}"
                    })
            
            if lab_abnormal_data:
                st.dataframe(pd.DataFrame(lab_abnormal_data), hide_index=True)
    
    # å®‰å…¨æ€§æ—¶é—´è¶‹åŠ¿åˆ†æ
    if 'visit_date' in df.columns and 'adverse_event' in df.columns:
        st.markdown("#### ğŸ“ˆ å®‰å…¨æ€§æ—¶é—´è¶‹åŠ¿")
        
        # æŒ‰æ—¶é—´ç»Ÿè®¡AEå‘ç”Ÿæƒ…å†µ
        df['visit_date'] = pd.to_datetime(df['visit_date'])
        df['month'] = df['visit_date'].dt.to_period('M')
        
        monthly_ae = df.groupby('month')['adverse_event'].agg(['sum', 'count', 'mean']).reset_index()
        monthly_ae['month_str'] = monthly_ae['month'].astype(str)
        
        fig = px.line(
            monthly_ae,
            x='month_str',
            y='mean',
            title="æœˆåº¦ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡è¶‹åŠ¿",
            labels={'month_str': 'æœˆä»½', 'mean': 'AEå‘ç”Ÿç‡'}
        )
        fig.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)
    
    # å®‰å…¨æ€§æ€»ç»“å’Œå»ºè®®
    st.markdown("#### ğŸ“ å®‰å…¨æ€§è¯„ä¼°æ€»ç»“")
    
    safety_summary = generate_safety_summary(df)
    
    for summary_point in safety_summary:
        st.info(f"â€¢ {summary_point}")

def create_safety_demo_data(df):
    """åˆ›å»ºå®‰å…¨æ€§æ¼”ç¤ºæ•°æ®"""
    
    np.random.seed(42)
    n = len(df)
    
    # æ·»åŠ ä¸è‰¯äº‹ä»¶æ•°æ®
    df['adverse_event'] = np.random.binomial(1, 0.15, n)  # 15%çš„AEå‘ç”Ÿç‡
    
    # æ·»åŠ ä¸¥é‡ç¨‹åº¦
    severity_options = ['è½»åº¦', 'ä¸­åº¦', 'é‡åº¦']
    df['severity'] = np.random.choice(severity_options, n, p=[0.6, 0.3, 0.1])
    
    # æ·»åŠ å› æœå…³ç³»
    causality_options = ['è‚¯å®šç›¸å…³', 'å¾ˆå¯èƒ½ç›¸å…³', 'å¯èƒ½ç›¸å…³', 'å¯èƒ½æ— å…³', 'æ— å…³']
    df['causality'] = np.random.choice(causality_options, n, p=[0.1, 0.2, 0.3, 0.3, 0.1])
    
    return df

def generate_safety_summary(df):
    """ç”Ÿæˆå®‰å…¨æ€§æ€»ç»“"""
    
    summary_points = []
    
    if 'adverse_event' in df.columns:
        ae_rate = df['adverse_event'].mean()
        
        if ae_rate < 0.1:
            summary_points.append(f"ä¸è‰¯äº‹ä»¶æ€»å‘ç”Ÿç‡ä¸º {ae_rate:.1%}ï¼Œå¤„äºè¾ƒä½æ°´å¹³")
        elif ae_rate < 0.2:
            summary_points.append(f"ä¸è‰¯äº‹ä»¶æ€»å‘ç”Ÿç‡ä¸º {ae_rate:.1%}ï¼Œåœ¨å¯æ¥å—èŒƒå›´å†…")
        else:
            summary_points.append(f"ä¸è‰¯äº‹ä»¶æ€»å‘ç”Ÿç‡ä¸º {ae_rate:.1%}ï¼Œéœ€è¦å¯†åˆ‡å…³æ³¨")
        
        # åˆ†ç»„æ¯”è¾ƒ
        if 'group' in df.columns:
            group_ae_rates = df.groupby('group')['adverse_event'].mean()
            
            if len(group_ae_rates) >= 2:
                max_rate = group_ae_rates.max()
                min_rate = group_ae_rates.min()
                
                if (max_rate - min_rate) > 0.05:  # å·®å¼‚è¶…è¿‡5%
                    summary_points.append("å„ç»„é—´ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼Œå»ºè®®è¿›ä¸€æ­¥åˆ†æ")
                else:
                    summary_points.append("å„ç»„é—´ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡ç›¸è¿‘ï¼Œç»„é—´å®‰å…¨æ€§å¹³è¡¡è‰¯å¥½")
        
        # ä¸¥é‡ç¨‹åº¦åˆ†æ
        if 'severity' in df.columns:
            ae_data = df[df['adverse_event'] == 1]
            if len(ae_data) > 0:
                severe_rate = (ae_data['severity'] == 'é‡åº¦').mean()
                
                if severe_rate > 0.1:
                    summary_points.append(f"é‡åº¦ä¸è‰¯äº‹ä»¶å æ¯” {severe_rate:.1%}ï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨")
                else:
                    summary_points.append(f"é‡åº¦ä¸è‰¯äº‹ä»¶å æ¯” {severe_rate:.1%}ï¼Œå¤§å¤šæ•°ä¸ºè½»ä¸­åº¦äº‹ä»¶")
    
    # å®éªŒå®¤å®‰å…¨æ€§
    lab_cols = [col for col in df.columns if any(keyword in col.lower() 
               for keyword in ['lab', 'test', 'level'])]
    
    if lab_cols:
        abnormal_counts = []
        for col in lab_cols:
            if df[col].dtype in ['int64', 'float64']:
                abnormal_count = detect_outliers(df[col])
                abnormal_counts.append(abnormal_count)
        
        if abnormal_counts:
            avg_abnormal = np.mean(abnormal_counts)
            if avg_abnormal > len(df) * 0.1:  # è¶…è¿‡10%å¼‚å¸¸
                summary_points.append("å®éªŒå®¤æŒ‡æ ‡å¼‚å¸¸ç‡åé«˜ï¼Œå»ºè®®åŠ å¼ºç›‘æµ‹")
            else:
                summary_points.append("å®éªŒå®¤æŒ‡æ ‡å¤§å¤šåœ¨æ­£å¸¸èŒƒå›´å†…")
    
    # æ€»ä½“å®‰å…¨æ€§è¯„ä¼°
    if 'adverse_event' in df.columns:
        ae_rate = df['adverse_event'].mean()
        
        if ae_rate < 0.05:
            summary_points.append("æ€»ä½“å®‰å…¨æ€§è¯„ä¼°ï¼šä¼˜ç§€")
        elif ae_rate < 0.15:
            summary_points.append("æ€»ä½“å®‰å…¨æ€§è¯„ä¼°ï¼šè‰¯å¥½")
        elif ae_rate < 0.25:
            summary_points.append("æ€»ä½“å®‰å…¨æ€§è¯„ä¼°ï¼šå¯æ¥å—")
        else:
            summary_points.append("æ€»ä½“å®‰å…¨æ€§è¯„ä¼°ï¼šéœ€è¦å…³æ³¨")
    
    return summary_points

def generate_html_report(content, title):
    """ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š"""
    
    html_template = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>{title}</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; }}
            h1 {{ color: #2E86AB; border-bottom: 2px solid #2E86AB; }}
            h2 {{ color: #A23B72; }}
            h3 {{ color: #F18F01; }}
            table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
            th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            .metric {{ background-color: #f8f9fa; padding: 10px; margin: 10px 0; border-radius: 5px; }}
            .summary {{ background-color: #e8f5e8; padding: 15px; border-radius: 5px; margin: 20px 0; }}
        </style>
    </head>
    <body>
        <h1>{title}</h1>
        <div class="metric">
            <strong>ç”Ÿæˆæ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>
            <strong>æ€»æ ·æœ¬é‡:</strong> {content.get('basic_info', {}).get('total_subjects', 'N/A')}
        </div>
        
        <h2>æŠ¥å‘Šæ‘˜è¦</h2>
        <div class="summary">
            æœ¬æŠ¥å‘ŠåŸºäºä¸´åºŠç ”ç©¶æ•°æ®ç”Ÿæˆï¼ŒåŒ…å«äº†å®Œæ•´çš„ç»Ÿè®¡åˆ†æç»“æœå’Œæ•°æ®è´¨é‡è¯„ä¼°ã€‚
            æ‰€æœ‰åˆ†æå‡é‡‡ç”¨æ ‡å‡†ç»Ÿè®¡æ–¹æ³•ï¼Œç»“æœå…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ã€‚
        </div>
        
        <h2>ä¸»è¦å‘ç°</h2>
        <ul>
            <li>æ•°æ®è´¨é‡è‰¯å¥½ï¼Œç¼ºå¤±å€¼åœ¨å¯æ¥å—èŒƒå›´å†…</li>
            <li>ç»Ÿè®¡åˆ†æç»“æœæ˜¾ç¤ºç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚</li>
            <li>å®‰å…¨æ€§æŒ‡æ ‡åœ¨é¢„æœŸèŒƒå›´å†…</li>
        </ul>
        
        <h2>ç»“è®ºä¸å»ºè®®</h2>
        <p>åŸºäºæœ¬æ¬¡åˆ†æç»“æœï¼Œå»ºè®®ï¼š</p>
        <ol>
            <li>ç»§ç»­ç›‘æµ‹ä¸»è¦ç–—æ•ˆæŒ‡æ ‡</li>
            <li>åŠ å¼ºå®‰å…¨æ€§æ•°æ®æ”¶é›†</li>
            <li>è€ƒè™‘æ‰©å¤§æ ·æœ¬é‡ä»¥æé«˜ç»Ÿè®¡åŠŸæ•ˆ</li>
        </ol>
        
        <hr>
        <p><em>æœ¬æŠ¥å‘Šç”±ä¸´åºŠè¯•éªŒæ•°æ®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ</em></p>
    </body>
    </html>
    """
    
    return html_template

def generate_pdf_report(content, title):
    """ç”ŸæˆPDFæ ¼å¼æŠ¥å‘Š"""
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    buffer = io.BytesIO()
    
    # åˆ›å»ºPDFæ–‡æ¡£
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    styles = getSampleStyleSheet()
    story = []
    
    # æ ‡é¢˜
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        spaceAfter=30,
        alignment=TA_CENTER
    )
    story.append(Paragraph(title, title_style))
    story.append(Spacer(1, 12))
    
    # åŸºæœ¬ä¿¡æ¯
    info_data = [
        ['ç”Ÿæˆæ—¶é—´', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
        ['æ€»æ ·æœ¬é‡', str(content.get('basic_info', {}).get('total_subjects', 'N/A'))],
        ['åˆ†ææ—¥æœŸ', content.get('basic_info', {}).get('analysis_date', 'N/A')]
    ]
    
    info_table = Table(info_data)
    info_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 14),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(info_table)
    story.append(Spacer(1, 12))
    
    # æŠ¥å‘Šå†…å®¹
    story.append(Paragraph("æŠ¥å‘Šæ‘˜è¦", styles['Heading2']))
    story.append(Paragraph("æœ¬æŠ¥å‘ŠåŸºäºä¸´åºŠç ”ç©¶æ•°æ®ç”Ÿæˆï¼ŒåŒ…å«äº†å®Œæ•´çš„ç»Ÿè®¡åˆ†æç»“æœå’Œæ•°æ®è´¨é‡è¯„ä¼°ã€‚", styles['Normal']))
    story.append(Spacer(1, 12))
    
    story.append(Paragraph("ä¸»è¦å‘ç°", styles['Heading2']))
    findings = [
        "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œç¼ºå¤±å€¼åœ¨å¯æ¥å—èŒƒå›´å†…",
        "ç»Ÿè®¡åˆ†æç»“æœæ˜¾ç¤ºç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚", 
        "å®‰å…¨æ€§æŒ‡æ ‡åœ¨é¢„æœŸèŒƒå›´å†…"
    ]
    
    for finding in findings:
        story.append(Paragraph(f"â€¢ {finding}", styles['Normal']))
    
    story.append(Spacer(1, 12))
    
    story.append(Paragraph("ç»“è®ºä¸å»ºè®®", styles['Heading2']))
    recommendations = [
        "ç»§ç»­ç›‘æµ‹ä¸»è¦ç–—æ•ˆæŒ‡æ ‡",
        "åŠ å¼ºå®‰å…¨æ€§æ•°æ®æ”¶é›†",
        "è€ƒè™‘æ‰©å¤§æ ·æœ¬é‡ä»¥æé«˜ç»Ÿè®¡åŠŸæ•ˆ"
    ]
    
    for i, rec in enumerate(recommendations, 1):
        story.append(Paragraph(f"{i}. {rec}", styles['Normal']))
    
    # æ„å»ºPDF
    doc.build(story)
    
    # è·å–PDFæ•°æ®
    buffer.seek(0)
    pdf_data = buffer.getvalue()
    buffer.close()
    
    return pdf_data

def generate_word_report(content, title):
    """ç”ŸæˆWordæ ¼å¼æŠ¥å‘Š"""
    
    # åˆ›å»ºWordæ–‡æ¡£
    doc = Document()
    
    # è®¾ç½®æ ‡é¢˜
    doc_title = doc.add_heading(title, 0)
    doc_title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # åŸºæœ¬ä¿¡æ¯
    doc.add_heading('åŸºæœ¬ä¿¡æ¯', level=1)
    
    info_table = doc.add_table(rows=3, cols=2)
    info_table.style = 'Table Grid'
    
    info_cells = info_table.rows[0].cells
    info_cells[0].text = 'ç”Ÿæˆæ—¶é—´'
    info_cells[1].text = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    info_cells = info_table.rows[1].cells
    info_cells[0].text = 'æ€»æ ·æœ¬é‡'
    info_cells[1].text = str(content.get('basic_info', {}).get('total_subjects', 'N/A'))
    
    info_cells = info_table.rows[2].cells
    info_cells[0].text = 'åˆ†ææ—¥æœŸ'
    info_cells[1].text = content.get('basic_info', {}).get('analysis_date', 'N/A')
    
    # æŠ¥å‘Šæ‘˜è¦
    doc.add_heading('æŠ¥å‘Šæ‘˜è¦', level=1)
    doc.add_paragraph('æœ¬æŠ¥å‘ŠåŸºäºä¸´åºŠç ”ç©¶æ•°æ®ç”Ÿæˆï¼ŒåŒ…å«äº†å®Œæ•´çš„ç»Ÿè®¡åˆ†æç»“æœå’Œæ•°æ®è´¨é‡è¯„ä¼°ã€‚æ‰€æœ‰åˆ†æå‡é‡‡ç”¨æ ‡å‡†ç»Ÿè®¡æ–¹æ³•ï¼Œç»“æœå…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ã€‚')
    
    # ä¸»è¦å‘ç°
    doc.add_heading('ä¸»è¦å‘ç°', level=1)
    findings = [
        "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œç¼ºå¤±å€¼åœ¨å¯æ¥å—èŒƒå›´å†…",
        "ç»Ÿè®¡åˆ†æç»“æœæ˜¾ç¤ºç»„é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚",
        "å®‰å…¨æ€§æŒ‡æ ‡åœ¨é¢„æœŸèŒƒå›´å†…"
    ]
    
    for finding in findings:
        doc.add_paragraph(finding, style='List Bullet')
    
    # ç»“è®ºä¸å»ºè®®
    doc.add_heading('ç»“è®ºä¸å»ºè®®', level=1)
    doc.add_paragraph('åŸºäºæœ¬æ¬¡åˆ†æç»“æœï¼Œå»ºè®®ï¼š')
    
    recommendations = [
        "ç»§ç»­ç›‘æµ‹ä¸»è¦ç–—æ•ˆæŒ‡æ ‡",
        "åŠ å¼ºå®‰å…¨æ€§æ•°æ®æ”¶é›†", 
        "è€ƒè™‘æ‰©å¤§æ ·æœ¬é‡ä»¥æé«˜ç»Ÿè®¡åŠŸæ•ˆ"
    ]
    
    for rec in recommendations:
        doc.add_paragraph(rec, style='List Number')
    
    # ä¿å­˜åˆ°å†…å­˜
    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    
    return buffer.getvalue()

def generate_custom_report(df):
    """ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Š"""
    st.markdown("### ğŸ“Š è‡ªå®šä¹‰æŠ¥å‘Šç”Ÿæˆå™¨")
    
    # æŠ¥å‘Šæ„å»ºå™¨ç•Œé¢
    st.markdown("#### ğŸ”§ æŠ¥å‘Šæ„å»ºå™¨")
    
    # é€‰æ‹©æŠ¥å‘Šç»„ä»¶
    report_components = st.multiselect(
        "é€‰æ‹©æŠ¥å‘Šç»„ä»¶",
        [
            "ğŸ“Š æ•°æ®æ¦‚è§ˆ",
            "ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡", 
            "ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥",
            "ğŸ“‹ åˆ†ç»„æ¯”è¾ƒ",
            "ğŸ“Š å¯è§†åŒ–å›¾è¡¨",
            "âš ï¸ å¼‚å¸¸å€¼æ£€æµ‹",
            "ğŸ”— ç›¸å…³æ€§åˆ†æ",
            "ğŸ“ è‡ªå®šä¹‰æ–‡æœ¬"
        ],
        default=["ğŸ“Š æ•°æ®æ¦‚è§ˆ", "ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡"]
    )
    
    # æŠ¥å‘Šé…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        report_title = st.text_input("æŠ¥å‘Šæ ‡é¢˜", value="è‡ªå®šä¹‰æ•°æ®åˆ†ææŠ¥å‘Š")
        report_author = st.text_input("æŠ¥å‘Šä½œè€…", value="æ•°æ®åˆ†æå¸ˆ")
        
    with col2:
        report_format = st.selectbox("è¾“å‡ºæ ¼å¼", ["HTML", "PDF", "Word"])
        include_code = st.checkbox("åŒ…å«åˆ†æä»£ç ", value=False)
    
    # é«˜çº§é€‰é¡¹
    with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
        
        color_theme = st.selectbox(
            "å›¾è¡¨ä¸»é¢˜",
            ["é»˜è®¤", "å•†åŠ¡", "å­¦æœ¯", "å½©è‰²", "å•è‰²"]
        )
        
        significance_level = st.slider(
            "æ˜¾è‘—æ€§æ°´å¹³",
            0.01, 0.10, 0.05, 0.01
        )
        
        decimal_places = st.slider(
            "å°æ•°ä½æ•°",
            1, 5, 3, 1
        )
        
        custom_css = st.text_area(
            "è‡ªå®šä¹‰CSSæ ·å¼ï¼ˆå¯é€‰ï¼‰",
            placeholder="è¾“å…¥è‡ªå®šä¹‰CSSä»£ç ..."
        )
    
    if st.button("ğŸš€ ç”Ÿæˆè‡ªå®šä¹‰æŠ¥å‘Š", type="primary"):
        
        # åˆ›å»ºè‡ªå®šä¹‰æŠ¥å‘Š
        custom_report_content = create_custom_report_content(
            df, report_components, report_title, report_author,
            color_theme, significance_level, decimal_places
        )
        
        # æ˜¾ç¤ºæŠ¥å‘Šé¢„è§ˆ
        st.markdown("### ğŸ“„ æŠ¥å‘Šé¢„è§ˆ")
        display_custom_report(custom_report_content, include_code)
        
        # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
        if report_format == "HTML":
            html_content = generate_custom_html_report(
                custom_report_content, custom_css
            )
            st.download_button(
                "ğŸ“¥ ä¸‹è½½HTMLæŠ¥å‘Š",
                data=html_content,
                file_name=f"{report_title.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                mime="text/html"
            )

def create_custom_report_content(df, components, title, author, 
                               theme, significance_level, decimal_places):
    """åˆ›å»ºè‡ªå®šä¹‰æŠ¥å‘Šå†…å®¹"""
    
    content = {
        'title': title,
        'author': author,
        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'theme': theme,
        'significance_level': significance_level,
        'decimal_places': decimal_places,
        'components': {}
    }
    
    # æ ¹æ®é€‰æ‹©çš„ç»„ä»¶ç”Ÿæˆå†…å®¹
    for component in components:
        
        if "æ•°æ®æ¦‚è§ˆ" in component:
            content['components']['overview'] = {
                'total_rows': len(df),
                'total_columns': len(df.columns),
                'missing_values': df.isnull().sum().sum(),
                'duplicate_rows': df.duplicated().sum(),
                'memory_usage': df.memory_usage(deep=True).sum(),
                'column_types': df.dtypes.value_counts().to_dict()
            }
        
        if "æè¿°æ€§ç»Ÿè®¡" in component:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                desc_stats = df[numeric_cols].describe()
                content['components']['descriptive_stats'] = desc_stats.round(decimal_places)
        
        if "æ•°æ®è´¨é‡æ£€æŸ¥" in component:
            content['components']['quality_check'] = perform_quality_check(df)
        
        if "åˆ†ç»„æ¯”è¾ƒ" in component:
            categorical_cols = df.select_dtypes(include=['object']).columns
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            if len(categorical_cols) > 0 and len(numeric_cols) > 0:
                content['components']['group_comparison'] = perform_group_analysis(
                    df, categorical_cols[0], numeric_cols, significance_level
                )
        
        if "å¼‚å¸¸å€¼æ£€æµ‹" in component:
            content['components']['outlier_detection'] = detect_all_outliers(df)
        
        if "ç›¸å…³æ€§åˆ†æ" in component:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) >= 2:
                corr_matrix = df[numeric_cols].corr()
                content['components']['correlation'] = corr_matrix.round(decimal_places)
    
    return content

def perform_quality_check(df):
    """æ‰§è¡Œæ•°æ®è´¨é‡æ£€æŸ¥"""
    
    quality_issues = []
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    missing_cols = df.columns[df.isnull().any()].tolist()
    if missing_cols:
        quality_issues.append(f"å‘ç°ç¼ºå¤±å€¼çš„åˆ—: {', '.join(missing_cols)}")
    
    # æ£€æŸ¥é‡å¤è¡Œ
    if df.duplicated().any():
        quality_issues.append(f"å‘ç° {df.duplicated().sum()} è¡Œé‡å¤æ•°æ®")
    
    # æ£€æŸ¥æ•°æ®ç±»å‹ä¸ä¸€è‡´
    for col in df.columns:
        if df[col].dtype == 'object':
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ˜¯æ•°å€¼ç±»å‹
            try:
                pd.to_numeric(df[col], errors='raise')
                quality_issues.append(f"åˆ— '{col}' å¯èƒ½åº”è¯¥è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
            except:
                pass
    
    # æ£€æŸ¥å¼‚å¸¸å€¼
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        outlier_count = detect_outliers(df[col])
        if outlier_count > len(df) * 0.05:  # è¶…è¿‡5%çš„å¼‚å¸¸å€¼
            quality_issues.append(f"åˆ— '{col}' å­˜åœ¨è¾ƒå¤šå¼‚å¸¸å€¼ ({outlier_count}ä¸ª)")
    
    return {
        'issues': quality_issues,
        'score': calculate_quality_score(df),
        'recommendations': generate_quality_recommendations(quality_issues)
    }

def perform_group_analysis(df, group_col, numeric_cols, significance_level):
    """æ‰§è¡Œåˆ†ç»„åˆ†æ"""
    
    from scipy import stats
    
    group_results = {}
    
    for col in numeric_cols:
        groups = df.groupby(group_col)[col].apply(list)
        
        if len(groups) >= 2:
            # æ‰§è¡Œç»Ÿè®¡æ£€éªŒ
            if len(groups) == 2:
                # tæ£€éªŒ
                group_data = [df[df[group_col] == group][col].dropna() for group in groups.index]
                try:
                    t_stat, p_value = stats.ttest_ind(*group_data)
                    
                    group_results[col] = {
                        'test_type': 't-test',
                        'statistic': t_stat,
                        'p_value': p_value,
                        'significant': p_value < significance_level,
                        'group_means': df.groupby(group_col)[col].mean().to_dict()
                    }
                except:
                    group_results[col] = {'error': 'æ— æ³•æ‰§è¡Œtæ£€éªŒ'}
            
            else:
                # æ–¹å·®åˆ†æ
                group_data = [df[df[group_col] == group][col].dropna() for group in groups.index]
                try:
                    f_stat, p_value = stats.f_oneway(*group_data)
                    
                    group_results[col] = {
                        'test_type': 'ANOVA',
                        'statistic': f_stat,
                        'p_value': p_value,
                        'significant': p_value < significance_level,
                        'group_means': df.groupby(group_col)[col].mean().to_dict()
                    }
                except:
                    group_results[col] = {'error': 'æ— æ³•æ‰§è¡Œæ–¹å·®åˆ†æ'}
    
    return group_results

def detect_all_outliers(df):
    """æ£€æµ‹æ‰€æœ‰æ•°å€¼åˆ—çš„å¼‚å¸¸å€¼"""
    
    outlier_results = {}
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        # IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]
        
        outlier_results[col] = {
            'count': len(outliers),
            'percentage': len(outliers) / len(df) * 100,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound,
            'outlier_values': outliers.tolist()[:10]  # åªæ˜¾ç¤ºå‰10ä¸ªå¼‚å¸¸å€¼
        }
    
    return outlier_results

def generate_quality_recommendations(quality_issues):
    """ç”Ÿæˆæ•°æ®è´¨é‡æ”¹è¿›å»ºè®®"""
    
    recommendations = []
    
    for issue in quality_issues:
        if "ç¼ºå¤±å€¼" in issue:
            recommendations.append("è€ƒè™‘ä½¿ç”¨æ’å€¼ã€å‡å€¼å¡«å……æˆ–åˆ é™¤ç¼ºå¤±å€¼")
        elif "é‡å¤æ•°æ®" in issue:
            recommendations.append("ä½¿ç”¨drop_duplicates()æ–¹æ³•å»é™¤é‡å¤è¡Œ")
        elif "æ•°å€¼ç±»å‹" in issue:
            recommendations.append("ä½¿ç”¨pd.to_numeric()è½¬æ¢æ•°æ®ç±»å‹")
        elif "å¼‚å¸¸å€¼" in issue:
            recommendations.append("æ£€æŸ¥å¼‚å¸¸å€¼çš„åˆç†æ€§ï¼Œè€ƒè™‘æ˜¯å¦éœ€è¦å¤„ç†æˆ–åˆ é™¤")
    
    if not recommendations:
        recommendations.append("æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç‰¹æ®Šå¤„ç†")
    
    return recommendations

def display_custom_report(content, include_code):
    """æ˜¾ç¤ºè‡ªå®šä¹‰æŠ¥å‘Š"""
    
    st.markdown(f"# {content['title']}")
    st.markdown(f"**ä½œè€…**: {content['author']}")
    st.markdown(f"**ç”Ÿæˆæ—¶é—´**: {content['generated_at']}")
    st.markdown("---")
    
    # æ•°æ®æ¦‚è§ˆ
    if 'overview' in content['components']:
        st.markdown("## ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        
        overview = content['components']['overview']
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»è¡Œæ•°", overview['total_rows'])
        with col2:
            st.metric("æ€»åˆ—æ•°", overview['total_columns'])
        with col3:
            st.metric("ç¼ºå¤±å€¼", overview['missing_values'])
        with col4:
            st.metric("é‡å¤è¡Œ", overview['duplicate_rows'])
        
        # æ•°æ®ç±»å‹åˆ†å¸ƒ
        if overview['column_types']:
            st.markdown("### æ•°æ®ç±»å‹åˆ†å¸ƒ")
            
            type_df = pd.DataFrame(
                list(overview['column_types'].items()),
                columns=['æ•°æ®ç±»å‹', 'åˆ—æ•°']
            )
            
            fig = px.pie(
                type_df,
                values='åˆ—æ•°',
                names='æ•°æ®ç±»å‹',
                title="æ•°æ®ç±»å‹åˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # æè¿°æ€§ç»Ÿè®¡
    if 'descriptive_stats' in content['components']:
        st.markdown("## ğŸ“ˆ æè¿°æ€§ç»Ÿè®¡")
        
        desc_stats = content['components']['descriptive_stats']
        st.dataframe(desc_stats)
        
        if include_code:
            st.code("""
# æè¿°æ€§ç»Ÿè®¡ä»£ç 
df.describe()
            """, language='python')
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    if 'quality_check' in content['components']:
        st.markdown("## ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")
        
        quality = content['components']['quality_check']
        
        # è´¨é‡è¯„åˆ†
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å®Œæ•´æ€§è¯„åˆ†", f"{quality['score']['completeness']:.1f}/100")
        with col2:
            st.metric("ä¸€è‡´æ€§è¯„åˆ†", f"{quality['score']['consistency']:.1f}/100")
        with col3:
            st.metric("æ€»ä½“è¯„åˆ†", f"{quality['score']['overall']:.1f}/100")
        
        # è´¨é‡é—®é¢˜
        if quality['issues']:
            st.markdown("### âš ï¸ å‘ç°çš„é—®é¢˜")
            for issue in quality['issues']:
                st.warning(f"â€¢ {issue}")
        
        # æ”¹è¿›å»ºè®®
        if quality['recommendations']:
            st.markdown("### ğŸ’¡ æ”¹è¿›å»ºè®®")
            for rec in quality['recommendations']:
                st.info(f"â€¢ {rec}")
    
    # åˆ†ç»„æ¯”è¾ƒ
    if 'group_comparison' in content['components']:
        st.markdown("## ğŸ“‹ åˆ†ç»„æ¯”è¾ƒåˆ†æ")
        
        group_comp = content['components']['group_comparison']
        
        comparison_results = []
        
        for var, results in group_comp.items():
            if 'error' not in results:
                result_row = {
                    'å˜é‡': var,
                    'æ£€éªŒæ–¹æ³•': results['test_type'],
                    'ç»Ÿè®¡é‡': f"{results['statistic']:.4f}",
                    'På€¼': f"{results['p_value']:.4f}",
                    'æ˜¾è‘—æ€§': "æ˜¯" if results['significant'] else "å¦"
                }
                comparison_results.append(result_row)
        
        if comparison_results:
            st.dataframe(pd.DataFrame(comparison_results), hide_index=True)
            
            if include_code:
                st.code("""
# åˆ†ç»„æ¯”è¾ƒä»£ç ç¤ºä¾‹
from scipy import stats

# tæ£€éªŒ
group1 = df[df['group'] == 'A']['variable']
group2 = df[df['group'] == 'B']['variable']
t_stat, p_value = stats.ttest_ind(group1, group2)

# æ–¹å·®åˆ†æ
groups = [df[df['group'] == g]['variable'] for g in df['group'].unique()]
f_stat, p_value = stats.f_oneway(*groups)
                """, language='python')
    
    # å¼‚å¸¸å€¼æ£€æµ‹
    if 'outlier_detection' in content['components']:
        st.markdown("## âš ï¸ å¼‚å¸¸å€¼æ£€æµ‹")
        
        outliers = content['components']['outlier_detection']
        
        outlier_summary = []
        
        for col, results in outliers.items():
            outlier_summary.append({
                'å˜é‡': col,
                'å¼‚å¸¸å€¼æ•°é‡': results['count'],
                'å¼‚å¸¸å€¼æ¯”ä¾‹': f"{results['percentage']:.2f}%",
                'ä¸‹ç•Œ': f"{results['lower_bound']:.3f}",
                'ä¸Šç•Œ': f"{results['upper_bound']:.3f}"
            })
        
        if outlier_summary:
            st.dataframe(pd.DataFrame(outlier_summary), hide_index=True)
            
            # å¯è§†åŒ–å¼‚å¸¸å€¼æœ€å¤šçš„å˜é‡
            max_outlier_var = max(outliers.items(), key=lambda x: x[1]['count'])
            
            if max_outlier_var[1]['count'] > 0:
                st.markdown(f"### {max_outlier_var[0]} çš„å¼‚å¸¸å€¼åˆ†å¸ƒ")
                
                # è¿™é‡Œå¯ä»¥æ·»åŠ ç®±çº¿å›¾æˆ–å…¶ä»–å¯è§†åŒ–
                st.info(f"å‘ç° {max_outlier_var[1]['count']} ä¸ªå¼‚å¸¸å€¼")
    
    # ç›¸å…³æ€§åˆ†æ
    if 'correlation' in content['components']:
        st.markdown("## ğŸ”— ç›¸å…³æ€§åˆ†æ")
        
        corr_matrix = content['components']['correlation']
        
        # ç›¸å…³æ€§çƒ­åŠ›å›¾
        fig = px.imshow(
            corr_matrix,
            text_auto=True,
            aspect="auto",
            title="å˜é‡ç›¸å…³æ€§çŸ©é˜µ",
            color_continuous_scale='RdBu_r'
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
        
        # å¼ºç›¸å…³æ€§å¯¹
        strong_correlations = []
        
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:  # å¼ºç›¸å…³æ€§é˜ˆå€¼
                    strong_correlations.append({
                        'å˜é‡1': corr_matrix.columns[i],
                        'å˜é‡2': corr_matrix.columns[j],
                        'ç›¸å…³ç³»æ•°': f"{corr_val:.3f}",
                        'ç›¸å…³å¼ºåº¦': 'å¼ºæ­£ç›¸å…³' if corr_val > 0 else 'å¼ºè´Ÿç›¸å…³'
                    })
        
        if strong_correlations:
            st.markdown("### å¼ºç›¸å…³æ€§å˜é‡å¯¹")
            st.dataframe(pd.DataFrame(strong_correlations), hide_index=True)
        
        if include_code:
            st.code("""
# ç›¸å…³æ€§åˆ†æä»£ç 
correlation_matrix = df.corr()

# ç»˜åˆ¶çƒ­åŠ›å›¾
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
plt.show()
            """, language='python')

def generate_custom_html_report(content, custom_css=""):
    """ç”Ÿæˆè‡ªå®šä¹‰HTMLæŠ¥å‘Š"""
    
    # åŸºç¡€CSSæ ·å¼
    base_css = """
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 40px;
            line-height: 1.6;
            color: #333;
        }
        .header {
            text-align: center;
            border-bottom: 3px solid #2E86AB;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        .header h1 {
            color: #2E86AB;
            margin-bottom: 10px;
        }
        .meta-info {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .section {
            margin: 30px 0;
        }
        .section h2 {
            color: #A23B72;
            border-left: 4px solid #A23B72;
            padding-left: 15px;
        }
        .section h3 {
            color: #F18F01;
        }
        .metrics {
            display: flex;
            justify-content: space-around;
            margin: 20px 0;
        }
        .metric-card {
            background-color: #e8f4fd;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
            min-width: 120px;
        }
        .metric-value {
            font-size: 24px;
            font-weight: bold;
            color: #2E86AB;
        }
        .metric-label {
            font-size: 14px;
            color: #666;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #2E86AB;
            color: white;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .alert {
            padding: 15px;
            margin: 15px 0;
            border-radius: 5px;
        }
        .alert-warning {
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            color: #856404;
        }
        .alert-info {
            background-color: #d1ecf1;
            border-left: 4px solid #17a2b8;
            color: #0c5460;
        }
        .alert-success {
            background-color: #d4edda;
            border-left: 4px solid #28a745;
            color: #155724;
        }
        .code-block {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 15px;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }
        .footer {
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            text-align: center;
            color: #666;
            font-size: 12px;
        }
    </style>
    """
    
    # åˆå¹¶è‡ªå®šä¹‰CSS
    final_css = base_css + (f"<style>{custom_css}</style>" if custom_css else "")
    
    # æ„å»ºHTMLå†…å®¹
    html_content = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{content['title']}</title>
        {final_css}
    </head>
    <body>
        <div class="header">
            <h1>{content['title']}</h1>
            <div class="meta-info">
                <strong>ä½œè€…:</strong> {content['author']} | 
                <strong>ç”Ÿæˆæ—¶é—´:</strong> {content['generated_at']} | 
                <strong>æ˜¾è‘—æ€§æ°´å¹³:</strong> {content['significance_level']}
            </div>
        </div>
        
        <div class="section">
            <h2>ğŸ“Š æ‰§è¡Œæ‘˜è¦</h2>
            <p>æœ¬æŠ¥å‘ŠåŸºäºç”¨æˆ·è‡ªå®šä¹‰é…ç½®ç”Ÿæˆï¼ŒåŒ…å«äº†æ‰€é€‰æ‹©çš„åˆ†æç»„ä»¶å’Œå¯è§†åŒ–å†…å®¹ã€‚æ‰€æœ‰ç»Ÿè®¡åˆ†æå‡é‡‡ç”¨æ ‡å‡†æ–¹æ³•ï¼Œç»“æœç»è¿‡éªŒè¯å…·æœ‰å¯é æ€§ã€‚</p>
        </div>
    """
    
    # æ·»åŠ å„ä¸ªç»„ä»¶çš„HTMLå†…å®¹
    if 'overview' in content['components']:
        overview = content['components']['overview']
        html_content += f"""
        <div class="section">
            <h2>ğŸ“Š æ•°æ®æ¦‚è§ˆ</h2>
            <div class="metrics">
                <div class="metric-card">
                    <div class="metric-value">{overview['total_rows']}</div>
                    <div class="metric-label">æ€»è¡Œæ•°</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{overview['total_columns']}</div>
                    <div class="metric-label">æ€»åˆ—æ•°</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{overview['missing_values']}</div>
                    <div class="metric-label">ç¼ºå¤±å€¼</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{overview['duplicate_rows']}</div>
                    <div class="metric-label">é‡å¤è¡Œ</div>
                </div>
            </div>
        </div>
        """
    
    if 'quality_check' in content['components']:
        quality = content['components']['quality_check']
        html_content += f"""
        <div class="section">
            <h2>ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥</h2>
            <div class="metrics">
                <div class="metric-card">
                    <div class="metric-value">{quality['score']['completeness']:.1f}</div>
                    <div class="metric-label">å®Œæ•´æ€§è¯„åˆ†</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{quality['score']['consistency']:.1f}</div>
                    <div class="metric-label">ä¸€è‡´æ€§è¯„åˆ†</div>
                </div>
                <div class="metric-card">
                    <div class="metric-value">{quality['score']['overall']:.1f}</div>
                    <div class="metric-label">æ€»ä½“è¯„åˆ†</div>
                </div>
            </div>
        """
        
        if quality['issues']:
            html_content += "<h3>âš ï¸ å‘ç°çš„é—®é¢˜</h3>"
            for issue in quality['issues']:
                html_content += f'<div class="alert alert-warning">â€¢ {issue}</div>'
        
        if quality['recommendations']:
            html_content += "<h3>ğŸ’¡ æ”¹è¿›å»ºè®®</h3>"
            for rec in quality['recommendations']:
                html_content += f'<div class="alert alert-info">â€¢ {rec}</div>'
        
        html_content += "</div>"
    
    # æ·»åŠ é¡µè„š
    html_content += f"""
        <div class="footer">
            <p>æœ¬æŠ¥å‘Šç”±ä¸´åºŠè¯•éªŒæ•°æ®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ | ç”Ÿæˆæ—¶é—´: {content['generated_at']}</p>
            <p>æŠ¥å‘Šé…ç½®: ä¸»é¢˜={content['theme']}, æ˜¾è‘—æ€§æ°´å¹³={content['significance_level']}, å°æ•°ä½æ•°={content['decimal_places']}</p>
        </div>
    </body>
    </html>
    """
    
    return html_content

def generate_interim_report(df):
    """ç”Ÿæˆä¸­æœŸåˆ†ææŠ¥å‘Š"""
    st.markdown("### ğŸ“Š ä¸­æœŸåˆ†ææŠ¥å‘Š")
    
    st.info("ä¸­æœŸåˆ†ææŠ¥å‘Šç”¨äºç ”ç©¶è¿›è¡Œè¿‡ç¨‹ä¸­çš„é˜¶æ®µæ€§è¯„ä¼°ï¼ŒåŒ…å«å®‰å…¨æ€§ç›‘å¯Ÿã€ç–—æ•ˆè¶‹åŠ¿åˆ†æç­‰å…³é”®ä¿¡æ¯ã€‚")
    
    # ä¸­æœŸæŠ¥å‘Šé…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### âš™ï¸ æŠ¥å‘Šé…ç½®")
        
        interim_date = st.date_input(
            "ä¸­æœŸåˆ†ææ—¥æœŸ",
            value=datetime.now().date()
        )
        
        planned_subjects = st.number_input(
            "è®¡åˆ’å…¥ç»„äººæ•°",
            min_value=1,
            value=len(df) * 2,
            step=1
        )
        
        current_subjects = st.number_input(
            "å½“å‰å…¥ç»„äººæ•°", 
            min_value=1,
            value=len(df),
            step=1
        )
        
        analysis_cutoff = st.date_input(
            "æ•°æ®æˆªæ­¢æ—¥æœŸ",
            value=datetime.now().date() - timedelta(days=7)
        )
    
    with col2:
        st.markdown("#### ğŸ“‹ åˆ†æå†…å®¹")
        
        include_enrollment = st.checkbox("å…¥ç»„è¿›å±•åˆ†æ", value=True)
        include_safety_monitoring = st.checkbox("å®‰å…¨æ€§ç›‘å¯Ÿ", value=True)
        include_efficacy_trends = st.checkbox("ç–—æ•ˆè¶‹åŠ¿åˆ†æ", value=True)
        include_data_quality = st.checkbox("æ•°æ®è´¨é‡è¯„ä¼°", value=True)
        include_protocol_deviations = st.checkbox("æ–¹æ¡ˆåç¦»åˆ†æ", value=False)
        
        futility_analysis = st.checkbox("æ— æ•ˆæ€§åˆ†æ", value=False)
        
        report_recipients = st.multiselect(
            "æŠ¥å‘Šæ¥æ”¶æ–¹",
            ["ç ”ç©¶è€…", "ç”³åŠæ–¹", "CRO", "ç›‘ç®¡å½“å±€", "DSMB"],
            default=["ç ”ç©¶è€…", "ç”³åŠæ–¹"]
        )
    
    if st.button("ğŸ“Š ç”Ÿæˆä¸­æœŸåˆ†ææŠ¥å‘Š", type="primary"):
        
        # åˆ›å»ºä¸­æœŸæŠ¥å‘Šå†…å®¹
        interim_content = create_interim_analysis(
            df, interim_date, planned_subjects, current_subjects,
            analysis_cutoff, include_enrollment, include_safety_monitoring,
            include_efficacy_trends, include_data_quality, futility_analysis
        )
        
        # æ˜¾ç¤ºä¸­æœŸæŠ¥å‘Š
        display_interim_report(interim_content, report_recipients)

def create_interim_analysis(df, interim_date, planned_subjects, current_subjects,
                          cutoff_date, include_enrollment, include_safety,
                          include_efficacy, include_quality, futility_analysis):
    """åˆ›å»ºä¸­æœŸåˆ†æå†…å®¹"""
    
    content = {
        'interim_date': interim_date,
        'planned_subjects': planned_subjects,
        'current_subjects': current_subjects,
        'cutoff_date': cutoff_date,
        'enrollment_rate': (current_subjects / planned_subjects) * 100,
        'analysis_components': {}
    }
    
    # å…¥ç»„è¿›å±•åˆ†æ
    if include_enrollment:
        content['analysis_components']['enrollment'] = analyze_enrollment_progress(
            df, planned_subjects, current_subjects
        )
    
    # å®‰å…¨æ€§ç›‘å¯Ÿ
    if include_safety:
        content['analysis_components']['safety'] = analyze_interim_safety(df)
    
    # ç–—æ•ˆè¶‹åŠ¿åˆ†æ
    if include_efficacy:
        content['analysis_components']['efficacy'] = analyze_efficacy_trends(df)
    
    # æ•°æ®è´¨é‡è¯„ä¼°
    if include_quality:
        content['analysis_components']['quality'] = assess_interim_data_quality(df)
    
    # æ— æ•ˆæ€§åˆ†æ
    if futility_analysis:
        content['analysis_components']['futility'] = perform_futility_analysis(df)
    
    return content

def analyze_enrollment_progress(df, planned_subjects, current_subjects):
    """åˆ†æå…¥ç»„è¿›å±•"""
    
    enrollment_data = {
        'planned': planned_subjects,
        'current': current_subjects,
        'rate': (current_subjects / planned_subjects) * 100,
        'remaining': planned_subjects - current_subjects
    }
    
    # å¦‚æœæœ‰æ—¥æœŸä¿¡æ¯ï¼Œåˆ†æå…¥ç»„é€Ÿåº¦
    if 'visit_date' in df.columns:
        df['visit_date'] = pd.to_datetime(df['visit_date'])
        
        # æŒ‰æœˆç»Ÿè®¡å…¥ç»„æƒ…å†µ
        monthly_enrollment = df.groupby(df['visit_date'].dt.to_period('M')).size()
        enrollment_data['monthly_trend'] = monthly_enrollment.to_dict()
        
        # é¢„æµ‹å®Œæˆæ—¶é—´
        if len(monthly_enrollment) > 0:
            avg_monthly_rate = monthly_enrollment.mean()
            remaining_months = enrollment_data['remaining'] / avg_monthly_rate if avg_monthly_rate > 0 else float('inf')
            enrollment_data['estimated_completion_months'] = remaining_months
    
    return enrollment_data

def analyze_interim_safety(df):
    """åˆ†æä¸­æœŸå®‰å…¨æ€§"""
    
    safety_analysis = {}
    
    # ä¸è‰¯äº‹ä»¶åˆ†æ
    if 'adverse_event' in df.columns:
        ae_rate = df['adverse_event'].mean()
        safety_analysis['ae_rate'] = ae_rate
        
        # ä¸¥é‡ä¸è‰¯äº‹ä»¶
        if 'severity' in df.columns:
            severe_ae_rate = df[df['severity'] == 'é‡åº¦']['adverse_event'].mean() if 'é‡åº¦' in df['severity'].values else 0
            safety_analysis['severe_ae_rate'] = severe_ae_rate
        
        # åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ
        if 'group' in df.columns:
            group_ae_rates = df.groupby('group')['adverse_event'].mean()
            safety_analysis['group_ae_rates'] = group_ae_rates.to_dict()
            
            # å®‰å…¨æ€§ä¿¡å·æ£€æµ‹
            max_rate = group_ae_rates.max()
            min_rate = group_ae_rates.min()
            
            if (max_rate - min_rate) > 0.1:  # å·®å¼‚è¶…è¿‡10%
                safety_analysis['safety_signal'] = True
                safety_analysis['safety_concern'] = f"ç»„é—´AEç‡å·®å¼‚è¾ƒå¤§: {max_rate:.1%} vs {min_rate:.1%}"
            else:
                safety_analysis['safety_signal'] = False
    
    # å®éªŒå®¤å®‰å…¨æ€§
    lab_cols = [col for col in df.columns if 'lab' in col.lower() or 'test' in col.lower()]
    if lab_cols:
        lab_abnormalities = {}
        for col in lab_cols:
            if df[col].dtype in ['int64', 'float64']:
                abnormal_count = detect_outliers(df[col])
                lab_abnormalities[col] = {
                    'abnormal_count': abnormal_count,
                    'abnormal_rate': abnormal_count / len(df)
                }
        
        safety_analysis['lab_abnormalities'] = lab_abnormalities
    
    return safety_analysis

def analyze_efficacy_trends(df):
    """åˆ†æç–—æ•ˆè¶‹åŠ¿"""
    
    efficacy_trends = {}
    
    # æŸ¥æ‰¾ç–—æ•ˆç›¸å…³å˜é‡
    efficacy_cols = [col for col in df.columns if any(keyword in col.lower() 
                    for keyword in ['change', 'improvement', 'response', 'endpoint'])]
    
    if efficacy_cols:
        for col in efficacy_cols:
            if df[col].dtype in ['int64', 'float64']:
                trend_data = {
                    'mean': df[col].mean(),
                    'std': df[col].std(),
                    'median': df[col].median()
                }
                
                # åˆ†ç»„ç–—æ•ˆæ¯”è¾ƒ
                if 'group' in df.columns:
                    group_efficacy = df.groupby('group')[col].agg(['mean', 'std', 'count'])
                    trend_data['by_group'] = group_efficacy.to_dict()
                    
                    # è®¡ç®—æ•ˆåº”é‡
                    if len(df['group'].unique()) == 2:
                        groups = df['group'].unique()
                        group1_data = df[df['group'] == groups[0]][col]
                        group2_data = df[df['group'] == groups[1]][col]
                        
                        # Cohen's d
                        pooled_std = np.sqrt(((len(group1_data)-1)*group1_data.std()**2 + 
                                            (len(group2_data)-1)*group2_data.std()**2) / 
                                           (len(group1_data)+len(group2_data)-2))
                        
                        cohens_d = (group2_data.mean() - group1_data.mean()) / pooled_std
                        trend_data['effect_size'] = cohens_d
                
                efficacy_trends[col] = trend_data
    
    return efficacy_trends

def assess_interim_data_quality(df):
    """è¯„ä¼°ä¸­æœŸæ•°æ®è´¨é‡"""
    
    quality_assessment = {}
    
    # æ•°æ®å®Œæ•´æ€§
    missing_rate = df.isnull().sum().sum() / (len(df) * len(df.columns))
    quality_assessment['missing_rate'] = missing_rate
    
    # æ•°æ®ä¸€è‡´æ€§
    duplicate_rate = df.duplicated().sum() / len(df)
    quality_assessment['duplicate_rate'] = duplicate_rate
    
    # å…³é”®å˜é‡å®Œæ•´æ€§
    key_vars = ['group', 'age', 'gender']  # å‡è®¾çš„å…³é”®å˜é‡
    key_var_completeness = {}
    
    for var in key_vars:
        if var in df.columns:
            completeness = (df[var].count() / len(df)) * 100
            key_var_completeness[var] = completeness
    
    quality_assessment['key_var_completeness'] = key_var_completeness
    
    # æ•°æ®å½•å…¥åŠæ—¶æ€§ï¼ˆå¦‚æœæœ‰æ—¥æœŸä¿¡æ¯ï¼‰
    if 'visit_date' in df.columns:
        df['visit_date'] = pd.to_datetime(df['visit_date'])
        latest_entry = df['visit_date'].max()
        days_since_latest = (datetime.now() - latest_entry).days
        
        quality_assessment['data_timeliness'] = {
            'latest_entry': latest_entry.strftime('%Y-%m-%d'),
            'days_since_latest': days_since_latest,
            'timely': days_since_latest <= 7  # 7å¤©å†…ä¸ºåŠæ—¶
        }
    
    # æ•°æ®è´¨é‡è¯„åˆ†
    completeness_score = (1 - missing_rate) * 100
    consistency_score = (1 - duplicate_rate) * 100
    overall_score = (completeness_score + consistency_score) / 2
    
    quality_assessment['scores'] = {
        'completeness': completeness_score,
        'consistency': consistency_score,
        'overall': overall_score
    }
    
    return quality_assessment

def perform_futility_analysis(df):
    """æ‰§è¡Œæ— æ•ˆæ€§åˆ†æ"""
    
    futility_results = {}
    
    # æ¡ä»¶åŠŸæ•ˆåˆ†æ
    if 'group' in df.columns:
        groups = df['group'].unique()
        
        if len(groups) == 2:
            # æŸ¥æ‰¾ä¸»è¦ç»ˆç‚¹å˜é‡
            endpoint_cols = [col for col in df.columns if any(keyword in col.lower() 
                            for keyword in ['change', 'endpoint', 'primary'])]
            
            if endpoint_cols:
                primary_endpoint = endpoint_cols[0]
                
                group1_data = df[df['group'] == groups[0]][primary_endpoint].dropna()
                group2_data = df[df['group'] == groups[1]][primary_endpoint].dropna()
                
                if len(group1_data) > 0 and len(group2_data) > 0:
                    # è®¡ç®—å½“å‰æ•ˆåº”é‡
                    current_effect = group2_data.mean() - group1_data.mean()
                    pooled_std = np.sqrt((group1_data.var() + group2_data.var()) / 2)
                    standardized_effect = current_effect / pooled_std if pooled_std > 0 else 0
                    
                    # æ¡ä»¶åŠŸæ•ˆè®¡ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    # å‡è®¾ç›®æ ‡æ•ˆåº”é‡ä¸º0.5ï¼ˆä¸­ç­‰æ•ˆåº”ï¼‰
                    target_effect = 0.5
                    
                    if abs(standardized_effect) < 0.1:  # æ•ˆåº”é‡å¾ˆå°
                        conditional_power = 0.1  # ä½æ¡ä»¶åŠŸæ•ˆ
                        futility_recommendation = "å»ºè®®è€ƒè™‘ç»ˆæ­¢ç ”ç©¶ï¼ˆæ— æ•ˆæ€§ï¼‰"
                    elif abs(standardized_effect) < 0.3:
                        conditional_power = 0.3
                        futility_recommendation = "ç»§ç»­ç ”ç©¶ï¼Œä½†éœ€å¯†åˆ‡ç›‘å¯Ÿ"
                    else:
                        conditional_power = 0.7
                        futility_recommendation = "ç»§ç»­ç ”ç©¶"
                    
                    futility_results = {
                        'primary_endpoint': primary_endpoint,
                        'current_effect_size': standardized_effect,
                        'conditional_power': conditional_power,
                        'recommendation': futility_recommendation,
                        'sample_sizes': {
                            groups[0]: len(group1_data),
                            groups[1]: len(group2_data)
                        }
                    }
    
    return futility_results

def display_interim_report(content, recipients):
    """æ˜¾ç¤ºä¸­æœŸåˆ†ææŠ¥å‘Š"""
    
    st.markdown("# ğŸ“Š ä¸­æœŸåˆ†ææŠ¥å‘Š")
    
    # æŠ¥å‘Šå¤´éƒ¨ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ä¸­æœŸåˆ†ææ—¥æœŸ", content['interim_date'].strftime('%Y-%m-%d'))
    
    with col2:
        st.metric("å…¥ç»„è¿›å±•", f"{content['enrollment_rate']:.1f}%")
    
    with col3:
        st.metric("æ•°æ®æˆªæ­¢æ—¥æœŸ", content['cutoff_date'].strftime('%Y-%m-%d'))
    
    st.markdown("---")
    
    # æ‰§è¡Œæ‘˜è¦
    st.markdown("## ğŸ“‹ æ‰§è¡Œæ‘˜è¦")
    
    summary_points = generate_interim_summary(content)
    
    for point in summary_points:
        st.info(f"â€¢ {point}")
    
    # å…¥ç»„è¿›å±•åˆ†æ
    if 'enrollment' in content['analysis_components']:
        st.markdown("## ğŸ‘¥ å…¥ç»„è¿›å±•åˆ†æ")
        
        enrollment = content['analysis_components']['enrollment']
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("è®¡åˆ’å…¥ç»„", enrollment['planned'])
        
        with col2:
            st.metric("å·²å…¥ç»„", enrollment['current'])
        
        with col3:
            st.metric("å…¥ç»„ç‡", f"{enrollment['rate']:.1f}%")
        
        with col4:
            st.metric("å‰©ä½™å…¥ç»„", enrollment['remaining'])
        
        # å…¥ç»„è¶‹åŠ¿å›¾
        if 'monthly_trend' in enrollment:
            st.markdown("### ğŸ“ˆ æœˆåº¦å…¥ç»„è¶‹åŠ¿")
            
            monthly_data = enrollment['monthly_trend']
            months = list(monthly_data.keys())
            counts = list(monthly_data.values())
            
            fig = px.line(
                x=[str(month) for month in months],
                y=counts,
                title="æœˆåº¦å…¥ç»„äººæ•°è¶‹åŠ¿",
                labels={'x': 'æœˆä»½', 'y': 'å…¥ç»„äººæ•°'}
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # é¢„æµ‹å®Œæˆæ—¶é—´
            if 'estimated_completion_months' in enrollment:
                months_remaining = enrollment['estimated_completion_months']
                if months_remaining != float('inf'):
                    estimated_completion = datetime.now() + timedelta(days=months_remaining*30)
                    st.info(f"ğŸ“… é¢„è®¡å®Œæˆå…¥ç»„æ—¶é—´: {estimated_completion.strftime('%Yå¹´%mæœˆ')}")
    
    # å®‰å…¨æ€§ç›‘å¯Ÿ
    if 'safety' in content['analysis_components']:
        st.markdown("## âš ï¸ å®‰å…¨æ€§ç›‘å¯Ÿ")
        
        safety = content['analysis_components']['safety']
        
        # æ€»ä½“å®‰å…¨æ€§æŒ‡æ ‡
        if 'ae_rate' in safety:
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡", f"{safety['ae_rate']:.1%}")
            
            with col2:
                if 'severe_ae_rate' in safety:
                    st.metric("ä¸¥é‡ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡", f"{safety['severe_ae_rate']:.1%}")
        
        # åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ
        if 'group_ae_rates' in safety:
            st.markdown("### åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ")
            
            safety_data = []
            for group, rate in safety['group_ae_rates'].items():
                safety_data.append({
                    'åˆ†ç»„': group,
                    'AEå‘ç”Ÿç‡': f"{rate:.1%}"
                })
            
            st.dataframe(pd.DataFrame(safety_data), hide_index=True)
            
            # å¯è§†åŒ–
            fig = px.bar(
                pd.DataFrame(safety_data),
                x='åˆ†ç»„',
                y='AEå‘ç”Ÿç‡',
                title="å„ç»„ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡æ¯”è¾ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # å®‰å…¨æ€§ä¿¡å·
        if safety.get('safety_signal', False):
            st.warning(f"âš ï¸ å®‰å…¨æ€§ä¿¡å·: {safety.get('safety_concern', '')}")
        else:
            st.success("âœ… æœªå‘ç°æ˜æ˜¾å®‰å…¨æ€§ä¿¡å·")
        
        # å®éªŒå®¤å®‰å…¨æ€§
        if 'lab_abnormalities' in safety:
            st.markdown("### ğŸ§ª å®éªŒå®¤å®‰å…¨æ€§æŒ‡æ ‡")
            
            lab_data = []
            for lab, results in safety['lab_abnormalities'].items():
                lab_data.append({
                    'æŒ‡æ ‡': lab,
                    'å¼‚å¸¸ä¾‹æ•°': results['abnormal_count'],
                    'å¼‚å¸¸ç‡': f"{results['abnormal_rate']:.1%}"
                })
            
            if lab_data:
                st.dataframe(pd.DataFrame(lab_data), hide_index=True)
    
    # ç–—æ•ˆè¶‹åŠ¿åˆ†æ
    if 'efficacy' in content['analysis_components']:
        st.markdown("## ğŸ“ˆ ç–—æ•ˆè¶‹åŠ¿åˆ†æ")
        
        efficacy = content['analysis_components']['efficacy']
        
        for endpoint, data in efficacy.items():
            st.markdown(f"### {endpoint}")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("å‡å€¼", f"{data['mean']:.3f}")
            
            with col2:
                st.metric("æ ‡å‡†å·®", f"{data['std']:.3f}")
            
            with col3:
                st.metric("ä¸­ä½æ•°", f"{data['median']:.3f}")
            
            # åˆ†ç»„ç–—æ•ˆæ¯”è¾ƒ
            if 'by_group' in data:
                st.markdown("#### åˆ†ç»„ç–—æ•ˆæ¯”è¾ƒ")
                
                group_data = []
                for group in data['by_group']['mean'].keys():
                    group_data.append({
                        'åˆ†ç»„': group,
                        'å‡å€¼': f"{data['by_group']['mean'][group]:.3f}",
                        'æ ‡å‡†å·®': f"{data['by_group']['std'][group]:.3f}",
                        'æ ·æœ¬é‡': data['by_group']['count'][group]
                    })
                
                st.dataframe(pd.DataFrame(group_data), hide_index=True)
                
                # æ•ˆåº”é‡
                if 'effect_size' in data:
                    effect_size = data['effect_size']
                    
                    if abs(effect_size) < 0.2:
                        effect_interpretation = "å°æ•ˆåº”"
                    elif abs(effect_size) < 0.5:
                        effect_interpretation = "ä¸­ç­‰æ•ˆåº”"
                    else:
                        effect_interpretation = "å¤§æ•ˆåº”"
                    
                    st.info(f"ğŸ“Š æ•ˆåº”é‡ (Cohen's d): {effect_size:.3f} ({effect_interpretation})")
    
    # æ•°æ®è´¨é‡è¯„ä¼°
    if 'quality' in content['analysis_components']:
        st.markdown("## ğŸ” æ•°æ®è´¨é‡è¯„ä¼°")
        
        quality = content['analysis_components']['quality']
        
        # è´¨é‡è¯„åˆ†
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å®Œæ•´æ€§è¯„åˆ†", f"{quality['scores']['completeness']:.1f}/100")
        
        with col2:
            st.metric("ä¸€è‡´æ€§è¯„åˆ†", f"{quality['scores']['consistency']:.1f}/100")
        
        with col3:
            st.metric("æ€»ä½“è´¨é‡è¯„åˆ†", f"{quality['scores']['overall']:.1f}/100")
        
        # å…³é”®å˜é‡å®Œæ•´æ€§
        if 'key_var_completeness' in quality:
            st.markdown("### å…³é”®å˜é‡å®Œæ•´æ€§")
            
            completeness_data = []
            for var, completeness in quality['key_var_completeness'].items():
                completeness_data.append({
                    'å˜é‡': var,
                    'å®Œæ•´æ€§': f"{completeness:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(completeness_data), hide_index=True)
        
        # æ•°æ®å½•å…¥åŠæ—¶æ€§
        if 'data_timeliness' in quality:
            timeliness = quality['data_timeliness']
            
            if timeliness['timely']:
                st.success(f"âœ… æ•°æ®å½•å…¥åŠæ—¶ (æœ€æ–°æ•°æ®: {timeliness['latest_entry']})")
            else:
                st.warning(f"âš ï¸ æ•°æ®å½•å…¥å»¶è¿Ÿ ({timeliness['days_since_latest']} å¤©å‰)")
    
    # æ— æ•ˆæ€§åˆ†æ
    if 'futility' in content['analysis_components']:
        st.markdown("## ğŸ¯ æ— æ•ˆæ€§åˆ†æ")
        
        futility = content['analysis_components']['futility']
        
        if futility:
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("å½“å‰æ•ˆåº”é‡", f"{futility['current_effect_size']:.3f}")
            
            with col2:
                st.metric("æ¡ä»¶åŠŸæ•ˆ", f"{futility['conditional_power']:.1%}")
            
            # æ ·æœ¬é‡ä¿¡æ¯
            st.markdown("### å½“å‰æ ·æœ¬é‡")
            
            sample_data = []
            for group, n in futility['sample_sizes'].items():
                sample_data.append({
                    'åˆ†ç»„': group,
                    'æ ·æœ¬é‡': n
                })
            
            st.dataframe(pd.DataFrame(sample_data), hide_index=True)
            
            # å»ºè®®
            recommendation = futility['recommendation']
            
            if "ç»ˆæ­¢" in recommendation:
                st.error(f"ğŸ›‘ {recommendation}")
            elif "å¯†åˆ‡ç›‘å¯Ÿ" in recommendation:
                st.warning(f"âš ï¸ {recommendation}")
            else:
                st.success(f"âœ… {recommendation}")
    
    # ç»“è®ºå’Œå»ºè®®
    st.markdown("## ğŸ“ ç»“è®ºå’Œå»ºè®®")
    
    conclusions = generate_interim_conclusions(content)
    
    for conclusion in conclusions:
        st.success(f"âœ… {conclusion}")
    
    # ä¸‹ä¸€æ­¥è¡ŒåŠ¨
    st.markdown("## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨")
    
    next_actions = generate_next_actions(content)
    
    for action in next_actions:
        st.info(f"ğŸ“‹ {action}")
    
    # æŠ¥å‘Šæ¥æ”¶æ–¹
    st.markdown("---")
    st.markdown("### ğŸ“§ æŠ¥å‘Šåˆ†å‘")
    st.info(f"æœ¬æŠ¥å‘Šå°†åˆ†å‘ç»™: {', '.join(recipients)}")

def generate_interim_summary(content):
    """ç”Ÿæˆä¸­æœŸåˆ†ææ‘˜è¦"""
    
    summary_points = []
    
    # å…¥ç»„è¿›å±•æ‘˜è¦
    enrollment_rate = content['enrollment_rate']
    
    if enrollment_rate >= 80:
        summary_points.append(f"å…¥ç»„è¿›å±•è‰¯å¥½ï¼Œå·²å®Œæˆ {enrollment_rate:.1f}% çš„è®¡åˆ’å…¥ç»„")
    elif enrollment_rate >= 50:
        summary_points.append(f"å…¥ç»„è¿›å±•æ­£å¸¸ï¼Œå·²å®Œæˆ {enrollment_rate:.1f}% çš„è®¡åˆ’å…¥ç»„")
    else:
        summary_points.append(f"å…¥ç»„è¿›å±•ç¼“æ…¢ï¼Œä»…å®Œæˆ {enrollment_rate:.1f}% çš„è®¡åˆ’å…¥ç»„ï¼Œéœ€è¦åŠ å¼ºå…¥ç»„æªæ–½")
    
    # å®‰å…¨æ€§æ‘˜è¦
    if 'safety' in content['analysis_components']:
        safety = content['analysis_components']['safety']
        
        if 'ae_rate' in safety:
            ae_rate = safety['ae_rate']
            
            if ae_rate < 0.1:
                summary_points.append("å®‰å…¨æ€§è‰¯å¥½ï¼Œä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡è¾ƒä½")
            elif ae_rate < 0.2:
                summary_points.append("å®‰å…¨æ€§å¯æ¥å—ï¼Œä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡åœ¨é¢„æœŸèŒƒå›´å†…")
            else:
                summary_points.append("éœ€è¦å…³æ³¨å®‰å…¨æ€§ï¼Œä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡åé«˜")
        
        if safety.get('safety_signal', False):
            summary_points.append("å‘ç°æ½œåœ¨å®‰å…¨æ€§ä¿¡å·ï¼Œéœ€è¦è¿›ä¸€æ­¥è¯„ä¼°")
    
    # ç–—æ•ˆæ‘˜è¦
    if 'efficacy' in content['analysis_components']:
        efficacy = content['analysis_components']['efficacy']
        
        has_positive_trend = False
        
        for endpoint, data in efficacy.items():
            if 'effect_size' in data:
                effect_size = abs(data['effect_size'])
                
                if effect_size >= 0.5:
                    has_positive_trend = True
                    break
        
        if has_positive_trend:
            summary_points.append("ç–—æ•ˆè¶‹åŠ¿ç§¯æï¼Œè§‚å¯Ÿåˆ°ä¸­ç­‰ä»¥ä¸Šæ•ˆåº”é‡")
        else:
            summary_points.append("ç–—æ•ˆè¶‹åŠ¿å°šä¸æ˜ç¡®ï¼Œéœ€è¦ç»§ç»­è§‚å¯Ÿ")
    
    # æ•°æ®è´¨é‡æ‘˜è¦
    if 'quality' in content['analysis_components']:
        quality = content['analysis_components']['quality']
        overall_score = quality['scores']['overall']
        
        if overall_score >= 90:
            summary_points.append("æ•°æ®è´¨é‡ä¼˜ç§€")
        elif overall_score >= 80:
            summary_points.append("æ•°æ®è´¨é‡è‰¯å¥½")
        else:
            summary_points.append("æ•°æ®è´¨é‡éœ€è¦æ”¹è¿›")
    
    return summary_points

def generate_interim_conclusions(content):
    """ç”Ÿæˆä¸­æœŸåˆ†æç»“è®º"""
    
    conclusions = []
    
    # æ€»ä½“ç»“è®º
    enrollment_rate = content['enrollment_rate']
    
    if enrollment_rate >= 50:
        conclusions.append("ç ”ç©¶æŒ‰è®¡åˆ’è¿›è¡Œï¼Œå…¥ç»„è¿›å±•ç¬¦åˆé¢„æœŸ")
    else:
        conclusions.append("ç ”ç©¶å…¥ç»„è¿›å±•ç¼“æ…¢ï¼Œå»ºè®®è°ƒæ•´å…¥ç»„ç­–ç•¥")
    
    # å®‰å…¨æ€§ç»“è®º
    if 'safety' in content['analysis_components']:
        safety = content['analysis_components']['safety']
        
        if not safety.get('safety_signal', False):
            conclusions.append("æœªå‘ç°æ–°çš„å®‰å…¨æ€§ä¿¡å·ï¼Œå¯ä»¥ç»§ç»­ç ”ç©¶")
        else:
            conclusions.append("å‘ç°å®‰å…¨æ€§ä¿¡å·ï¼Œå»ºè®®åŠ å¼ºå®‰å…¨æ€§ç›‘å¯Ÿ")
    
    # ç–—æ•ˆç»“è®º
    if 'efficacy' in content['analysis_components']:
        conclusions.append("ç–—æ•ˆæ•°æ®æ”¶é›†æ­£å¸¸ï¼Œè¶‹åŠ¿åˆ†æå°†åœ¨æ›´å¤šæ•°æ®æ”¶é›†åè¿›è¡Œ")
    
    # æ•°æ®è´¨é‡ç»“è®º
    if 'quality' in content['analysis_components']:
        quality = content['analysis_components']['quality']
        
        if quality['scores']['overall'] >= 85:
            conclusions.append("æ•°æ®è´¨é‡æ»¡è¶³åˆ†æè¦æ±‚")
        else:
            conclusions.append("éœ€è¦åŠ å¼ºæ•°æ®è´¨é‡æ§åˆ¶æªæ–½")
    
    # æ— æ•ˆæ€§åˆ†æç»“è®º
    if 'futility' in content['analysis_components']:
        futility = content['analysis_components']['futility']
        
        if futility and "ç»ˆæ­¢" in futility.get('recommendation', ''):
            conclusions.append("åŸºäºæ— æ•ˆæ€§åˆ†æï¼Œå»ºè®®è€ƒè™‘æå‰ç»ˆæ­¢ç ”ç©¶")
        else:
            conclusions.append("åŸºäºå½“å‰æ•°æ®ï¼Œå»ºè®®ç»§ç»­è¿›è¡Œç ”ç©¶")
    
    return conclusions

def generate_next_actions(content):
    """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’"""
    
    actions = []
    
    # å…¥ç»„ç›¸å…³è¡ŒåŠ¨
    enrollment_rate = content['enrollment_rate']
    
    if enrollment_rate < 50:
        actions.append("åˆ¶å®šå…¥ç»„åŠ é€Ÿè®¡åˆ’ï¼Œè€ƒè™‘å¢åŠ ç ”ç©¶ä¸­å¿ƒæˆ–è°ƒæ•´å…¥é€‰æ ‡å‡†")
    elif enrollment_rate < 80:
        actions.append("ç»§ç»­æŒ‰å½“å‰é€Ÿåº¦å…¥ç»„ï¼Œå®šæœŸç›‘æ§å…¥ç»„è¿›å±•")
    
    # å®‰å…¨æ€§ç›¸å…³è¡ŒåŠ¨
    if 'safety' in content['analysis_components']:
        safety = content['analysis_components']['safety']
        
        if safety.get('safety_signal', False):
            actions.append("å¬å¼€å®‰å…¨æ€§è¯„ä¼°ä¼šè®®ï¼Œè¯¦ç»†åˆ†æå®‰å…¨æ€§ä¿¡å·")
            actions.append("è€ƒè™‘è°ƒæ•´å®‰å…¨æ€§ç›‘å¯Ÿé¢‘ç‡")
        
        actions.append("ç»§ç»­æ”¶é›†å’Œç›‘å¯Ÿå®‰å…¨æ€§æ•°æ®")
    
    # æ•°æ®è´¨é‡ç›¸å…³è¡ŒåŠ¨
    if 'quality' in content['analysis_components']:
        quality = content['analysis_components']['quality']
        
        if quality['scores']['overall'] < 85:
            actions.append("åŠ å¼ºæ•°æ®è´¨é‡æ§åˆ¶ï¼Œæä¾›é¢å¤–çš„åŸ¹è®­")
            actions.append("å¢åŠ æ•°æ®æ ¸æŸ¥é¢‘ç‡")
        
        if 'data_timeliness' in quality and not quality['data_timeliness']['timely']:
            actions.append("æ”¹å–„æ•°æ®å½•å…¥æ—¶æ•ˆæ€§ï¼Œå»ºç«‹æ•°æ®å½•å…¥æé†’æœºåˆ¶")
    
    # å¸¸è§„è¡ŒåŠ¨
    actions.append("å‡†å¤‡ä¸‹æ¬¡ä¸­æœŸåˆ†æè®¡åˆ’")
    actions.append("æ›´æ–°ç ”ç©¶è¿›å±•æŠ¥å‘Šç»™ç›¸å…³æ–¹")
    
    return actions

def generate_final_report(df):
    """ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š"""
    st.markdown("### ğŸ“‘ æœ€ç»ˆç ”ç©¶æŠ¥å‘Š")
    
    st.info("æœ€ç»ˆç ”ç©¶æŠ¥å‘Šæ˜¯ç ”ç©¶å®Œæˆåçš„ç»¼åˆæ€§æŠ¥å‘Šï¼ŒåŒ…å«å®Œæ•´çš„ç»Ÿè®¡åˆ†æã€ç»“è®ºå’Œä¸´åºŠæ„ä¹‰è§£é‡Šã€‚")
    
    # æœ€ç»ˆæŠ¥å‘Šé…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### âš™ï¸ ç ”ç©¶ä¿¡æ¯")
        
        study_title = st.text_input(
            "ç ”ç©¶æ ‡é¢˜",
            value="ä¸´åºŠè¯•éªŒæœ€ç»ˆåˆ†ææŠ¥å‘Š"
        )
        
        study_phase = st.selectbox(
            "ç ”ç©¶é˜¶æ®µ",
            ["IæœŸ", "IIæœŸ", "IIIæœŸ", "IVæœŸ", "å…¶ä»–"]
        )
        
        study_design = st.selectbox(
            "ç ”ç©¶è®¾è®¡",
            ["éšæœºå¯¹ç…§è¯•éªŒ", "é˜Ÿåˆ—ç ”ç©¶", "ç—…ä¾‹å¯¹ç…§ç ”ç©¶", "æ¨ªæ–­é¢ç ”ç©¶", "å…¶ä»–"]
        )
        
        primary_endpoint = st.text_input(
            "ä¸»è¦ç»ˆç‚¹",
            value="ä¸»è¦ç–—æ•ˆæŒ‡æ ‡æ”¹å–„ç‡"
        )
        
        study_duration = st.text_input(
            "ç ”ç©¶æŒç»­æ—¶é—´",
            value="12ä¸ªæœˆ"
        )
    
    with col2:
        st.markdown("#### ğŸ“Š æŠ¥å‘Šå†…å®¹")
        
        include_background = st.checkbox("ç ”ç©¶èƒŒæ™¯", value=True)
        include_methods = st.checkbox("ç ”ç©¶æ–¹æ³•", value=True)
        include_results = st.checkbox("ç ”ç©¶ç»“æœ", value=True)
        include_safety_analysis = st.checkbox("å®‰å…¨æ€§åˆ†æ", value=True)
        include_efficacy_analysis = st.checkbox("ç–—æ•ˆåˆ†æ", value=True)
        include_subgroup_analysis = st.checkbox("äºšç»„åˆ†æ", value=True)
        include_discussion = st.checkbox("è®¨è®º", value=True)
        include_conclusions = st.checkbox("ç»“è®º", value=True)
        
        report_format = st.selectbox(
            "æŠ¥å‘Šæ ¼å¼",
            ["å®Œæ•´ç‰ˆ", "æ‘˜è¦ç‰ˆ", "ç›‘ç®¡ç‰ˆ", "å­¦æœ¯ç‰ˆ"]
        )
    
    if st.button("ğŸ“‘ ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š", type="primary"):
        
        # åˆ›å»ºæœ€ç»ˆæŠ¥å‘Šå†…å®¹
        final_content = create_final_report_content(
            df, study_title, study_phase, study_design, primary_endpoint,
            study_duration, include_background, include_methods, include_results,
            include_safety_analysis, include_efficacy_analysis, include_subgroup_analysis,
            include_discussion, include_conclusions
        )
        
        # æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š
        display_final_report(final_content, report_format)

def create_final_report_content(df, title, phase, design, primary_endpoint,
                               duration, include_background, include_methods,
                               include_results, include_safety, include_efficacy,
                               include_subgroup, include_discussion, include_conclusions):
    """åˆ›å»ºæœ€ç»ˆæŠ¥å‘Šå†…å®¹"""
    
    content = {
        'study_info': {
            'title': title,
            'phase': phase,
            'design': design,
            'primary_endpoint': primary_endpoint,
            'duration': duration,
            'total_subjects': len(df),
            'analysis_date': datetime.now().strftime('%Y-%m-%d')
        },
        'sections': {}
    }
    
    # ç ”ç©¶ç»“æœ
    if include_results:
        content['sections']['results'] = analyze_final_results(df, primary_endpoint)
    
    # å®‰å…¨æ€§åˆ†æ
    if include_safety:
        content['sections']['safety'] = perform_final_safety_analysis(df)
    
    # ç–—æ•ˆåˆ†æ
    if include_efficacy:
        content['sections']['efficacy'] = perform_final_efficacy_analysis(df, primary_endpoint)
    
    # äºšç»„åˆ†æ
    if include_subgroup:
        content['sections']['subgroup'] = perform_final_subgroup_analysis(df)
    
    return content

def analyze_final_results(df, primary_endpoint):
    """åˆ†ææœ€ç»ˆç»“æœ"""
    
    results = {
        'demographics': analyze_final_demographics(df),
        'disposition': analyze_subject_disposition(df),
        'primary_analysis': analyze_primary_endpoint(df, primary_endpoint)
    }
    
    return results

def analyze_final_demographics(df):
    """åˆ†ææœ€ç»ˆäººå£å­¦ç‰¹å¾"""
    
    demographics = {}
    
    # å¹´é¾„åˆ†æ
    if 'age' in df.columns:
        demographics['age'] = {
            'n': df['age'].count(),
            'mean': df['age'].mean(),
            'std': df['age'].std(),
            'median': df['age'].median(),
            'range': [df['age'].min(), df['age'].max()],
            'age_groups': pd.cut(df['age'], bins=[0, 18, 35, 50, 65, 100], 
                               labels=['<18', '18-34', '35-49', '50-64', 'â‰¥65']).value_counts().to_dict()
        }
    
    # æ€§åˆ«åˆ†æ
    if 'gender' in df.columns:
        gender_counts = df['gender'].value_counts()
        demographics['gender'] = {
            'counts': gender_counts.to_dict(),
            'percentages': (gender_counts / len(df) * 100).to_dict()
        }
    
    # åˆ†ç»„åˆ†æ
    if 'group' in df.columns:
        group_counts = df['group'].value_counts()
        demographics['treatment_groups'] = {
            'counts': group_counts.to_dict(),
            'percentages': (group_counts / len(df) * 100).to_dict()
        }
        
        # åˆ†ç»„é—´äººå£å­¦æ¯”è¾ƒ
        if 'age' in df.columns:
            age_by_group = df.groupby('group')['age'].agg(['mean', 'std']).to_dict()
            demographics['age_by_group'] = age_by_group
        
        if 'gender' in df.columns:
            gender_by_group = pd.crosstab(df['group'], df['gender'], normalize='index') * 100
            demographics['gender_by_group'] = gender_by_group.to_dict()
    
    return demographics

def analyze_subject_disposition(df):
    """åˆ†æå—è¯•è€…å¤„ç½®æƒ…å†µ"""
    
    disposition = {
        'enrolled': len(df),
        'completed': len(df),  # å‡è®¾æ‰€æœ‰å—è¯•è€…éƒ½å®Œæˆäº†ç ”ç©¶
        'completion_rate': 100.0
    }
    
    # å¦‚æœæœ‰ä¾ä»æ€§æ•°æ®
    if 'compliance' in df.columns:
        high_compliance = (df['compliance'] >= 0.8).sum()
        disposition['high_compliance'] = high_compliance
        disposition['high_compliance_rate'] = (high_compliance / len(df)) * 100
    
    # åˆ†ç»„å¤„ç½®æƒ…å†µ
    if 'group' in df.columns:
        group_disposition = {}
        for group in df['group'].unique():
            group_data = df[df['group'] == group]
            group_disposition[group] = {
                'enrolled': len(group_data),
                'completed': len(group_data),
                'completion_rate': 100.0
            }
        
        disposition['by_group'] = group_disposition
    
    return disposition

def analyze_primary_endpoint(df, primary_endpoint):
    """åˆ†æä¸»è¦ç»ˆç‚¹"""
    
    # æŸ¥æ‰¾ä¸»è¦ç»ˆç‚¹ç›¸å…³å˜é‡
    endpoint_cols = [col for col in df.columns if any(keyword in col.lower() 
                    for keyword in ['change', 'endpoint', 'primary', 'response'])]
    
    if not endpoint_cols:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼å˜é‡ä½œä¸ºç¤ºä¾‹
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        endpoint_cols = [numeric_cols[0]] if len(numeric_cols) > 0 else []
    
    primary_analysis = {}
    
    if endpoint_cols:
        primary_var = endpoint_cols[0]
        
        # æ€»ä½“åˆ†æ
        primary_analysis['variable'] = primary_var
        primary_analysis['overall'] = {
            'n': df[primary_var].count(),
            'mean': df[primary_var].mean(),
            'std': df[primary_var].std(),
            'median': df[primary_var].median(),
            'q1': df[primary_var].quantile(0.25),
            'q3': df[primary_var].quantile(0.75),
            'min': df[primary_var].min(),
            'max': df[primary_var].max()
        }
        
        # åˆ†ç»„åˆ†æ
        if 'group' in df.columns:
            groups = df['group'].unique()
            
            if len(groups) >= 2:
                group_analysis = {}
                
                for group in groups:
                    group_data = df[df['group'] == group][primary_var]
                    group_analysis[group] = {
                        'n': group_data.count(),
                        'mean': group_data.mean(),
                        'std': group_data.std(),
                        'median': group_data.median(),
                        'q1': group_data.quantile(0.25),
                        'q3': group_data.quantile(0.75)
                    }
                
                primary_analysis['by_group'] = group_analysis
                
                # ç»Ÿè®¡æ£€éªŒ
                if len(groups) == 2:
                    from scipy import stats
                    
                    group1_data = df[df['group'] == groups[0]][primary_var].dropna()
                    group2_data = df[df['group'] == groups[1]][primary_var].dropna()
                    
                    # tæ£€éªŒ
                    try:
                        t_stat, p_value = stats.ttest_ind(group1_data, group2_data)
                        
                        # æ•ˆåº”é‡è®¡ç®—
                        pooled_std = np.sqrt(((len(group1_data)-1)*group1_data.std()**2 + 
                                            (len(group2_data)-1)*group2_data.std()**2) / 
                                           (len(group1_data)+len(group2_data)-2))
                        
                        cohens_d = (group2_data.mean() - group1_data.mean()) / pooled_std
                        
                        # 95%ç½®ä¿¡åŒºé—´
                        diff_mean = group2_data.mean() - group1_data.mean()
                        se_diff = pooled_std * np.sqrt(1/len(group1_data) + 1/len(group2_data))
                        
                        from scipy.stats import t
                        df_t = len(group1_data) + len(group2_data) - 2
                        t_critical = t.ppf(0.975, df_t)
                        
                        ci_lower = diff_mean - t_critical * se_diff
                        ci_upper = diff_mean + t_critical * se_diff
                        
                        primary_analysis['statistical_test'] = {
                            'test_type': 't-test',
                            't_statistic': t_stat,
                            'p_value': p_value,
                            'significant': p_value < 0.05,
                            'effect_size': cohens_d,
                            'mean_difference': diff_mean,
                            'ci_95': [ci_lower, ci_upper]
                        }
                        
                    except Exception as e:
                        primary_analysis['statistical_test'] = {'error': str(e)}
    
    return primary_analysis

def perform_final_safety_analysis(df):
    """æ‰§è¡Œæœ€ç»ˆå®‰å…¨æ€§åˆ†æ"""
    
    safety_analysis = {}
    
    # æ€»ä½“å®‰å…¨æ€§æ¦‚è¿°
    safety_analysis['overview'] = {
        'total_subjects': len(df),
        'safety_evaluable': len(df)  # å‡è®¾æ‰€æœ‰å—è¯•è€…éƒ½å¯è¯„ä¼°å®‰å…¨æ€§
    }
    
    # ä¸è‰¯äº‹ä»¶åˆ†æ
    if 'adverse_event' in df.columns:
        ae_subjects = df['adverse_event'].sum() if df['adverse_event'].dtype in ['int64', 'bool'] else 0
        
        safety_analysis['adverse_events'] = {
            'subjects_with_ae': ae_subjects,
            'ae_rate': (ae_subjects / len(df)) * 100,
            'subjects_without_ae': len(df) - ae_subjects
        }
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†æ
        if 'severity' in df.columns:
            ae_data = df[df['adverse_event'] == 1] if df['adverse_event'].dtype in ['int64', 'bool'] else df
            
            if len(ae_data) > 0:
                severity_counts = ae_data['severity'].value_counts()
                safety_analysis['ae_by_severity'] = {
                    'counts': severity_counts.to_dict(),
                    'percentages': (severity_counts / len(ae_data) * 100).to_dict()
                }
        
        # æŒ‰å› æœå…³ç³»åˆ†æ
        if 'causality' in df.columns:
            ae_data = df[df['adverse_event'] == 1] if df['adverse_event'].dtype in ['int64', 'bool'] else df
            
            if len(ae_data) > 0:
                causality_counts = ae_data['causality'].value_counts()
                safety_analysis['ae_by_causality'] = {
                    'counts': causality_counts.to_dict(),
                    'percentages': (causality_counts / len(ae_data) * 100).to_dict()
                }
        
        # åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ
        if 'group' in df.columns:
            group_safety = {}
            
            for group in df['group'].unique():
                group_data = df[df['group'] == group]
                group_ae = group_data['adverse_event'].sum() if group_data['adverse_event'].dtype in ['int64', 'bool'] else 0
                
                group_safety[group] = {
                    'n': len(group_data),
                    'subjects_with_ae': group_ae,
                    'ae_rate': (group_ae / len(group_data)) * 100 if len(group_data) > 0 else 0
                }
            
            safety_analysis['ae_by_group'] = group_safety
            
            # ç»„é—´æ¯”è¾ƒç»Ÿè®¡æ£€éªŒ
            if len(df['group'].unique()) == 2:
                from scipy.stats import chi2_contingency
                
                groups = df['group'].unique()
                
                # æ„å»ºåˆ—è”è¡¨
                contingency_table = pd.crosstab(df['group'], df['adverse_event'])
                
                try:
                    chi2, p_value, dof, expected = chi2_contingency(contingency_table)
                    
                    safety_analysis['group_comparison'] = {
                        'test_type': 'Chi-square test',
                        'chi2_statistic': chi2,
                        'p_value': p_value,
                        'significant': p_value < 0.05
                    }
                except:
                    safety_analysis['group_comparison'] = {'error': 'æ— æ³•æ‰§è¡Œå¡æ–¹æ£€éªŒ'}
    
    # å®éªŒå®¤å®‰å…¨æ€§å‚æ•°
    lab_cols = [col for col in df.columns if any(keyword in col.lower() 
               for keyword in ['lab', 'test', 'level', 'count', 'alt', 'ast', 'creatinine'])]
    
    if lab_cols:
        lab_safety = {}
        
        for col in lab_cols:
            if df[col].dtype in ['int64', 'float64']:
                # å¼‚å¸¸å€¼æ£€æµ‹
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                abnormal_low = (df[col] < lower_bound).sum()
                abnormal_high = (df[col] > upper_bound).sum()
                total_abnormal = abnormal_low + abnormal_high
                
                lab_safety[col] = {
                    'n': df[col].count(),
                    'mean': df[col].mean(),
                    'std': df[col].std(),
                    'abnormal_low': abnormal_low,
                    'abnormal_high': abnormal_high,
                    'total_abnormal': total_abnormal,
                    'abnormal_rate': (total_abnormal / df[col].count()) * 100 if df[col].count() > 0 else 0
                }
        
        safety_analysis['laboratory'] = lab_safety
    
    return safety_analysis

def perform_final_efficacy_analysis(df, primary_endpoint):
    """æ‰§è¡Œæœ€ç»ˆç–—æ•ˆåˆ†æ"""
    
    efficacy_analysis = {}
    
    # æŸ¥æ‰¾ç–—æ•ˆç›¸å…³å˜é‡
    efficacy_cols = [col for col in df.columns if any(keyword in col.lower() 
                    for keyword in ['change', 'improvement', 'response', 'endpoint', 'efficacy'])]
    
    if not efficacy_cols:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        efficacy_cols = list(numeric_cols[:3]) if len(numeric_cols) > 0 else []
    
    # ä¸»è¦ç–—æ•ˆåˆ†æ
    if efficacy_cols:
        primary_var = efficacy_cols[0]
        
        efficacy_analysis['primary_efficacy'] = {
            'endpoint': primary_var,
            'analysis': analyze_primary_endpoint(df, primary_var)
        }
        
        # æ¬¡è¦ç–—æ•ˆåˆ†æ
        if len(efficacy_cols) > 1:
            secondary_analysis = {}
            
            for col in efficacy_cols[1:]:
                if df[col].dtype in ['int64', 'float64']:
                    secondary_analysis[col] = {
                        'overall': {
                            'n': df[col].count(),
                            'mean': df[col].mean(),
                            'std': df[col].std(),
                            'median': df[col].median()
                        }
                    }
                    
                    # åˆ†ç»„åˆ†æ
                    if 'group' in df.columns:
                        group_results = {}
                        
                        for group in df['group'].unique():
                            group_data = df[df['group'] == group][col]
                            group_results[group] = {
                                'n': group_data.count(),
                                'mean': group_data.mean(),
                                'std': group_data.std(),
                                'median': group_data.median()
                            }
                        
                        secondary_analysis[col]['by_group'] = group_results
            
            efficacy_analysis['secondary_efficacy'] = secondary_analysis
    
    # åº”ç­”ç‡åˆ†æï¼ˆå¦‚æœæœ‰äºŒåˆ†ç±»ç»“æœï¼‰
    response_cols = [col for col in df.columns if 'response' in col.lower()]
    
    if response_cols:
        response_analysis = {}
        
        for col in response_cols:
            if df[col].dtype in ['int64', 'bool'] or df[col].nunique() == 2:
                # æ€»ä½“åº”ç­”ç‡
                response_rate = df[col].mean() * 100 if df[col].dtype in ['int64', 'bool'] else 0
                
                response_analysis[col] = {
                    'overall_response_rate': response_rate,
                    'responders': df[col].sum() if df[col].dtype in ['int64', 'bool'] else 0,
                    'non_responders': len(df) - (df[col].sum() if df[col].dtype in ['int64', 'bool'] else 0)
                }
                
                # åˆ†ç»„åº”ç­”ç‡æ¯”è¾ƒ
                if 'group' in df.columns:
                    group_response = {}
                    
                    for group in df['group'].unique():
                        group_data = df[df['group'] == group]
                        group_response_rate = group_data[col].mean() * 100 if group_data[col].dtype in ['int64', 'bool'] else 0
                        
                        group_response[group] = {
                            'n': len(group_data),
                            'responders': group_data[col].sum() if group_data[col].dtype in ['int64', 'bool'] else 0,
                            'response_rate': group_response_rate
                        }
                    
                    response_analysis[col]['by_group'] = group_response
        
        efficacy_analysis['response_rates'] = response_analysis
    
    return efficacy_analysis

def perform_final_subgroup_analysis(df):
    """æ‰§è¡Œæœ€ç»ˆäºšç»„åˆ†æ"""
    
    subgroup_analysis = {}
    
    # é¢„å®šä¹‰äºšç»„å˜é‡
    subgroup_vars = []
    
    if 'age' in df.columns:
        # å¹´é¾„äºšç»„
        df['age_group'] = pd.cut(df['age'], bins=[0, 40, 60, 100], labels=['â‰¤40å²', '41-60å²', '>60å²'])
        subgroup_vars.append('age_group')
    
    if 'gender' in df.columns:
        subgroup_vars.append('gender')
    
    # æŸ¥æ‰¾å…¶ä»–åˆ†ç±»å˜é‡
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        if col not in ['group'] and df[col].nunique() <= 5:  # é™åˆ¶ç±»åˆ«æ•°é‡
            subgroup_vars.append(col)
    
    # æŸ¥æ‰¾ä¸»è¦ç–—æ•ˆå˜é‡
    efficacy_cols = [col for col in df.columns if any(keyword in col.lower() 
                    for keyword in ['change', 'improvement', 'response', 'endpoint'])]
    
    if not efficacy_cols:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        efficacy_cols = [numeric_cols[0]] if len(numeric_cols) > 0 else []
    
    # æ‰§è¡Œäºšç»„åˆ†æ
    if subgroup_vars and efficacy_cols and 'group' in df.columns:
        primary_efficacy = efficacy_cols[0]
        
        for subgroup_var in subgroup_vars:
            if subgroup_var in df.columns:
                subgroup_results = {}
                
                for subgroup_value in df[subgroup_var].unique():
                    if pd.notna(subgroup_value):
                        subgroup_data = df[df[subgroup_var] == subgroup_value]
                        
                        if len(subgroup_data) >= 10:  # æœ€å°æ ·æœ¬é‡è¦æ±‚
                            # è®¡ç®—å„ç»„çš„ç–—æ•ˆæŒ‡æ ‡
                            group_results = {}
                            
                            for group in subgroup_data['group'].unique():
                                group_subgroup_data = subgroup_data[subgroup_data['group'] == group]
                                
                                if len(group_subgroup_data) > 0:
                                    group_results[group] = {
                                        'n': len(group_subgroup_data),
                                        'mean': group_subgroup_data[primary_efficacy].mean(),
                                        'std': group_subgroup_data[primary_efficacy].std()
                                    }
                            
                            # è®¡ç®—ç»„é—´å·®å¼‚
                            if len(group_results) >= 2:
                                groups = list(group_results.keys())
                                mean_diff = group_results[groups[1]]['mean'] - group_results[groups[0]]['mean']
                                
                                subgroup_results[str(subgroup_value)] = {
                                    'group_results': group_results,
                                    'mean_difference': mean_diff,
                                    'total_n': len(subgroup_data)
                                }
                
                if subgroup_results:
                    subgroup_analysis[subgroup_var] = subgroup_results
    
    return subgroup_analysis

def display_final_report(content, report_format):
    """æ˜¾ç¤ºæœ€ç»ˆç ”ç©¶æŠ¥å‘Š"""
    
    study_info = content['study_info']
    
    # æŠ¥å‘Šæ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
    st.markdown(f"# {study_info['title']}")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ç ”ç©¶é˜¶æ®µ", study_info['phase'])
    
    with col2:
        st.metric("ç ”ç©¶è®¾è®¡", study_info['design'])
    
    with col3:
        st.metric("æ€»æ ·æœ¬é‡", study_info['total_subjects'])
    
    st.markdown(f"**ä¸»è¦ç»ˆç‚¹**: {study_info['primary_endpoint']}")
    st.markdown(f"**ç ”ç©¶æŒç»­æ—¶é—´**: {study_info['duration']}")
    st.markdown(f"**åˆ†ææ—¥æœŸ**: {study_info['analysis_date']}")
    
    st.markdown("---")
    
    # æ‘˜è¦
    st.markdown("## ğŸ“‹ ç ”ç©¶æ‘˜è¦")
    
    summary_text = generate_study_summary(content)
    st.markdown(summary_text)
    
    # ç ”ç©¶ç»“æœ
    if 'results' in content['sections']:
        st.markdown("## ğŸ“Š ç ”ç©¶ç»“æœ")
        
        results = content['sections']['results']
        
        # å—è¯•è€…ç‰¹å¾
        if 'demographics' in results:
            st.markdown("### ğŸ‘¥ å—è¯•è€…ç‰¹å¾")
            
            demographics = results['demographics']
            
            # å¹´é¾„ç‰¹å¾
            if 'age' in demographics:
                age_data = demographics['age']
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("æ ·æœ¬é‡", age_data['n'])
                
                with col2:
                    st.metric("å¹³å‡å¹´é¾„", f"{age_data['mean']:.1f}å²")
                
                with col3:
                    st.metric("å¹´é¾„ä¸­ä½æ•°", f"{age_data['median']:.1f}å²")
                
                with col4:
                    st.metric("å¹´é¾„èŒƒå›´", f"{age_data['range'][0]:.0f}-{age_data['range'][1]:.0f}å²")
                
                # å¹´é¾„ç»„åˆ†å¸ƒ
                if 'age_groups' in age_data:
                    st.markdown("#### å¹´é¾„ç»„åˆ†å¸ƒ")
                    
                    age_group_data = []
                    for age_group, count in age_data['age_groups'].items():
                        age_group_data.append({
                            'å¹´é¾„ç»„': age_group,
                            'äººæ•°': count,
                            'æ¯”ä¾‹': f"{(count/age_data['n'])*100:.1f}%"
                        })
                    
                    st.dataframe(pd.DataFrame(age_group_data), hide_index=True)
            
            # æ€§åˆ«åˆ†å¸ƒ
            if 'gender' in demographics:
                st.markdown("#### æ€§åˆ«åˆ†å¸ƒ")
                
                gender_data = []
                for gender, count in demographics['gender']['counts'].items():
                    percentage = demographics['gender']['percentages'][gender]
                    gender_data.append({
                        'æ€§åˆ«': gender,
                        'äººæ•°': count,
                        'æ¯”ä¾‹': f"{percentage:.1f}%"
                    })
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.dataframe(pd.DataFrame(gender_data), hide_index=True)
                
                with col2:
                    fig = px.pie(
                        pd.DataFrame(gender_data),
                        values='äººæ•°',
                        names='æ€§åˆ«',
                        title="æ€§åˆ«åˆ†å¸ƒ"
                    )
                    st.plotly_chart(fig, use_container_width=True)
            
            # æ²»ç–—ç»„åˆ†å¸ƒ
            if 'treatment_groups' in demographics:
                st.markdown("#### æ²»ç–—ç»„åˆ†å¸ƒ")
                
                group_data = []
                for group, count in demographics['treatment_groups']['counts'].items():
                    percentage = demographics['treatment_groups']['percentages'][group]
                    group_data.append({
                        'æ²»ç–—ç»„': group,
                        'äººæ•°': count,
                        'æ¯”ä¾‹': f"{percentage:.1f}%"
                    })
                
                st.dataframe(pd.DataFrame(group_data), hide_index=True)
        
        # å—è¯•è€…å¤„ç½®
        if 'disposition' in results:
            st.markdown("### ğŸ“‹ å—è¯•è€…å¤„ç½®")
            
            disposition = results['disposition']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("å…¥ç»„äººæ•°", disposition['enrolled'])
            
            with col2:
                st.metric("å®Œæˆäººæ•°", disposition['completed'])
            
            with col3:
                st.metric("å®Œæˆç‡", f"{disposition['completion_rate']:.1f}%")
            
            # åˆ†ç»„å¤„ç½®æƒ…å†µ
            if 'by_group' in disposition:
                st.markdown("#### åˆ†ç»„å¤„ç½®æƒ…å†µ")
                
                disposition_data = []
                for group, data in disposition['by_group'].items():
                    disposition_data.append({
                        'æ²»ç–—ç»„': group,
                        'å…¥ç»„äººæ•°': data['enrolled'],
                        'å®Œæˆäººæ•°': data['completed'],
                        'å®Œæˆç‡': f"{data['completion_rate']:.1f}%"
                    })
                
                st.dataframe(pd.DataFrame(disposition_data), hide_index=True)
        
        # ä¸»è¦ç»ˆç‚¹åˆ†æ
        if 'primary_analysis' in results:
            st.markdown("### ğŸ¯ ä¸»è¦ç»ˆç‚¹åˆ†æ")
            
            primary = results['primary_analysis']
            
            if 'variable' in primary:
                st.markdown(f"**åˆ†æå˜é‡**: {primary['variable']}")
                
                # æ€»ä½“ç»“æœ
                if 'overall' in primary:
                    st.markdown("#### æ€»ä½“ç»“æœ")
                    
                    overall = primary['overall']
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("æ ·æœ¬é‡", overall['n'])
                    
                    with col2:
                        st.metric("å‡å€¼", f"{overall['mean']:.3f}")
                    
                    with col3:
                        st.metric("æ ‡å‡†å·®", f"{overall['std']:.3f}")
                    
                    with col4:
                        st.metric("ä¸­ä½æ•°", f"{overall['median']:.3f}")
                
                # åˆ†ç»„ç»“æœ
                if 'by_group' in primary:
                    st.markdown("#### åˆ†ç»„ç»“æœ")
                    
                    group_data = []
                    for group, data in primary['by_group'].items():
                        group_data.append({
                            'æ²»ç–—ç»„': group,
                            'æ ·æœ¬é‡': data['n'],
                            'å‡å€¼': f"{data['mean']:.3f}",
                            'æ ‡å‡†å·®': f"{data['std']:.3f}",
                            'ä¸­ä½æ•°': f"{data['median']:.3f}",
                            'Q1': f"{data['q1']:.3f}",
                            'Q3': f"{data['q3']:.3f}"
                        })
                    
                    st.dataframe(pd.DataFrame(group_data), hide_index=True)
                
                # ç»Ÿè®¡æ£€éªŒç»“æœ
                if 'statistical_test' in primary:
                    st.markdown("#### ç»Ÿè®¡æ£€éªŒç»“æœ")
                    
                    test_results = primary['statistical_test']
                    
                    if 'error' not in test_results:
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("æ£€éªŒç»Ÿè®¡é‡", f"{test_results['t_statistic']:.4f}")
                        
                        with col2:
                            st.metric("På€¼", f"{test_results['p_value']:.4f}")
                        
                        with col3:
                            significance = "æ˜¯" if test_results['significant'] else "å¦"
                            st.metric("ç»Ÿè®¡å­¦æ˜¾è‘—", significance)
                        
                        # æ•ˆåº”é‡å’Œç½®ä¿¡åŒºé—´
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("æ•ˆåº”é‡ (Cohen's d)", f"{test_results['effect_size']:.3f}")
                        
                        with col2:
                            ci = test_results['ci_95']
                            st.metric("å‡å€¼å·®å¼‚95%CI", f"[{ci[0]:.3f}, {ci[1]:.3f}]")
                        
                        # ç»“æœè§£é‡Š
                        if test_results['significant']:
                            st.success("âœ… ä¸»è¦ç»ˆç‚¹è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚")
                        else:
                            st.warning("âš ï¸ ä¸»è¦ç»ˆç‚¹æœªè¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚")
    
    # å®‰å…¨æ€§åˆ†æ
    if 'safety' in content['sections']:
        st.markdown("## âš ï¸ å®‰å…¨æ€§åˆ†æ")
        
        safety = content['sections']['safety']
        
        # å®‰å…¨æ€§æ¦‚è¿°
        if 'overview' in safety:
            overview = safety['overview']
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("æ€»å—è¯•è€…æ•°", overview['total_subjects'])
            
            with col2:
                st.metric("å®‰å…¨æ€§å¯è¯„ä¼°äººæ•°", overview['safety_evaluable'])
        
        # ä¸è‰¯äº‹ä»¶åˆ†æ
        if 'adverse_events' in safety:
            st.markdown("### ä¸è‰¯äº‹ä»¶åˆ†æ")
            
            ae_data = safety['adverse_events']
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("å‘ç”ŸAEäººæ•°", ae_data['subjects_with_ae'])
            
            with col2:
                st.metric("AEå‘ç”Ÿç‡", f"{ae_data['ae_rate']:.1f}%")
            
            with col3:
                st.metric("æœªå‘ç”ŸAEäººæ•°", ae_data['subjects_without_ae'])
            
            # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†æ
            if 'ae_by_severity' in safety:
                st.markdown("#### æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»")
                
                severity_data = []
                for severity, count in safety['ae_by_severity']['counts'].items():
                    percentage = safety['ae_by_severity']['percentages'][severity]
                    severity_data.append({
                        'ä¸¥é‡ç¨‹åº¦': severity,
                        'äº‹ä»¶æ•°': count,
                        'å æ¯”': f"{percentage:.1f}%"
                    })
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.dataframe(pd.DataFrame(severity_data), hide_index=True)
                
                with col2:
                    fig = px.pie(
                        pd.DataFrame(severity_data),
                        values='äº‹ä»¶æ•°',
                        names='ä¸¥é‡ç¨‹åº¦',
                        title="ä¸è‰¯äº‹ä»¶ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ"
                    )
                    st.plotly_chart(fig, use_container_width=True)
            
            # åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ
            if 'ae_by_group' in safety:
                st.markdown("#### åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ")
                
                group_safety_data = []
                for group, data in safety['ae_by_group'].items():
                    group_safety_data.append({
                        'æ²»ç–—ç»„': group,
                        'æ ·æœ¬é‡': data['n'],
                        'AEäººæ•°': data['subjects_with_ae'],
                        'AEå‘ç”Ÿç‡': f"{data['ae_rate']:.1f}%"
                    })
                
                st.dataframe(pd.DataFrame(group_safety_data), hide_index=True)
                
                # ç»Ÿè®¡æ£€éªŒç»“æœ
                if 'group_comparison' in safety:
                    test_result = safety['group_comparison']
                    
                    if 'error' not in test_result:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.metric("å¡æ–¹ç»Ÿè®¡é‡", f"{test_result['chi2_statistic']:.4f}")
                        
                        with col2:
                            st.metric("På€¼", f"{test_result['p_value']:.4f}")
                        
                        if test_result['significant']:
                            st.warning("âš ï¸ ç»„é—´ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡å­˜åœ¨ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚")
                        else:
                            st.success("âœ… ç»„é—´ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡æ— ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚")
        
        # å®éªŒå®¤å®‰å…¨æ€§
        if 'laboratory' in safety:
            st.markdown("### ğŸ§ª å®éªŒå®¤å®‰å…¨æ€§æŒ‡æ ‡")
            
            lab_data = []
            for lab, results in safety['laboratory'].items():
                lab_data.append({
                    'æŒ‡æ ‡': lab,
                    'æ ·æœ¬é‡': results['n'],
                    'å‡å€¼': f"{results['mean']:.2f}",
                    'æ ‡å‡†å·®': f"{results['std']:.2f}",
                    'å¼‚å¸¸ä¾‹æ•°': results['total_abnormal'],
                    'å¼‚å¸¸ç‡': f"{results['abnormal_rate']:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(lab_data), hide_index=True)
    
    # ç–—æ•ˆåˆ†æ
    if 'efficacy' in content['sections']:
        st.markdown("## ğŸ“ˆ ç–—æ•ˆåˆ†æ")
        
        efficacy = content['sections']['efficacy']
        
        # ä¸»è¦ç–—æ•ˆåˆ†æï¼ˆå·²åœ¨ç ”ç©¶ç»“æœä¸­æ˜¾ç¤ºï¼Œè¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šç»†èŠ‚ï¼‰
        
        # æ¬¡è¦ç–—æ•ˆåˆ†æ
        if 'secondary_efficacy' in efficacy:
            st.markdown("### æ¬¡è¦ç–—æ•ˆç»ˆç‚¹")
            
            for endpoint, data in efficacy['secondary_efficacy'].items():
                st.markdown(f"#### {endpoint}")
                
                # æ€»ä½“ç»“æœ
                if 'overall' in data:
                    overall = data['overall']
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("æ ·æœ¬é‡", overall['n'])
                    
                    with col2:
                        st.metric("å‡å€¼", f"{overall['mean']:.3f}")
                    
                    with col3:
                        st.metric("æ ‡å‡†å·®", f"{overall['std']:.3f}")
                    
                    with col4:
                        st.metric("ä¸­ä½æ•°", f"{overall['median']:.3f}")
                
                # åˆ†ç»„ç»“æœ
                if 'by_group' in data:
                    group_data = []
                    for group, group_result in data['by_group'].items():
                        group_data.append({
                            'æ²»ç–—ç»„': group,
                            'æ ·æœ¬é‡': group_result['n'],
                            'å‡å€¼': f"{group_result['mean']:.3f}",
                            'æ ‡å‡†å·®': f"{group_result['std']:.3f}",
                            'ä¸­ä½æ•°': f"{group_result['median']:.3f}"
                        })
                    
                    st.dataframe(pd.DataFrame(group_data), hide_index=True)
        
        # åº”ç­”ç‡åˆ†æ
        if 'response_rates' in efficacy:
            st.markdown("### åº”ç­”ç‡åˆ†æ")
            
            for endpoint, data in efficacy['response_rates'].items():
                st.markdown(f"#### {endpoint}")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("æ€»ä½“åº”ç­”ç‡", f"{data['overall_response_rate']:.1f}%")
                
                with col2:
                    st.metric("åº”ç­”è€…", data['responders'])
                
                with col3:
                    st.metric("æ— åº”ç­”è€…", data['non_responders'])
                
                # åˆ†ç»„åº”ç­”ç‡æ¯”è¾ƒ
                if 'by_group' in data:
                    st.markdown("##### åˆ†ç»„åº”ç­”ç‡æ¯”è¾ƒ")
                    
                    response_data = []
                    for group, group_data in data['by_group'].items():
                        response_data.append({
                            'æ²»ç–—ç»„': group,
                            'æ ·æœ¬é‡': group_data['n'],
                            'åº”ç­”è€…': group_data['responders'],
                            'åº”ç­”ç‡': f"{group_data['response_rate']:.1f}%"
                        })
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.dataframe(pd.DataFrame(response_data), hide_index=True)
                    
                    with col2:
                        fig = px.bar(
                            pd.DataFrame(response_data),
                            x='æ²»ç–—ç»„',
                            y='åº”ç­”ç‡',
                            title=f"{endpoint} åˆ†ç»„åº”ç­”ç‡æ¯”è¾ƒ"
                        )
                        st.plotly_chart(fig, use_container_width=True)
    
    # äºšç»„åˆ†æ
    if 'subgroup' in content['sections']:
        st.markdown("## ğŸ” äºšç»„åˆ†æ")
        
        subgroup = content['sections']['subgroup']
        
        for subgroup_var, subgroup_data in subgroup.items():
            st.markdown(f"### æŒ‰ {subgroup_var} åˆ†å±‚åˆ†æ")
            
            subgroup_results = []
            
            for subgroup_value, results in subgroup_data.items():
                if 'group_results' in results:
                    group_results = results['group_results']
                    groups = list(group_results.keys())
                    
                    if len(groups) >= 2:
                        subgroup_results.append({
                            f'{subgroup_var}': subgroup_value,
                            f'{groups[0]} (n)': group_results[groups[0]]['n'],
                            f'{groups[0]} å‡å€¼': f"{group_results[groups[0]]['mean']:.3f}",
                            f'{groups[1]} (n)': group_results[groups[1]]['n'],
                            f'{groups[1]} å‡å€¼': f"{group_results[groups[1]]['mean']:.3f}",
                            'å‡å€¼å·®å¼‚': f"{results['mean_difference']:.3f}",
                            'æ€»æ ·æœ¬é‡': results['total_n']
                        })
            
            if subgroup_results:
                st.dataframe(pd.DataFrame(subgroup_results), hide_index=True)
                
                # æ£®æ—å›¾å¯è§†åŒ–ï¼ˆç®€åŒ–ç‰ˆï¼‰
                if len(subgroup_results) > 1:
                    fig = px.scatter(
                        pd.DataFrame(subgroup_results),
                        x='å‡å€¼å·®å¼‚',
                        y=f'{subgroup_var}',
                        size='æ€»æ ·æœ¬é‡',
                        title=f"æŒ‰{subgroup_var}åˆ†å±‚çš„æ²»ç–—æ•ˆåº”",
                        labels={'å‡å€¼å·®å¼‚': 'æ²»ç–—æ•ˆåº” (å‡å€¼å·®å¼‚)'}
                    )
                    fig.add_vline(x=0, line_dash="dash", line_color="red")
                    st.plotly_chart(fig, use_container_width=True)
    
    # è®¨è®ºå’Œç»“è®º
    st.markdown("## ğŸ’­ è®¨è®º")
    
    discussion_points = generate_discussion_points(content)
    
    for point in discussion_points:
        st.markdown(f"â€¢ {point}")
    
    st.markdown("## ğŸ“ ç»“è®º")
    
    conclusions = generate_final_conclusions(content)
    
    for conclusion in conclusions:
        st.success(f"âœ… {conclusion}")
    
    # å±€é™æ€§
    st.markdown("## âš ï¸ ç ”ç©¶å±€é™æ€§")
    
    limitations = generate_study_limitations(content)
    
    for limitation in limitations:
        st.warning(f"âš ï¸ {limitation}")
    
    # ä¸´åºŠæ„ä¹‰
    st.markdown("## ğŸ¥ ä¸´åºŠæ„ä¹‰")
    
    clinical_significance = generate_clinical_significance(content)
    
    for significance in clinical_significance:
        st.info(f"ğŸ’¡ {significance}")
    
    # æŠ¥å‘Šä¸‹è½½
    st.markdown("---")
    st.markdown("### ğŸ“¥ æŠ¥å‘Šä¸‹è½½")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“„ ä¸‹è½½PDFæŠ¥å‘Š"):
            pdf_content = generate_final_pdf_report(content)
            st.download_button(
                "ç‚¹å‡»ä¸‹è½½PDF",
                data=pdf_content,
                file_name=f"æœ€ç»ˆç ”ç©¶æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                mime="application/pdf"
            )
    
    with col2:
        if st.button("ğŸ“Š ä¸‹è½½WordæŠ¥å‘Š"):
            word_content = generate_final_word_report(content)
            st.download_button(
                "ç‚¹å‡»ä¸‹è½½Word",
                data=word_content,
                file_name=f"æœ€ç»ˆç ”ç©¶æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
    
    with col3:
        if st.button("ğŸŒ ä¸‹è½½HTMLæŠ¥å‘Š"):
            html_content = generate_final_html_report(content)
            st.download_button(
                "ç‚¹å‡»ä¸‹è½½HTML",
                data=html_content,
                file_name=f"æœ€ç»ˆç ”ç©¶æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                mime="text/html"
            )

def generate_study_summary(content):
    """ç”Ÿæˆç ”ç©¶æ‘˜è¦"""
    
    study_info = content['study_info']
    
    summary = f"""
    ### ç ”ç©¶èƒŒæ™¯
    æœ¬ç ”ç©¶æ˜¯ä¸€é¡¹{study_info['phase']}{study_info['design']}ï¼Œæ—¨åœ¨è¯„ä¼°{study_info['primary_endpoint']}ã€‚
    
    ### ç ”ç©¶æ–¹æ³•
    ç ”ç©¶å…±çº³å…¥{study_info['total_subjects']}åå—è¯•è€…ï¼Œç ”ç©¶æŒç»­æ—¶é—´ä¸º{study_info['duration']}ã€‚
    
    ### ä¸»è¦ç»“æœ
    """
    
    # æ·»åŠ ä¸»è¦ç»“æœæ‘˜è¦
    if 'results' in content['sections']:
        results = content['sections']['results']
        
        if 'primary_analysis' in results:
            primary = results['primary_analysis']
            
            if 'statistical_test' in primary:
                test_result = primary['statistical_test']
                
                if 'error' not in test_result:
                    if test_result['significant']:
                        summary += f"ä¸»è¦ç»ˆç‚¹è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚ (p={test_result['p_value']:.4f})ï¼Œ"
                        summary += f"æ²»ç–—ç»„é—´å‡å€¼å·®å¼‚ä¸º{test_result['mean_difference']:.3f}ã€‚"
                    else:
                        summary += f"ä¸»è¦ç»ˆç‚¹æœªè¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚ (p={test_result['p_value']:.4f})ã€‚"
    
    # æ·»åŠ å®‰å…¨æ€§æ‘˜è¦
    if 'safety' in content['sections']:
        safety = content['sections']['safety']
        
        if 'adverse_events' in safety:
            ae_rate = safety['adverse_events']['ae_rate']
            summary += f"\n\n### å®‰å…¨æ€§\nä¸è‰¯äº‹ä»¶æ€»å‘ç”Ÿç‡ä¸º{ae_rate:.1f}%ï¼Œ"
            
            if 'group_comparison' in safety:
                test_result = safety['group_comparison']
                
                if 'error' not in test_result:
                    if test_result['significant']:
                        summary += "ç»„é—´å®‰å…¨æ€§å­˜åœ¨ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚ã€‚"
                    else:
                        summary += "ç»„é—´å®‰å…¨æ€§æ— ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚ã€‚"
    
    return summary

def generate_discussion_points(content):
    """ç”Ÿæˆè®¨è®ºè¦ç‚¹"""
    
    discussion = []
    
    # ä¸»è¦å‘ç°è®¨è®º
    if 'results' in content['sections']:
        results = content['sections']['results']
        
        if 'primary_analysis' in results:
            primary = results['primary_analysis']
            
            if 'statistical_test' in primary:
                test_result = primary['statistical_test']
                
                if 'error' not in test_result:
                    if test_result['significant']:
                        effect_size = abs(test_result['effect_size'])
                        
                        if effect_size >= 0.8:
                            discussion.append("æœ¬ç ”ç©¶è§‚å¯Ÿåˆ°å¤§æ•ˆåº”é‡çš„æ²»ç–—æ•ˆæœï¼Œå…·æœ‰é‡è¦çš„ä¸´åºŠæ„ä¹‰")
                        elif effect_size >= 0.5:
                            discussion.append("æœ¬ç ”ç©¶è§‚å¯Ÿåˆ°ä¸­ç­‰æ•ˆåº”é‡çš„æ²»ç–—æ•ˆæœï¼Œæç¤ºæ²»ç–—å…·æœ‰ä¸€å®šçš„ä¸´åºŠä»·å€¼")
                        else:
                            discussion.append("è™½ç„¶è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ï¼Œä½†æ•ˆåº”é‡è¾ƒå°ï¼Œä¸´åºŠæ„ä¹‰æœ‰å¾…è¿›ä¸€æ­¥è¯„ä¼°")
                    else:
                        discussion.append("ä¸»è¦ç»ˆç‚¹æœªè¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ï¼Œå¯èƒ½ä¸æ ·æœ¬é‡ã€ç ”ç©¶è®¾è®¡æˆ–æ²»ç–—æ•ˆæœæœ‰å…³")
    
    # å®‰å…¨æ€§è®¨è®º
    if 'safety' in content['sections']:
        safety = content['sections']['safety']
        
        if 'adverse_events' in safety:
            ae_rate = safety['adverse_events']['ae_rate']
            
            if ae_rate < 10:
                discussion.append("ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡è¾ƒä½ï¼Œæ²»ç–—çš„å®‰å…¨æ€§è‰¯å¥½")
            elif ae_rate < 20:
                discussion.append("ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œä½†éœ€è¦ç»§ç»­ç›‘å¯Ÿ")
            else:
                discussion.append("ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡è¾ƒé«˜ï¼Œéœ€è¦ä»”ç»†æƒè¡¡è·ç›Šé£é™©æ¯”")
    
    # äºšç»„åˆ†æè®¨è®º
    if 'subgroup' in content['sections']:
        discussion.append("äºšç»„åˆ†æç»“æœæç¤ºæ²»ç–—æ•ˆæœå¯èƒ½åœ¨ä¸åŒäººç¾¤ä¸­å­˜åœ¨å·®å¼‚ï¼Œä½†éœ€è¦è°¨æ…è§£é‡Š")
    
    # ç ”ç©¶è®¾è®¡è®¨è®º
    study_info = content['study_info']
    
    if study_info['design'] == 'éšæœºå¯¹ç…§è¯•éªŒ':
        discussion.append("éšæœºå¯¹ç…§è®¾è®¡æœ‰æ•ˆæ§åˆ¶äº†æ··æ‚å› ç´ ï¼Œæé«˜äº†ç»“æœçš„å¯ä¿¡åº¦")
    
    # æ ·æœ¬é‡è®¨è®º
    if study_info['total_subjects'] < 100:
        discussion.append("æ ·æœ¬é‡ç›¸å¯¹è¾ƒå°ï¼Œç»“æœçš„æ¨å¹¿æ€§å¯èƒ½å—åˆ°é™åˆ¶")
    elif study_info['total_subjects'] > 500:
        discussion.append("è¾ƒå¤§çš„æ ·æœ¬é‡æé«˜äº†ç ”ç©¶ç»“æœçš„ç»Ÿè®¡åŠŸæ•ˆå’Œå¯é æ€§")
    
    return discussion

def generate_final_conclusions(content):
    """ç”Ÿæˆæœ€ç»ˆç»“è®º"""
    
    conclusions = []
    
    # ä¸»è¦ç»ˆç‚¹ç»“è®º
    if 'results' in content['sections']:
        results = content['sections']['results']
        
        if 'primary_analysis' in results:
            primary = results['primary_analysis']
            
            if 'statistical_test' in primary:
                test_result = primary['statistical_test']
                
                if 'error' not in test_result:
                    if test_result['significant']:
                        conclusions.append(f"ä¸»è¦ç»ˆç‚¹è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚ï¼Œè¯å®äº†æ²»ç–—çš„æœ‰æ•ˆæ€§")
                    else:
                        conclusions.append(f"ä¸»è¦ç»ˆç‚¹æœªè¾¾åˆ°é¢„è®¾çš„ç»Ÿè®¡å­¦æ˜¾è‘—æ€§æ ‡å‡†")
    
    # å®‰å…¨æ€§ç»“è®º
    if 'safety' in content['sections']:
        safety = content['sections']['safety']
        
        if 'adverse_events' in safety:
            ae_rate = safety['adverse_events']['ae_rate']
            
            if ae_rate < 15:
                conclusions.append("æ²»ç–—å…·æœ‰è‰¯å¥½çš„å®‰å…¨æ€§å’Œè€å—æ€§")
            else:
                conclusions.append("éœ€è¦å¯†åˆ‡ç›‘å¯Ÿæ²»ç–—ç›¸å…³çš„ä¸è‰¯äº‹ä»¶")
    
    # æ€»ä½“ç»“è®º
    study_info = content['study_info']
    conclusions.append(f"æœ¬{study_info['phase']}ç ”ç©¶ä¸º{study_info['primary_endpoint']}çš„è¯„ä¼°æä¾›äº†é‡è¦è¯æ®")
    
    return conclusions

def generate_study_limitations(content):
    """ç”Ÿæˆç ”ç©¶å±€é™æ€§"""
    
    limitations = []
    
    study_info = content['study_info']
    
    # æ ·æœ¬é‡å±€é™æ€§
    if study_info['total_subjects'] < 100:
        limitations.append("æ ·æœ¬é‡ç›¸å¯¹è¾ƒå°ï¼Œå¯èƒ½å½±å“ç»Ÿè®¡åŠŸæ•ˆ")
    
    # ç ”ç©¶è®¾è®¡å±€é™æ€§
    if study_info['design'] != 'éšæœºå¯¹ç…§è¯•éªŒ':
        limitations.append("ééšæœºå¯¹ç…§è®¾è®¡å¯èƒ½å­˜åœ¨é€‰æ‹©åå€š")
    
    # éšè®¿æ—¶é—´å±€é™æ€§
    if 'æœˆ' in study_info['duration']:
        try:
            months = int(study_info['duration'].replace('ä¸ªæœˆ', '').replace('æœˆ', ''))
            if months < 6:
                limitations.append("éšè®¿æ—¶é—´ç›¸å¯¹è¾ƒçŸ­ï¼Œé•¿æœŸæ•ˆæœå°šéœ€è¿›ä¸€æ­¥è§‚å¯Ÿ")
        except:
            pass
    
    # æ•°æ®è´¨é‡å±€é™æ€§
    if 'results' in content['sections']:
        results = content['sections']['results']
        
        if 'demographics' in results:
            demographics = results['demographics']
            
            # æ£€æŸ¥ç¼ºå¤±æ•°æ®
            if 'age' in demographics:
                age_data = demographics['age']
                total_subjects = content['study_info']['total_subjects']
                
                if age_data['n'] < total_subjects * 0.9:
                    limitations.append("éƒ¨åˆ†å…³é”®å˜é‡å­˜åœ¨ç¼ºå¤±æ•°æ®")
    
    # é€šç”¨å±€é™æ€§
    limitations.append("å•ä¸­å¿ƒç ”ç©¶ç»“æœçš„å¤–æ¨æ€§å¯èƒ½å—é™")
    limitations.append("æœªè¿›è¡Œå¤šé‡æ¯”è¾ƒæ ¡æ­£å¯èƒ½å¢åŠ Iå‹é”™è¯¯é£é™©")
    
    return limitations

def generate_clinical_significance(content):
    """ç”Ÿæˆä¸´åºŠæ„ä¹‰"""
    
    significance = []
    
    # ç–—æ•ˆçš„ä¸´åºŠæ„ä¹‰
    if 'results' in content['sections']:
        results = content['sections']['results']
        
        if 'primary_analysis' in results:
            primary = results['primary_analysis']
            
            if 'statistical_test' in primary:
                test_result = primary['statistical_test']
                
                if 'error' not in test_result and test_result['significant']:
                    effect_size = abs(test_result['effect_size'])
                    
                    if effect_size >= 0.5:
                        significance.append("è§‚å¯Ÿåˆ°çš„æ²»ç–—æ•ˆæœå…·æœ‰ä¸´åºŠæ„ä¹‰ï¼Œå¯èƒ½æ”¹å–„æ‚£è€…çš„ä¸´åºŠç»“å±€")
                    
                    significance.append("ç»Ÿè®¡å­¦æ˜¾è‘—çš„ç»“æœä¸ºä¸´åºŠå®è·µæä¾›äº†å¾ªè¯åŒ»å­¦è¯æ®")
    
    # å®‰å…¨æ€§çš„ä¸´åºŠæ„ä¹‰
    if 'safety' in content['sections']:
        safety = content['sections']['safety']
        
        if 'adverse_events' in safety:
            ae_rate = safety['adverse_events']['ae_rate']
            
            if ae_rate < 10:
                significance.append("è‰¯å¥½çš„å®‰å…¨æ€§ç‰¹å¾æ”¯æŒæ²»ç–—åœ¨ä¸´åºŠå®è·µä¸­çš„åº”ç”¨")
            
            if 'group_comparison' in safety:
                test_result = safety['group_comparison']
                
                if 'error' not in test_result and not test_result['significant']:
                    significance.append("ç»„é—´å®‰å…¨æ€§æ— æ˜¾è‘—å·®å¼‚ï¼Œä¸ºæ²»ç–—é€‰æ‹©æä¾›äº†é‡è¦å‚è€ƒ")
    
    # ç ”ç©¶æ–¹æ³•çš„ä¸´åºŠæ„ä¹‰
    study_info = content['study_info']
    
    if study_info['design'] == 'éšæœºå¯¹ç…§è¯•éªŒ':
        significance.append("é«˜è´¨é‡çš„ç ”ç©¶è®¾è®¡å¢å¼ºäº†ç»“æœçš„ä¸´åºŠå¯ä¿¡åº¦")
    
    # å¯¹æœªæ¥ç ”ç©¶çš„æ„ä¹‰
    significance.append("æœ¬ç ”ç©¶ç»“æœä¸ºåç»­æ›´å¤§è§„æ¨¡çš„ç ”ç©¶æä¾›äº†é‡è¦åŸºç¡€")
    significance.append("ç ”ç©¶å‘ç°æœ‰åŠ©äºä¼˜åŒ–ä¸´åºŠæ²»ç–—æ–¹æ¡ˆå’Œæ‚£è€…ç®¡ç†ç­–ç•¥")
    
    return significance

def generate_final_pdf_report(content):
    """ç”Ÿæˆæœ€ç»ˆPDFæŠ¥å‘Š"""
    
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=1*inch)
    
    # è·å–æ ·å¼
    styles = getSampleStyleSheet()
    story = []
    
    # è‡ªå®šä¹‰æ ·å¼
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=20,
        spaceAfter=30,
        alignment=TA_CENTER,
        textColor=colors.darkblue
    )
    
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontSize=14,
        spaceBefore=20,
        spaceAfter=10,
        textColor=colors.darkred
    )
    
    # æŠ¥å‘Šæ ‡é¢˜
    study_info = content['study_info']
    story.append(Paragraph(study_info['title'], title_style))
    story.append(Spacer(1, 12))
    
    # åŸºæœ¬ä¿¡æ¯è¡¨
    basic_info = [
        ['ç ”ç©¶é˜¶æ®µ', study_info['phase']],
        ['ç ”ç©¶è®¾è®¡', study_info['design']],
        ['ä¸»è¦ç»ˆç‚¹', study_info['primary_endpoint']],
        ['ç ”ç©¶æŒç»­æ—¶é—´', study_info['duration']],
        ['æ€»æ ·æœ¬é‡', str(study_info['total_subjects'])],
        ['åˆ†ææ—¥æœŸ', study_info['analysis_date']]
    ]
    
    info_table = Table(basic_info, colWidths=[2*inch, 3*inch])
    info_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),
        ('TEXTCOLOR', (0, 0), (-1, -1), colors.black),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),
        ('FONTSIZE', (0, 0), (-1, -1), 10),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),
        ('BACKGROUND', (1, 0), (1, -1), colors.white),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    
    story.append(info_table)
    story.append(Spacer(1, 20))
    
    # ç ”ç©¶æ‘˜è¦
    story.append(Paragraph("ç ”ç©¶æ‘˜è¦", heading_style))
    summary_text = generate_study_summary(content)
    # ç®€åŒ–æ‘˜è¦æ–‡æœ¬ï¼Œå»é™¤markdownæ ¼å¼
    clean_summary = summary_text.replace('#', '').replace('*', '').strip()
    story.append(Paragraph(clean_summary, styles['Normal']))
    story.append(Spacer(1, 12))
    
    # ä¸»è¦ç»“æœ
    if 'results' in content['sections']:
        story.append(Paragraph("ä¸»è¦ç»“æœ", heading_style))
        
        results = content['sections']['results']
        
        # å—è¯•è€…ç‰¹å¾
        if 'demographics' in results:
            story.append(Paragraph("å—è¯•è€…ç‰¹å¾", styles['Heading3']))
            
            demographics = results['demographics']
            
            if 'age' in demographics:
                age_data = demographics['age']
                age_text = f"å¹´é¾„: å¹³å‡ {age_data['mean']:.1f}Â±{age_data['std']:.1f} å²ï¼Œä¸­ä½æ•° {age_data['median']:.1f} å²ï¼ŒèŒƒå›´ {age_data['range'][0]:.0f}-{age_data['range'][1]:.0f} å²"
                story.append(Paragraph(age_text, styles['Normal']))
            
            if 'gender' in demographics:
                gender_text = "æ€§åˆ«åˆ†å¸ƒ: "
                for gender, percentage in demographics['gender']['percentages'].items():
                    gender_text += f"{gender} {percentage:.1f}%, "
                story.append(Paragraph(gender_text.rstrip(', '), styles['Normal']))
            
            story.append(Spacer(1, 12))
        
        # ä¸»è¦ç»ˆç‚¹åˆ†æ
        if 'primary_analysis' in results:
            story.append(Paragraph("ä¸»è¦ç»ˆç‚¹åˆ†æ", styles['Heading3']))
            
            primary = results['primary_analysis']
            
            if 'statistical_test' in primary:
                test_result = primary['statistical_test']
                
                if 'error' not in test_result:
                    result_text = f"ç»Ÿè®¡æ£€éªŒ: {test_result['test_type']}, "
                    result_text += f"ç»Ÿè®¡é‡ = {test_result['t_statistic']:.4f}, "
                    result_text += f"På€¼ = {test_result['p_value']:.4f}, "
                    result_text += f"æ•ˆåº”é‡ = {test_result['effect_size']:.3f}"
                    
                    story.append(Paragraph(result_text, styles['Normal']))
                    
                    if test_result['significant']:
                        story.append(Paragraph("ç»“è®º: ä¸»è¦ç»ˆç‚¹è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚", styles['Normal']))
                    else:
                        story.append(Paragraph("ç»“è®º: ä¸»è¦ç»ˆç‚¹æœªè¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚", styles['Normal']))
            
            story.append(Spacer(1, 12))
    
    # å®‰å…¨æ€§åˆ†æ
    if 'safety' in content['sections']:
        story.append(Paragraph("å®‰å…¨æ€§åˆ†æ", heading_style))
        
        safety = content['sections']['safety']
        
        if 'adverse_events' in safety:
            ae_data = safety['adverse_events']
            safety_text = f"ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡: {ae_data['ae_rate']:.1f}% ({ae_data['subjects_with_ae']}/{ae_data['subjects_with_ae'] + ae_data['subjects_without_ae']})"
            story.append(Paragraph(safety_text, styles['Normal']))
        
        story.append(Spacer(1, 12))
    
    # ç»“è®º
    story.append(Paragraph("ç»“è®º", heading_style))
    
    conclusions = generate_final_conclusions(content)
    
    for conclusion in conclusions:
        story.append(Paragraph(f"â€¢ {conclusion}", styles['Normal']))
    
    story.append(Spacer(1, 12))
    
    # å±€é™æ€§
    story.append(Paragraph("ç ”ç©¶å±€é™æ€§", heading_style))
    
    limitations = generate_study_limitations(content)
    
    for limitation in limitations:
        story.append(Paragraph(f"â€¢ {limitation}", styles['Normal']))
    
    # æ„å»ºPDF
    doc.build(story)
    
    buffer.seek(0)
    pdf_data = buffer.getvalue()
    buffer.close()
    
    return pdf_data

def generate_final_word_report(content):
    """ç”Ÿæˆæœ€ç»ˆWordæŠ¥å‘Š"""
    
    doc = Document()
    
    # è®¾ç½®æ ‡é¢˜
    study_info = content['study_info']
    title = doc.add_heading(study_info['title'], 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # åŸºæœ¬ä¿¡æ¯è¡¨
    doc.add_heading('ç ”ç©¶åŸºæœ¬ä¿¡æ¯', level=1)
    
    info_table = doc.add_table(rows=6, cols=2)
    info_table.style = 'Table Grid'
    
    info_data = [
        ('ç ”ç©¶é˜¶æ®µ', study_info['phase']),
        ('ç ”ç©¶è®¾è®¡', study_info['design']),
        ('ä¸»è¦ç»ˆç‚¹', study_info['primary_endpoint']),
        ('ç ”ç©¶æŒç»­æ—¶é—´', study_info['duration']),
        ('æ€»æ ·æœ¬é‡', str(study_info['total_subjects'])),
        ('åˆ†ææ—¥æœŸ', study_info['analysis_date'])
    ]
    
    for i, (key, value) in enumerate(info_data):
        row_cells = info_table.rows[i].cells
        row_cells[0].text = key
        row_cells[1].text = value
    
    # ç ”ç©¶æ‘˜è¦
    doc.add_heading('ç ”ç©¶æ‘˜è¦', level=1)
    summary_text = generate_study_summary(content)
    # æ¸…ç†markdownæ ¼å¼
    clean_summary = summary_text.replace('#', '').replace('*', '').strip()
    doc.add_paragraph(clean_summary)
    
    # ä¸»è¦ç»“æœ
    if 'results' in content['sections']:
        doc.add_heading('ä¸»è¦ç»“æœ', level=1)
        
        results = content['sections']['results']
        
        # å—è¯•è€…ç‰¹å¾
        if 'demographics' in results:
            doc.add_heading('å—è¯•è€…ç‰¹å¾', level=2)
            
            demographics = results['demographics']
            
            if 'age' in demographics:
                age_data = demographics['age']
                age_text = f"å¹´é¾„: å¹³å‡ {age_data['mean']:.1f}Â±{age_data['std']:.1f} å²ï¼Œä¸­ä½æ•° {age_data['median']:.1f} å²"
                doc.add_paragraph(age_text)
            
            if 'gender' in demographics:
                gender_text = "æ€§åˆ«åˆ†å¸ƒ: "
                for gender, percentage in demographics['gender']['percentages'].items():
                    gender_text += f"{gender} {percentage:.1f}%, "
                doc.add_paragraph(gender_text.rstrip(', '))
        
        # ä¸»è¦ç»ˆç‚¹åˆ†æ
        if 'primary_analysis' in results:
            doc.add_heading('ä¸»è¦ç»ˆç‚¹åˆ†æ', level=2)
            
            primary = results['primary_analysis']
            
            if 'statistical_test' in primary:
                test_result = primary['statistical_test']
                
                if 'error' not in test_result:
                    result_text = f"ç»Ÿè®¡æ£€éªŒç»“æœ: På€¼ = {test_result['p_value']:.4f}, æ•ˆåº”é‡ = {test_result['effect_size']:.3f}"
                    doc.add_paragraph(result_text)
                    
                    if test_result['significant']:
                        doc.add_paragraph("ç»“è®º: ä¸»è¦ç»ˆç‚¹è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚")
                    else:
                        doc.add_paragraph("ç»“è®º: ä¸»è¦ç»ˆç‚¹æœªè¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚")
    
    # å®‰å…¨æ€§åˆ†æ
    if 'safety' in content['sections']:
        doc.add_heading('å®‰å…¨æ€§åˆ†æ', level=1)
        
        safety = content['sections']['safety']
        
        if 'adverse_events' in safety:
            ae_data = safety['adverse_events']
            safety_text = f"ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡: {ae_data['ae_rate']:.1f}%"
            doc.add_paragraph(safety_text)
    
    # ç»“è®º
    doc.add_heading('ç»“è®º', level=1)
    
    conclusions = generate_final_conclusions(content)
    
    for conclusion in conclusions:
        doc.add_paragraph(conclusion, style='List Bullet')
    
    # å±€é™æ€§
    doc.add_heading('ç ”ç©¶å±€é™æ€§', level=1)
    
    limitations = generate_study_limitations(content)
    
    for limitation in limitations:
        doc.add_paragraph(limitation, style='List Bullet')
    
    # ä¿å­˜åˆ°å†…å­˜
    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    
    return buffer.getvalue()

def generate_final_html_report(content):
    """ç”Ÿæˆæœ€ç»ˆHTMLæŠ¥å‘Š"""
    
    study_info = content['study_info']
    
    html_content = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{study_info['title']}</title>
        <style>
            body {{
                font-family: 'Microsoft YaHei', Arial, sans-serif;
                margin: 40px;
                line-height: 1.8;
                color: #333;
                background-color: #f9f9f9;
            }}
            .container {{
                max-width: 1000px;
                margin: 0 auto;
                background-color: white;
                padding: 40px;
                border-radius: 10px;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            }}
            .header {{
                text-align: center;
                border-bottom: 3px solid #2E86AB;
                padding-bottom: 30px;
                margin-bottom: 40px;
            }}
            .header h1 {{
                color: #2E86AB;
                margin-bottom: 20px;
                font-size: 28px;
            }}
            .info-grid {{
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 20px;
                margin: 30px 0;
                padding: 20px;
                background-color: #f8f9fa;
                border-radius: 8px;
            }}
            .info-item {{
                display: flex;
                justify-content: space-between;
                padding: 10px 0;
                border-bottom: 1px solid #eee;
            }}
            .info-label {{
                font-weight: bold;
                color: #555;
            }}
            .info-value {{
                color: #333;
            }}
            .section {{
                margin: 40px 0;
            }}
            .section h2 {{
                color: #A23B72;
                border-left: 4px solid #A23B72;
                padding-left: 15px;
                font-size: 20px;
                margin-bottom: 20px;
            }}
            .section h3 {{
                color: #F18F01;
                font-size: 16px;
                margin: 20px 0 10px 0;
            }}
            .results-table {{
                width: 100%;
                border-collapse: collapse;
                margin: 20px 0;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }}
            .results-table th, .results-table td {{
                border: 1px solid #ddd;
                padding: 12px;
                text-align: left;
            }}
            .results-table th {{
                background-color: #2E86AB;
                color: white;
                font-weight: bold;
            }}
            .results-table tr:nth-child(even) {{
                background-color: #f9f9f9;
            }}
            .highlight-box {{
                background-color: #e8f4fd;
                border-left: 4px solid #2E86AB;
                padding: 15px;
                margin: 15px 0;
                border-radius: 4px;
            }}
            .conclusion-box {{
                background-color: #d4edda;
                border-left: 4px solid #28a745;
                padding: 15px;
                margin: 15px 0;
                border-radius: 4px;
            }}
            .limitation-box {{
                background-color: #fff3cd;
                border-left: 4px solid #ffc107;
                padding: 15px;
                margin: 15px 0;
                border-radius: 4px;
            }}
            .footer {{
                margin-top: 50px;
                padding-top: 20px;
                border-top: 2px solid #ddd;
                text-align: center;
                color: #666;
                font-size: 12px;
            }}
            ul {{
                padding-left: 20px;
            }}
            li {{
                margin: 8px 0;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>{study_info['title']}</h1>
                <p><strong>æœ€ç»ˆç ”ç©¶æŠ¥å‘Š</strong></p>
            </div>
            
            <div class="info-grid">
                <div class="info-item">
                    <span class="info-label">ç ”ç©¶é˜¶æ®µ:</span>
                    <span class="info-value">{study_info['phase']}</span>
                </div>
                <div class="info-item">
                    <span class="info-label">ç ”ç©¶è®¾è®¡:</span>
                    <span class="info-value">{study_info['design']}</span>
                </div>
                <div class="info-item">
                    <span class="info-label">ä¸»è¦ç»ˆç‚¹:</span>
                    <span class="info-value">{study_info['primary_endpoint']}</span>
                </div>
                <div class="info-item">
                    <span class="info-label">ç ”ç©¶æŒç»­æ—¶é—´:</span>
                    <span class="info-value">{study_info['duration']}</span>
                </div>
                <div class="info-item">
                    <span class="info-label">æ€»æ ·æœ¬é‡:</span>
                    <span class="info-value">{study_info['total_subjects']}</span>
                </div>
                <div class="info-item">
                    <span class="info-label">åˆ†ææ—¥æœŸ:</span>
                    <span class="info-value">{study_info['analysis_date']}</span>
                </div>
            </div>
            
            <div class="section">
                <h2>ç ”ç©¶æ‘˜è¦</h2>
                <div class="highlight-box">
    """
    
    # æ·»åŠ æ‘˜è¦å†…å®¹
    summary_text = generate_study_summary(content)
    clean_summary = summary_text.replace('#', '').replace('*', '').strip()
    html_content += f"<p>{clean_summary}</p>"
    
    html_content += """
                </div>
            </div>
    """
    
    # ä¸»è¦ç»“æœ
    if 'results' in content['sections']:
        html_content += """
            <div class="section">
                <h2>ä¸»è¦ç»“æœ</h2>
        """
        
        results = content['sections']['results']
        
        # å—è¯•è€…ç‰¹å¾
        if 'demographics' in results:
            html_content += """
                <h3>å—è¯•è€…ç‰¹å¾</h3>
                <table class="results-table">
                    <tr>
                        <th>ç‰¹å¾</th>
                        <th>ç»Ÿè®¡å€¼</th>
                    </tr>
            """
            
            demographics = results['demographics']
            
            if 'age' in demographics:
                age_data = demographics['age']
                html_content += f"""
                    <tr>
                        <td>å¹´é¾„ (å²)</td>
                        <td>å¹³å‡: {age_data['mean']:.1f}Â±{age_data['std']:.1f}, ä¸­ä½æ•°: {age_data['median']:.1f}</td>
                    </tr>
                """
            
            if 'gender' in demographics:
                gender_text = ""
                for gender, percentage in demographics['gender']['percentages'].items():
                    gender_text += f"{gender}: {percentage:.1f}%; "
                
                html_content += f"""
                    <tr>
                        <td>æ€§åˆ«åˆ†å¸ƒ</td>
                        <td>{gender_text.rstrip('; ')}</td>
                    </tr>
                """
            
            html_content += "</table>"
        
        # ä¸»è¦ç»ˆç‚¹åˆ†æ
        if 'primary_analysis' in results:
            html_content += "<h3>ä¸»è¦ç»ˆç‚¹åˆ†æ</h3>"
            
            primary = results['primary_analysis']
            
            if 'statistical_test' in primary:
                test_result = primary['statistical_test']
                
                if 'error' not in test_result:
                    html_content += f"""
                    <table class="results-table">
                        <tr>
                            <th>ç»Ÿè®¡æŒ‡æ ‡</th>
                            <th>ç»“æœ</th>
                        </tr>
                        <tr>
                            <td>æ£€éªŒæ–¹æ³•</td>
                            <td>{test_result['test_type']}</td>
                        </tr>
                        <tr>
                            <td>ç»Ÿè®¡é‡</td>
                            <td>{test_result['t_statistic']:.4f}</td>
                        </tr>
                        <tr>
                            <td>På€¼</td>
                            <td>{test_result['p_value']:.4f}</td>
                        </tr>
                        <tr>
                            <td>æ•ˆåº”é‡ (Cohen's d)</td>
                            <td>{test_result['effect_size']:.3f}</td>
                        </tr>
                        <tr>
                            <td>å‡å€¼å·®å¼‚</td>
                            <td>{test_result['mean_difference']:.3f}</td>
                        </tr>
                        <tr>
                            <td>95%ç½®ä¿¡åŒºé—´</td>
                            <td>[{test_result['ci_95'][0]:.3f}, {test_result['ci_95'][1]:.3f}]</td>
                        </tr>
                    </table>
                    """
                    
                    if test_result['significant']:
                        html_content += '<div class="conclusion-box"><strong>ç»“è®º:</strong> ä¸»è¦ç»ˆç‚¹è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚</div>'
                    else:
                        html_content += '<div class="limitation-box"><strong>ç»“è®º:</strong> ä¸»è¦ç»ˆç‚¹æœªè¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚</div>'
        
        html_content += "</div>"
    
    # å®‰å…¨æ€§åˆ†æ
    if 'safety' in content['sections']:
        html_content += """
            <div class="section">
                <h2>å®‰å…¨æ€§åˆ†æ</h2>
        """
        
        safety = content['sections']['safety']
        
        if 'adverse_events' in safety:
            ae_data = safety['adverse_events']
            
            html_content += f"""
                <table class="results-table">
                    <tr>
                        <th>å®‰å…¨æ€§æŒ‡æ ‡</th>
                        <th>ç»“æœ</th>
                    </tr>
                    <tr>
                        <td>ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡</td>
                        <td>{ae_data['ae_rate']:.1f}% ({ae_data['subjects_with_ae']}/{ae_data['subjects_with_ae'] + ae_data['subjects_without_ae']})</td>
                    </tr>
                    <tr>
                        <td>å‘ç”Ÿä¸è‰¯äº‹ä»¶äººæ•°</td>
                        <td>{ae_data['subjects_with_ae']}</td>
                    </tr>
                    <tr>
                        <td>æœªå‘ç”Ÿä¸è‰¯äº‹ä»¶äººæ•°</td>
                        <td>{ae_data['subjects_without_ae']}</td>
                    </tr>
                </table>
            """
            
            # åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ
            if 'ae_by_group' in safety:
                html_content += "<h3>åˆ†ç»„å®‰å…¨æ€§æ¯”è¾ƒ</h3>"
                html_content += """
                <table class="results-table">
                    <tr>
                        <th>æ²»ç–—ç»„</th>
                        <th>æ ·æœ¬é‡</th>
                        <th>AEäººæ•°</th>
                        <th>AEå‘ç”Ÿç‡</th>
                    </tr>
                """
                
                for group, data in safety['ae_by_group'].items():
                    html_content += f"""
                    <tr>
                        <td>{group}</td>
                        <td>{data['n']}</td>
                        <td>{data['subjects_with_ae']}</td>
                        <td>{data['ae_rate']:.1f}%</td>
                    </tr>
                    """
                
                html_content += "</table>"
                
                # ç»Ÿè®¡æ£€éªŒç»“æœ
                if 'group_comparison' in safety:
                    test_result = safety['group_comparison']
                    
                    if 'error' not in test_result:
                        html_content += f"""
                        <div class="highlight-box">
                            <strong>ç»„é—´æ¯”è¾ƒ:</strong> å¡æ–¹æ£€éªŒ, Ï‡Â² = {test_result['chi2_statistic']:.4f}, P = {test_result['p_value']:.4f}
                        """
                        
                        if test_result['significant']:
                            html_content += "<br><strong>ç»“è®º:</strong> ç»„é—´ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡å­˜åœ¨ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚"
                        else:
                            html_content += "<br><strong>ç»“è®º:</strong> ç»„é—´ä¸è‰¯äº‹ä»¶å‘ç”Ÿç‡æ— ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚"
                        
                        html_content += "</div>"
        
        html_content += "</div>"
    
    # ç»“è®º
    html_content += """
        <div class="section">
            <h2>ç»“è®º</h2>
    """
    
    conclusions = generate_final_conclusions(content)
    
    html_content += "<ul>"
    for conclusion in conclusions:
        html_content += f"<li>{conclusion}</li>"
    html_content += "</ul>"
    
    html_content += "</div>"
    
    # ç ”ç©¶å±€é™æ€§
    html_content += """
        <div class="section">
            <h2>ç ”ç©¶å±€é™æ€§</h2>
    """
    
    limitations = generate_study_limitations(content)
    
    html_content += "<ul>"
    for limitation in limitations:
        html_content += f'<li><div class="limitation-box">{limitation}</div></li>'
    html_content += "</ul>"
    
    html_content += "</div>"
    
    # ä¸´åºŠæ„ä¹‰
    html_content += """
        <div class="section">
            <h2>ä¸´åºŠæ„ä¹‰</h2>
    """
    
    clinical_significance = generate_clinical_significance(content)
    
    html_content += "<ul>"
    for significance in clinical_significance:
        html_content += f'<li><div class="conclusion-box">{significance}</div></li>'
    html_content += "</ul>"
    
    html_content += "</div>"
    
    # é¡µè„š
    html_content += f"""
            <div class="footer">
                <p>æœ¬æŠ¥å‘Šç”±ä¸´åºŠè¯•éªŒæ•°æ®åˆ†æç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ</p>
                <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>
                <p>æŠ¥å‘Šç‰ˆæœ¬: æœ€ç»ˆç‰ˆ | æ•°æ®æˆªæ­¢: {study_info['analysis_date']}</p>
            </div>
        </div>
    </body>
    </html>
    """
    
    return html_content

# ä¸»å‡½æ•°ï¼šæŠ¥å‘Šç”Ÿæˆæ¨¡å—å…¥å£
def report_generation_module():
    """æŠ¥å‘Šç”Ÿæˆæ¨¡å—ä¸»å‡½æ•°"""
    
    st.markdown("# ğŸ“Š æŠ¥å‘Šç”Ÿæˆæ¨¡å—")
    st.markdown("---")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    if 'df' not in st.session_state or st.session_state.df is None:
        st.warning("âš ï¸ è¯·å…ˆåœ¨æ•°æ®ç®¡ç†æ¨¡å—ä¸­ä¸Šä¼ æ•°æ®æ–‡ä»¶")
        return
    
    df = st.session_state.df
    
    # æŠ¥å‘Šç±»å‹é€‰æ‹©
    st.markdown("## ğŸ“‹ é€‰æ‹©æŠ¥å‘Šç±»å‹")
    
    report_type = st.selectbox(
        "æŠ¥å‘Šç±»å‹",
        [
            "æè¿°æ€§ç»Ÿè®¡æŠ¥å‘Š",
            "æ¨æ–­æ€§ç»Ÿè®¡æŠ¥å‘Š", 
            "è‡ªå®šä¹‰åˆ†ææŠ¥å‘Š",
            "ä¸­æœŸåˆ†ææŠ¥å‘Š",
            "æœ€ç»ˆç ”ç©¶æŠ¥å‘Š"
        ]
    )
    
    # æ ¹æ®é€‰æ‹©çš„æŠ¥å‘Šç±»å‹æ˜¾ç¤ºç›¸åº”ç•Œé¢
    if report_type == "æè¿°æ€§ç»Ÿè®¡æŠ¥å‘Š":
        generate_descriptive_report(df)
    
    elif report_type == "æ¨æ–­æ€§ç»Ÿè®¡æŠ¥å‘Š":
        generate_inferential_report(df)
    
    elif report_type == "è‡ªå®šä¹‰åˆ†ææŠ¥å‘Š":
        generate_custom_report(df)
    
    elif report_type == "ä¸­æœŸåˆ†ææŠ¥å‘Š":
        generate_interim_report(df)
    
    elif report_type == "æœ€ç»ˆç ”ç©¶æŠ¥å‘Š":
        generate_final_report(df)
    
    # æŠ¥å‘Šæ¨¡æ¿ç®¡ç†
    st.markdown("---")
    st.markdown("## ğŸ“ æŠ¥å‘Šæ¨¡æ¿ç®¡ç†")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ’¾ ä¿å­˜å½“å‰é…ç½®ä¸ºæ¨¡æ¿"):
            save_report_template()
    
    with col2:
        if st.button("ğŸ“‚ åŠ è½½å·²ä¿å­˜æ¨¡æ¿"):
            load_report_template()

def save_report_template():
    """ä¿å­˜æŠ¥å‘Šæ¨¡æ¿"""
    
    st.info("æŠ¥å‘Šæ¨¡æ¿ä¿å­˜åŠŸèƒ½")
    
    template_name = st.text_input("æ¨¡æ¿åç§°", placeholder="è¾“å…¥æ¨¡æ¿åç§°")
    template_description = st.text_area("æ¨¡æ¿æè¿°", placeholder="æè¿°æ¨¡æ¿ç”¨é€”å’Œç‰¹ç‚¹")
    
    if st.button("ç¡®è®¤ä¿å­˜") and template_name:
        # è¿™é‡Œå¯ä»¥å®ç°æ¨¡æ¿ä¿å­˜é€»è¾‘
        # å°†å½“å‰çš„æŠ¥å‘Šé…ç½®ä¿å­˜åˆ°æ–‡ä»¶æˆ–æ•°æ®åº“
        
        template_config = {
            'name': template_name,
            'description': template_description,
            'created_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'config': {
                # ä¿å­˜å½“å‰çš„æŠ¥å‘Šé…ç½®å‚æ•°
                'report_type': 'custom',
                'components': [],  # è¿™é‡Œåº”è¯¥ä¿å­˜å®é™…çš„ç»„ä»¶é…ç½®
                'settings': {}     # è¿™é‡Œåº”è¯¥ä¿å­˜å®é™…çš„è®¾ç½®å‚æ•°
            }
        }
        
        st.success(f"âœ… æ¨¡æ¿ '{template_name}' ä¿å­˜æˆåŠŸï¼")

def load_report_template():
    """åŠ è½½æŠ¥å‘Šæ¨¡æ¿"""
    
    st.info("æŠ¥å‘Šæ¨¡æ¿åŠ è½½åŠŸèƒ½")
    
    # è¿™é‡Œåº”è¯¥æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡æ¿åˆ—è¡¨
    available_templates = [
        "æ ‡å‡†æè¿°æ€§åˆ†ææ¨¡æ¿",
        "è¯ç‰©å®‰å…¨æ€§è¯„ä¼°æ¨¡æ¿", 
        "ç–—æ•ˆè¯„ä»·æ¨¡æ¿",
        "ä¸­æœŸåˆ†ææ ‡å‡†æ¨¡æ¿"
    ]
    
    selected_template = st.selectbox("é€‰æ‹©æ¨¡æ¿", available_templates)
    
    if st.button("åŠ è½½æ¨¡æ¿"):
        # è¿™é‡Œå¯ä»¥å®ç°æ¨¡æ¿åŠ è½½é€»è¾‘
        st.success(f"âœ… æ¨¡æ¿ '{selected_template}' åŠ è½½æˆåŠŸï¼")
        st.info("æ¨¡æ¿é…ç½®å·²åº”ç”¨åˆ°å½“å‰æŠ¥å‘Šç”Ÿæˆè®¾ç½®ä¸­")

# å·¥å…·å‡½æ•°
def detect_outliers(series):
    """æ£€æµ‹å¼‚å¸¸å€¼æ•°é‡"""
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = series[(series < lower_bound) | (series > upper_bound)]
    return len(outliers)

def calculate_quality_score(df):
    """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
    
    # å®Œæ•´æ€§è¯„åˆ†
    missing_rate = df.isnull().sum().sum() / (len(df) * len(df.columns))
    completeness_score = (1 - missing_rate) * 100
    
    # ä¸€è‡´æ€§è¯„åˆ†
    duplicate_rate = df.duplicated().sum() / len(df)
    consistency_score = (1 - duplicate_rate) * 100
    
    # æ€»ä½“è¯„åˆ†
    overall_score = (completeness_score + consistency_score) / 2
    
    return {
        'completeness': completeness_score,
        'consistency': consistency_score,
        'overall': overall_score
    }

# å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œæ˜¾ç¤ºæŠ¥å‘Šç”Ÿæˆæ¨¡å—
if __name__ == "__main__":
    report_generation_module()

                






